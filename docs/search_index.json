[["index.html", "Data Science from Scratch Code Chapter 1 Computer Set-Up 1.1 Virtual Environment 1.2 R Markdown 1.3 Terminal-Commands: 1.4 How to activate &amp; use Python? 1.5 Git &amp; Github: 1.6 LaTeX 1.7 W√∂rterbuch 1.8 Synonyme 1.9 Projekt-Management", " Data Science from Scratch Code Joffrey Anthony 2021-11-19 Chapter 1 Computer Set-Up When building projects efficiently, you will need different set-ups in order to have everything in your code work properly, not only on your own machine, but also on other machines, for example of another team-member. 1.1 Virtual Environment Because the libraries you work with in your projects will be updated over time (this is generally bad news, since this will cause all sorts of dependency problems across your libaries you use), it is crucial to understand that you will need a virtual environment (venv). There, you will install all the libraries you need. The major advantage here, is that you can control the version you install the library. Furthermore, you can send the venv to another computer and the people will download exactly the versions of each library. This allows that your code will always work, independently of the machine you will use! There will be no dependency problems anymore, which is a huge win.. :) 1.1.1 Create a venv Go to your terminal and plug in the following code: conda create -n YOUR-VENVIRONMENT-NAME-HERE python=3.6 1.1.2 Activate your newly created venv Weirdly though, you also need to activate the environment you created above. Plug in the following code: source activate YOUR-ENVIRONMENT-NAME Note that the code above can also be used to activate virtual environments you created in the past! =) 1.1.3 Install packages Now that you are in your new venv, you can start downloading some packages: python -m pip install SOME-PACKAGES 1.1.4 Overview of packages To check your packages within your venv, simply type: conda list 1.1.5 Overview of every venv To check all the venv I created, simply type: conda env list 1.1.6 Execute any python skript In order to execute a Python-script, you will need to head towards the directory that the .py-file is and - then - type in: cd go-to-the-dir-where-your-file-is python my-script.py 1.1.7 Deactivate the venv After you have completed what you wanted, you will need to shut-down the venv. Simply type: conda deactivate 1.1.8 Delete a venv Simply type: conda env remove -n my-new-env 1.2 R Markdown When writing Code, I recommend you to use .Rmd-Documents, which will allow you to combine both, text, as well as Code (in R, Python, or any other language of your choice). Actually, this document is written in .Rmd-Files, where I combine the text, with so-called ‚Äúcode-snippets‚Äù, like the follwing: This is a Code-Snippet When writing Code in R-Markdown, it will be useful for you to know when: to execute code wihtin a code-snippet and where not. 1.2.1 Hide Source Code This will be done with echo = FALSE: ## [1] 2 With figures, you need fig.show = 'hide' in R: plot(cars) To hide warning-messages, just use message = FALSE: message(&quot;You will not see the message.&quot;) 1.2.2 Execute a Code-Chunk without showing any Output You will get an output, e.g. the code will execute, but you will not show the code. 1.2.3 Do NOT execute a Code-Chunk If you want to show code for demonstration purposes - like on this Website - you will probably want to only show the code, but not execute it. This is also possible with eval=FALSE: 1.2.4 RMarkdown- VS. Markdown-Files Verwende &lt;ins&gt;&lt;/ins&gt; als HTML, um Texte zu Unterstreichen. Achtung : Der HTML-Tag &lt;u&gt;&lt;/u&gt; geht nicht in .rm-files. Lustigerweise funktioniert &lt;u&gt;&lt;/u&gt; jedoch in .Rmd (= R Markdown) üòÇ 1.2.5 N√ºtzliche Hexadecimals Hexadecimal code for the left square-bracket = &amp;#91; ‚Äì&gt; Ich muss das so machen mit den eckigen Klammern, weil [] wird f√ºr Links &amp; Bilder verwendet in Markdown  Hexadecimal code for the right square-bracket = &amp;#93; ‚Äì&gt; Ich muss das so machen mit den eckigen Klammern, weil [] wird f√ºr Links &amp; Bilder verwendet in Markdown  1.3 Terminal-Commands: A terminal will be essential for your projects, since you will - oftentimes - install packages or move files around your repositories with it. Here, you will find the most useful things you should know when using the Terminal. 1.3.1 Aktuelle Position // Directory? For Mac: pwd = print working directory For Windows: dir = this is the same command as pwd, but dir is for Windows 1.3.2 Showing the child-directories inside the directory you are currently in? ls = prints all the child-directories (= one layer deeper of the path) from the parent-directory (= current directory you are in with your terminal) you are currently in. 1.3.3 Delete everything you wrote in your Terminal up until now? clear = clears the terminal 1.3.4 Change directory? cd = change directory cd .. = go back one directory. 1.3.5 Creating a new directory? mkdir new-folder-1 new-folder-2 new-folder-3 = This creates 3 new folder within the current (working-) directory you are currently in. 1.3.6 Create a new file? touch index.html app.css == This will create an index.html, as well as a app.css-file within the current (working-) directory you are currently in. 1.3.7 Remove files? rm index.html app.css capture.png = This will delete the index.html-, the app.css and the capture.png-files from the current (working-) directory you are currently in. 1.3.8 Open the current directory you are in? open . = opens the current directory you are in 1.3.9 Terminal Magic-Commands for being faster? Trick #1: hit the ‚ÄúTab-Taste‚Äù == will automatically auto-fill the name of the file / directories etc. Example: Type cd Dok + ‚ÄúTab‚Äù-Taste ‚Äì&gt; auto-fill activates ‚Äì&gt; im Terminal steht dann der automatisch ausgef√ºllte Name des Files / Directories, zum Beispiel cd Dokumente bzw. cd Name_Of_Child_Directory Trick #2: How to find a path of a directory that is situated very deeply in your local computer? Example: Type cd + drag-&amp;-drop the folder that is deep in your computer with the file in it. 1.3.10 Syntax im Terminal *-Zeichen == Represents ‚Äúall files‚Äù. 1.3.10.1 Beispiel: Delete all Files in a folder that start with the letter a? To delete all files in a folder that start with the letter a, then you should write: /folder/a* .-Zeichen == use the . character to represent the current folder. ~-Zeichen == represents the ‚Äúhome directory‚Äù. 1.3.10.2 Beispiel: how to return to your home directory? You should use: cd ~ 1.4 How to activate &amp; use Python? Python can be executed on your local computer via a Jupyter Notebook, which can be accessed through an IDE. R, Visual Studio Code or PyCharm are examples of IDEs. Let‚Äôs assume, that we took PyCharm as our IDE. We do the following steps: Use the Terminal within PyCharm. Once you opened the PyCharm-Terminal, go to the directory that will be used for the Jupyter Notebook, by typing something as cd /some_folder_name. Finally, type in jupyter notebook in the Terminal to launch the Jupyter Notebook App. The notebook interface will appear in a new browser window or tab. 1.5 Git &amp; Github: pull request = ‚ÄúTake some changes from a particular branch and bring it into another branch.‚Äù Achtung: es ist eine Request, es wurde noch nichts gemerged! F√ºr das brauch es noch merge als zus√§tzlichen Befehl. fork a repo = ‚ÄúTake someone else‚Äôs repo - because you love it üòä - and put it into your own list of repos, in order to be able to edit it yourself without affectig the original repository of the owner.‚Äù commit = save hash = unique identifier in the history of files. A has is a huge string composed of characters (= Buchstaben) &amp; numbers and is used when using a version-control software, such as Git. git add = Der Befehl git add wird zu vielen verschiedenen Zwecken eingesetzt. Man verwendet ihn, um: neue Dateien zur Version-Control hinzuzuf√ºgen, Dateien f√ºr einen Commit vorzumerken, UND verschiedene andere Dinge ‚Äì beispielsweise einen Konflikt aus einem Merge als aufgel√∂st zu kennzeichnen. Leider wird der Befehl git add oft missverstanden. Viele assoziieren damit, dass damit Dateien zum Projekt hinzugef√ºgt werden. Wie Sie aber gerade gelernt haben, wird der Befehl auch noch f√ºr viele andere Dinge eingesetzt. Wenn Sie den Befehl git add einsetzen, sollten Sie das eher so sehen, dass Sie damit einen bestimmten Inhalt f√ºr den n√§chsten Commit vormerken (= also Punkt (2) ist vor allem relevant in der obigen Liste. How to tell the original owner you want to merge your changes that you made back into their orignal repo and implement them those changes into their original work // repo? Look at the youtube video from Coding Train ab 9:35-11:50 To see how to refer to issues &amp; bugs in your code directly via your commit-command, look at the youtube video ab 6:35-7:40 and to diretly close issues, because you resolved it, look look at the youtube video ab 7:40-8:55. What is a remote? A remote is a duplicate instance of your repository (on your local computer) that lives somewhere else on a remote server (like Github). 1.5.1 First time using Git &amp; Github There are specific Git-commands that you need to know, when you begin to start to work with Git and Gibthun for the first time. Note that all these Git-commands need to be typed within the Terminal on your local computer. git config --list = Sehr wichtig, wenn du Git zum ersten Mal via einem neuen Computer runst! Dieser Befehl zeigt dir, welchen Username &amp; Email du aktuell verwendest (schaue bei user.name &amp; user.email, ob es deine Github Anmelde-Daten sind). Es ist key - insbesondere, wenn du neu mit Git beginnst - dass diese Parameter mit deinen Github Anmelde-Daten √ºbereinstimmen! Ansonsten musst du immer git clone machen und die √§ltere Version in einen ‚Äúalt‚Äù-Ordner tun, was extrem m√ºhsam ist. Wenn du noch keinen user.name hast, dann gebe folgenden Code in die Command-Line ein: git config --global user.name 'Dein_Github_UserName'. Beachte: Schreibe den Namen mit die Anf√ºhrungszeichen! Wenn du noch keinen user.name hast, dann gebe folgenden Code in die Command-Line ein: git config --global user.name 'deineEmail@email.ch'. Beachte: Schreibe die Email ohne die Anf√ºhrungszeichen! Check if it worked?: Gebe wieder den Befehl git config --list und schaue bei user.name &amp; user.email, ob dort deine Github Anmelde-Daten √ºbernommen wurden. git push = this is the act of sending to Github. git pull = this is the act of receiving from Github. 1.5.2 2 Key concepts in Git Before starting to work with Git, you need to understand that there are 2 ways of starting a project: 1) Create a `remote` repository on Github and then `cloning` it - via Git - on your local computer to work from there. 2) Creating a repository `locally` on your computer and then - aftre a few months working on this repository - adding it to Github. Depending on which of those 2 different ways you choose to start a project (create a repo right from the get-go on Github VS. work locally and then - after some time - push everything to Github), the Git-Commands will slightly differ. 1.5.2.1 Start Project via Github (remote-possibility) What are the Git-Commands, if you start your project directly by creating a Repo on Github (= possibility 1) above)? git clone https://github.com/joffreymayer/tageb.git == Will clone your remote directory tageb - which is currently on Github on your local computer, which is simpler // more comfy when working on projects =) git status = Assume that you worked on &amp; modified a file on your local computer that you previously had on Github (you cloned the directory with the file in it on your local computer). With the command git status, Git will check whether there is any changes between your local files VS. the files in the remote directory on the Github-Server // -Website. git commit -a -m \"Test comment for a commit\" = If you changed a file locally and you are happy with your results, you will need to make a commit (= save) and add all files (= this is why we have an input // argument -a; the concept of adding will be explored in the chapter below, where you want to put a local repo into Github after a few months) and you also want to document, what exactly you modified, if you need to go back to a previous version of your file (= this is why we have an input // argument -m \"comment is here...\"). git push origin master = If you have done some changes locally on your file, you can now push everything on the Github-Website. git log = see, locally, the history of your git commits. Achtung: When running this command, you might - accidentally - run into a dangerous environment called VIM, which is a terminal-based text-editor. The problem when you are in VIM, is that you might not be able to get out of it. -Solution: To get out of VIM, just type in :q and you will get out of it. git remote -v = This will tell you which URL is the remote on which your repository is hosted. Merke: The URL of your repo is assigned to the variable origin in Git. 1.5.2.2 Start Project via local computer (local-possibility) What commands do you need, when you decide - after a few months working locally on your computer - to put everything on Github (= possibility 2)? git init == To get started, you need to go to your repository with your terminal - e.g. set the working directory with cd Joffrey\\dokumente\\my_project) first - and, then, transform your repository to a Git-Repository by just typing git init into your terminal. git add single_file.txt == After you initialized your repository, you will have an empty git-repository. Git will not track the files in your repository (= untracked files), unless you explicitly point them out via the git add command. If you want to add all files quickly // simultanoeusly: git add . F√ºr genauere Theorie // Erkl√§rung dahinter: Siehe Youtube-Video Coding Train ab 2:10-6:03 git commit -m \"Adding a new comment for my commit\": After having pointed out to Git, which files he needs to track, you can do a commit of the changes of the files you modified, like in possibility 1). Achtung, es gibt einen kleinen Unterschied zu possibility 1): das -a (siehe oben) ist verschwunden, weil wir hier add und commit als zwei separate Schritte betrachten. git remote add origin https://github.com/joffreymayer/new-repo = Because our repository is still currently not on Github, we first need to go on the Github Website and create an empty repository. After having done this, you need to tell Git - with the command git remote add origin + copy-pasting the URL ‚Äúhttps://github.com/joffreymayer/new-repo‚Äù - that this is our local Check if it worked: Type the following into the Terminal git remote -v. It should output the variable name - usually called origin - Note if you want to be fancy: Within git remote add origin, the name origin can be changed to any word you like. This is just the variable name in which your Github-URL will be stored. If there is already a remote with the default name origin but you don‚Äôt like the name, you can change the name by: git remote remove origin ‚Äì&gt; this will delete the remote git remote -v ‚Äì&gt; just to check if step 1) worked ‚Äì&gt; should not output anything git remote add noob https:\\\\github.com\\project-1 ‚Äì&gt; now, re-name the remote and call it noob git push origin master == Finally, you will be able to put all your files into the freshly made remote-repository on Github. git pull origin master == Assume that you did changes remotly on Github but not yet locally on your computer. This does not matter, since you can just enter the command git pull origin master to be able to retrieve the changes that you did remotly on Github onto your local computer =) 1.5.3 Working with Branches Tutorial for branches? Look at youtube-videos from Coding Train. git branch new_branch == this will create a branch locally on your computer git checkout new_branch == this will tell Git: ‚Äúah, he wants to go into the branch called ‚Äònew_branch‚Äô‚Äù. git branch == this will give you a list of all the branches you ave created locally. Furthermore, it will tell you on which branch you currently work on. How to merge the changes you made on a separate branch to the master-branch (= main branch)? git branch new_branch == this will create a branch called new_branch locally on your computer. git checkout new_branch == You will tell Git: ‚ÄúI now want to work on this newly created branch called ‚Äònew_branch‚Äô‚Äù. git checkout master == After you are happy with the changes you did in new_branch you will need to prepare for the merging by switching to your main-branch, which is the master-branch. git merge new_branch == Since you currently are in the master-branch, Git will know that you want to merge new_branch into the master-branch. That was it üòé 1.6 LaTeX This bookdown is created via a .Rmd-File. For a Markdown to be able to read some mathematical formulas, we will need the LaTeX-language. 1.6.1 What is the LaTeX-Code for \\(\\hat{y}\\)? Simply type: $\\hat{y}$ 1.7 W√∂rterbuch 1.7.1 Data Science VS. mein Economics-Studium Was ist der Unterschied zwischen einem Data Scientist VS. was ich in meinem Economics-Studium gemacht habe? Erkenntnis: Machine Learning wird als eine ‚ÄúBlack Box‚Äù betrachtet, wo man den X-Variablen des Modells keine grosse Beachtung schenkt: man bringt sie einfach ins Modell rein. Im Kontrast dazu, sind √ñkonomen mehr dazu getrimmt, mit Hilfe eines theoretischen Modells, die ‚Äúrichtigen‚Äù X-Variablen zu selektieren. 1.7.2 IDE explained What is an IDE? Abk√ºrzung: IDE == Integrated Development Environment Definition: An integrated development environment (IDE) is software for building applications. It combines common developer tools into a single graphical user interface (GUI). Example: R, PyCharm oder Visual-Studio Code are all IDEs. Think of it as a modern Dream Weaver! :) Was ist IDE PyCharm? Das ist das RStudio von Python. 1.7.3 Restful API What are Rest APIs? Synonym: Restful APIs Defintion: API stands for Application Programming Interface. An API is a contract that allows a developer (= you) to interact with an ‚Äúapplication‚Äù (= a database // the object of interest) through a set of ‚Äúinterfaces‚Äù (= list of URLs // this is how you are able to interact with the ‚Äúapplication‚Äù, which can be an App, a library in R / Python or a Database). Quelle: Pokemon-API Zusammengefasst in meinen Worten: Ein API sind Befehle, die du gibst, um mit einer Datenbank (z.B. auf einem Server) zu kommunizieren oder ein Package (in R oder Python) zum runnen zu bringen. Ganz einfach xD Background Client-Server Architecture: most of the applications these days, follow this architecture. Client == App itself == Front-End Server == Back-End Communication between the Sever &amp; the Client (= App) happens via API by using the Http Protocol. Example: if the App wants to access the particular data of a customer, it sends a request to the server via http-protocol. So, when does the Rest API comes into play? ‚Äì&gt; the Rest API is a standard that established itself in the industry, when communaction between client &amp; server ‚Äì&gt; these are the CRUD Operations, which are by definition: GET == getting the data from the server POST == creating data PUT == updating data DELETE == deleting data 1.7.3.1 API Example Beispiel eines API in Python? Das Modul // Package sktime verwendet einen √§hnlichen API, wie die ber√ºhmte Machine-Learning sklearn-Library. Hierbei w√§re der Programmierer (= Du) als Forecaster verstanden, welcher via sogannten methods (zum Beispiel die fit-method, um das Modell zu trainieren // estimaten) mit der application (= hier: Python) interagiert. 1.7.4 Magic Commands in Python ‚ÄúMagic Commands‚Äù in Python, mit denen du unglaublich schnell herausfinden kannst, was eine Funktion √ºberhaupt tut UND welche Inputs in eine Funktion geh√∂ren? shift + Tab ‚Üí wenn du nicht weisst, was eine Funktion // Method tut Tab ‚Üí innerhalb einer Funktion, um eine √úbersicht zu allen Inputs zu erhalten! xD 1.7.5 Pipe-Operator in R What is the Pipe-Operator in R and what does it do? The Pipe-Operator in R looks like this: %&gt;%. It takes in an input and ‚Äútransports‚Äù it into another function to use the input and produces an output. This verbal explanation can be best illustrated via a code-example in R: library(tidyverse) result &lt;- mtcars %&gt;% group_by(cyl) %&gt;% summarise(meanMPG = mean(mpg)) Quelle: A Guide to the Pipe in R 1.7.6 Docker Was ist Docker und was ist der Vorteil davon? Docker ist ein Virtual Environment, welches - wie ein Container - dir Punktgenaue Versionen von bestimmten Packages und Programmiersprachen (Python etc.) liefert. Docker l√§uft √ºber Open Shift, welches eine Art Management-Programm f√ºr Docker ist (so viel ich das verstanden habe‚Ä¶). Wichtig zu wissen ist, dass JEDES Data Science Kit Notebook ein Docker-Container ist, welcher auf Open Shift l√§uft. Dies hat den Vorteil, dass jedes dieser Notebooks auf jeder Maschine ge-runnt werden kann, ohne das Error-Problemen wegen aktualisierten Libraries zu begengnen. 1.7.7 Data Pipeline Was ist eine Data-Pipeline? After streaming your data (in real time) // downloading your data from a provider, it‚Äôs basically a way to automate the process of data cleaning in order to be able to get the plots // models from your ‚Äúdirty data‚Äù in a fraction of the time you would spend, if you would do the data cleaning ‚Äúby hand‚Äù yourself. Youtube-Video: What is a Data-Pipeline? 1.7.8 Fundamental-Daten Was versteht man unter Fundamental-Daten? Fundamental-Daten sind effektiv messbare Daten, die √ºber Datenbanken accessible sind und welche als Proxy - beispielsweise in Regressions-Analysen - verwendet werden k√∂nnen. 1.7.9 Data-Flow Was versteht man unter dem Data Flow? Mit dem Data Flow sollen folgende Fragen beantwortet werden: Welche Daten werden wo geholt &amp; wieso? Wie werden die Daten anschliessend verarbeitet? Was ist der End-Output, nachdem die Daten - beispielsweise - in einem ML-Modell verwedet wurde? Zur Illustration des Data Flows, gab es hierzu im Wissensaustausch auch eine Bild: Beispiel zum Data Flow 1.8 Synonyme 1.8.1 Data Science batch = sample-size when you train your model with a dataset Granularit√§t (Beispiel) = Angenommen, man m√∂chte wissen, wie viele Tage, Stunden, Minuten und Sekunden innerhalb von 20‚Äô044 Sekunden enthalten sind ‚Üí hier haben wir also Granularit√§t von 4 ‚Üí L√∂sung: 4 Tage, 18 Stunden, 37 Minuten, 44 Sekunden Kalibrierung des Modells == Wie wurde das Modell programmiert im Allgemeinen? ‚Üí Dazu geh√∂rt - bei uns - die Anpassung der Prognose. label == true y-value Pop == ‚ÄúPop‚Äù is simply a word that means ‚Äúto drop something‚Äù. For example, df.pop('date') means that I am dropping the column called ‚Äúdata‚Äù from a dataframe called ‚Äúdf‚Äù. Fancily, if you write df.pop('date') and save it into another variable, then you can only select this dropped column from the ddset. Example: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html relativ zu == im Verh√§ltnis zu shape == dimension target == predicted y-value Treiber == x-Variablen Volume == Speicherplatz weights == estimated coefficients 1.8.2 Machine Learning \"feed in\" == plug in (‚Äì&gt; h√§ufig im Zusammenhang mit Einsetzen von konkreten Werten f√ºr die x-Variablen in das gesch√§tzte Modell, um Predictions zu erhalten) instance == value within a cell == konkreter ‚Äúx‚Äù-Wert, welcher angenommen wird und du - beispielsweise - f√ºr eine Prediction verwenden kannst. Forcasted data == These are the predictions that you do via the help of a model (‚Äì&gt; by plugging in concrete x-values), that you‚Äôve built. Training Dataset // Training Set == This is the sample, that you use to estimate your model. Testing Dataset // Test Set == This is the hold out set, which you use at the end, to check whether your model is able to generalize // extrapolate well to new data. \"the model is learning == what is meant by ‚Äúlearning‚Äù is: given some Datenpunkt-Wolke, the computer will try and fit the ‚Äúbest line‚Äù [oftentimes by minimizing the sum of the squared residuals, if you use OLS (= Ordinary Least Squared)] to construct the ‚Äúbest model‚Äù possible. Training == You are estimating a model on the trainig-dataset, such that the model ‚Äúlearns‚Äù from the data. shuffle == englisches Wort f√ºr ‚Äúmischen‚Äù. In the context of splitting the dataset into test- &amp; training-data, it is common practice to shuffle your observations within your dataset first. Reason why you shuffle?: Shuffling data serves the purpose of reducing variance AND making sure that models remain general AND overfit less. Merke: When dealing with time series, you should not use shuffle when splitting the data into training- &amp; testing-data. training score // Test Error == This error // score is the [oftentimes squared] difference between the true y-variable and estimated // predicted y-variable and measures // evaluates how well the model is ‚Äúperforming‚Äù // how good the model is on a test set with an increasingly bigger training dataset. cross-validation score // Validation Error == This is the (mean) error // score [because of cross-validation] that measures // evaluates how the model is ‚Äúlearning‚Äù over increasingly bigger training datasets. fold == subset of the training dataset Example: In a K-Fold Cross-Validation, you randomly split the training set into 10 distinct subsets, which are called folds. samples == number of rows // number of observations within a dataset. classifiers == These are simply regression-functions, where the Y-Variable is binary, e.g. die Y-Variable kann nur Y = 0 ODER Y = 1 als Werte annehmen. Example: Logit- &amp; Probit-Regression, or Naiv Bayes, etc‚Ä¶ initialization // declaration // specification == This is the assignment of an initial value for a data object or variable. Array == A List of Data is an array. It is a data structure, which contains ‚Äún‚Äù objects within a list. Quelle: The Coding Train 3:10-3:22 Extrapolation == Voraussage von Y-Predicted Values, welche mittels X-Variablen ermittelt werden, welche zuvor nicht im Datensatz waren. Interpolation == Voraussage von Y-Predicted Values, welche mittels X-Variablen ermittelt werden, welche bereits im Datensatz waren, als die Sch√§tzung get√§tigt wurde. sliding window == This is just a way to tell python how to do a cross-validation and have equal lengths of time series where we can learn on. Learning Task == Forecasting Task // Extrapolation [in Time Series] Forecasting Horizon == Time Points, you want to predict (= dein ) \\(\\hat{y}\\) Time Heterogenous Data == Different Time Series have different time stamps Quelle: Ab 27:05 (Link: http://www.youtube.com/watch?v=Wf2naBHRo8Q&amp;t=27m05s) Seasonal Periodicity == The number of months per year, in which the forecaster expects to see a seasonal pattern. Concrete Example: In Philipp‚Äôs Notebook, he had a seasonal periodicity of 2, e.g. he said that in winter &amp; sommer, he expects a seasonal pattern. Reduction is composable ‚Üí Synonym w√§re ‚Äúaddieren‚Äù ‚Üí E.g. you can split a difficult task into a bunch of smaller tasks (= reduction) and ‚Äúadd‚Äù them together to solve the bigger task at the end (= ‚Äúreduction is composable‚Äù). Pearson Korrelation == Lineare Korrelation Grid ‚Üí Das ist nichts anderes als die Optimierung von diversen ‚ÄúModell-Parametern‚Äù. - Beispiel: Bei Random-Forrest Modellen kann man zum Beispiel die Tiefe eines Modells bestimmen, dh die relevante Frage, welche ein Forscher sich stellt, ist, wie viele Baum-Zweigungen die geeignesten Predictions bringen? Mit Funktionen, wie zum Beispiel GridSearchCV() kann dieses Problem geregelt werden. Classifier == These are simply Regression-Functions, where the Y-variable is binary, e.g. die Y-Variable kann nur Y = 0 oder Y= = 1 als Werte annehmen. Beispiele: Logit-Regression Probit-Regression Naive Bayes etc‚Ä¶ 1.8.3 Python Module == Python-File PyPA == Python Packaging Authority PyPI == Python Package Index 1.8.4 IT &amp; Software-Development Abh√§ngigkeitsprobleme == 1) Probleme bei den Versionen des Packages; 2) Packages werden vorausgesetzt, sodass gewisser Code dann einen Error printed, wenn man ihn nach 2 Jahren wiederverwenden will. agnostisch == Im IT-Umfeld hat das Wort agnostisch eine besondere Bedeutung. Es bezieht sich auf etwas, das soweit verallgemeinert wird, dass es auch unter verschiedenen Umgebungen funktionieren kann. Beispiel: Eine Plattform-agnostische Software l√§uft unter jeder Kombination aus Betriebssystemen und Prozessorarchitekturen. cached == store away for future use Client == Damit ist h√§ufig der Browser gemeint, wenn er Abfragen an den Server gibt. composite == custom Remote == Das ist z.B. ein Server / eine Maschine, die du nicht lokal bedienst. Rest API == Restful API instanziieren == Das Erzeugen eines Objekts in der objektorientierten Programmierung. 1.9 Projekt-Management Sitzungen m√ºssen gut dokumentiert werden! Insbesondere ist hervorzuheben, in welche Richtung das Projekt geht. 1.9.1 Meetings Was ist das Ziel eines Meetings? Das Ziel des Meetings ist es, dir &amp; deinem Team die n√∂tige Basis zu geben, damit du in der folgenden Zeit bis zum n√§chsten Meeting genau weisst, was du zu tun hast. Am wichtigsten ist hier mit dem ‚ÄúBoss‚Äù zu reden und klar definieren, was er erreichen will im Projekt. Dies gibt die globale Richtung des Projektes an. Es ist exterm wichtig, mit dem Boss diese Ziele zu definieren, da die Planung des gesamten Projektes in dieser Phase hier noch definiert werden kann. Nachdem diese anf√§ngliche Gliederung get√§tigt wurde, kann im Verlauf des Projektes nicht mehr viel davon abgewichen werden. Deshalb h√§ngt die Gesampt-Performance eines Projektes sehr stark von der anf√§nglichen Planung ab! W√§hrend des Projektes gibt es dann immer wieder folgende Punkte zu pr√ºfen: Sind die get√§tigten Schritte im Einklang mit dem Endziel des Bosses? Wichtig ist zu rechtfertigen, was du gerade am tun bist und warum genau du das tust. Aufkl√§rung, damit alle auf dem gleichen Informationsstand sind Goal: Wo stehen wir? Wie sieht die Situation mit dem Notebook aus? Gibt es noch offene L√ºcken im Wissen eines Team-Mitglieds, welches von anderen Mitarbeitern gedeckt werden m√ºsste? ‚Äì&gt; Goal: Kein Mitglied isolieren, jeder muss sich integriert f√ºhlen. Insbesondere Wert auf Papers &amp; Daten setzen hier Was sind weitere offene Optionen und inwiefern eignen sich diese Ans√§tze f√ºr unser Ziel? Goal: Aufzeigen, dass wir noch weitere Alternativen haben, als nur Phillip‚Äôs Notebooks Sonstige Unklarheiten / Bemerkungen / Inputs / Vorschl√§ge? ‚Äì&gt; Goal: letzte Informationsasymmetrien beheben Was ist ein Kanban? In der BWL-Sprache ist Kanban ein Vorgehensmodell zur Softwareentwicklung. Ziel #1: Das Meetings soll die Anzahl an paralleler Arbeiten, (= der Work in Progress (WiP)) minimiert // begrenzt werden und somit k√ºrzere Durchlaufzeiten erreicht. Ziel #2: Das Meeting soll die Probleme ‚Äì insbesondere Engp√§sse ‚Äì schnell sichtbar machen. "],["foundations-of-data-science.html", "Chapter 2 Foundations of Data Science 2.1 Questions you need to answer when starting a new Project 2.2 Effective Research: How to find answers quickly? 2.3 How to read Notebooks from other People? 2.4 Machine-Learning Theory 2.5 Programming Theory 2.6 Statistics-Theory 2.7 Appendix for the Future", " Chapter 2 Foundations of Data Science In meinem Data Scientist Job werde ich h√§ufig auf √§hnliche Probleme stossen mit der Zeit. Hier habe ich eine Reihe an Fragen aufgelistet, welche ich f√§hig sein muss, zu beantworten, wenn ich effizient in meinem Beruf sein will! 2.1 Questions you need to answer when starting a new Project BEFORE you start writing your R-Scripts or Jupyter-Notebooks, you first need to think about several key-things &amp; -questions: - Welche Datenbasis haben wir? - Was ist das Prognoseobjekt? - Welche Metrik hast du in deinen Notebooks verwendet? - Wie ist das Trainings- &amp; Validierungs-Dataset aufgebaut? - Welche Daten sind im Test-Set, welche f√ºr den Benchmark verwendet werden? - Welche Prognoseans√§tze wurden angewendet? - Welche Daten sind effektiv genutzt &amp; welche sind verf√ºgbar? - Etc‚Ä¶ Datenbasis // Woher kommen die Daten?: ENTSOE exklusiv. Das ist der Dachverband der TSO (kennen Nachfrage und Angebot) Prognoseobjekt (= y-dach): St√ºndliche EUR/kWh f√ºr Folgetag. Metrik: Zeigt, wie gut das Modell ‚Äúlernt‚Äù (= training error) &amp; ‚Äúgeneralisiert‚Äù // exrapoliert (= generalization error). Im Notebook von Philipp werden 2 verschiedene Metriken verwendet, n√§mlich: - Mean Absolute Error, sowie - [Root] Mean Squared Error. Training Dataset: Daten von 2019. Validation Dataset: Random choice of 20% of the hours within this year. Mit welchem true y-value werden die Predictions verglichen? // Was ist der Benchmark? // Test-Set: EFFEX Spotpreise benutzt f√ºr Benchmark // true [y-]values. Struktur [der Analyse]: Output: Day ahead Strompreis CH Input: jeweils 24h f√ºr ca. 20 Pr√§diktoren. Reshape: K dimensionen = #Prediktors x 24h Was ist die Daten-Imputation Methode?: Missing Values mit Mittelwerten 2.2 Effective Research: How to find answers quickly? How to find Answers quickly, especially when a Concept is complicated Aus Erfahrung weiss ich jetzt, dass Youtube bisher immer, die beste Quelle war, um mir etwas schnell &amp; effizient beizubringen. Twitter-Community von Wissenschaftlern sind ebenfalls sehr wertvoll. Als Beispiel w√§re dieser Twitter-Post vom Prophet-Gr√ºnder. 2.3 How to read Notebooks from other People? Es geht am Anfang um die Gesamt√ºbersicht und noch nicht um die Details // Eigenheiten im Code oder im Datensatz! Am wichtigsten ist es, dass du diese Fragen zun√§chst beantworten kannst, wenn du das Notebook liest. 2.4 Machine-Learning Theory 2.4.1 Difference between Training-, Validation- &amp; Test-dataset Since I started with Machine Learning, I was always confused about the concept of data splitting, e.g. which sub-set of the entire dataset is now considered to be the training dataset, which one is the validation dataset and which one is the testing dataset. In the graph below, you see how it is defined correctly: Training Set VS. Validation Set VS. Test Set Important to note: There is oftentimes confusion between the definition of validation dataset VS. testing dataset, because there is no consens about it. Therefore - and if we take the above picture as the ‚Äútrue‚Äù definition - some people will call the validation dataset the ‚Äútest dataset‚Äù and vice versa, e.g. the test data as the ‚Äúvalidation data‚Äù! xD 2.4.1.1 Validation-Set VS. Test-Set What is the difference between a Validation Dataset and a Testing Dataset? Es gibt keinen Konsens daf√ºr, was nun das validation dataset und welches das test set genau ist. Nima (= mein Mentor bei der SBB) verwendet den Begriff test set f√ºr dasjenige Dataset, welches hold out // separat f√ºr die (sp√§tere) Prediction verwendet wird. Regel zu Unterscheidung der beiden Terme: Wenn steht: we hold out [name of the set], dann ist es das testing dataset. 2.4.1.2 Reason for a Validation-Set Why do we need validation set? At the end, you want the best model possible. If you want to tune your hyperparameters, you will need your test set. The big problem here, however, is that - if we use the test-set more than once when wanting to find out the best hyperparameters - our model will know the data by heart and the predictions will be too good, but only on this dataset that you are currently using! The model will not generalize well on new data. That‚Äôs why we need this additional subsetting of the training-dataset! 2.4.2 Concept of Stratification Angenommen du hast eine kategorische Y-Variable, welche entweder Nullen oder Einsen als Werte annimmt. Nehme nun an, dass - im Training-Dataset - der Anteil der Nullen 60% betr√§gt. Wenn du nun ein stratified Sample willst, dann wird das Test-Dataset ebenfalls einen Anteil von 60% an Nullen enthalten! Quelle: Train-Test-Split in Sklearn and Cross-Validation 2.4.3 Cross-Validation The concept of cross-validation can be splitted into 2 parts: Step 1: Split your dataset into 1 training- &amp; 1 test-set. Rule of Thumb: Usually, the split is 70-90% training set and 10-30% for the test-set. Code Example: Example of Code for Train-Test Split Step 2: Now, we divide the training set further, such that it will contain - if we assume a 3-fold cross-validation as an example - 3 different validation sets and 3 training sets. Allgemeine Cross-Validation 2.4.3.1 Special Case: Cross-Validation for Time-Series Data Because time-series are ordered, since the flow of time is only going forward, the graph shown above for step 2 is not valid and we need another approach: 2.4.3.2 Why do we use Cross-Validation? There are 2 reasons: It allows us to compare the score (MAPE, MAE or RMSE) of different model set-ups, for example: CV-Scheme changes, e.g. a Time-Series Prophet-Model with a Sliding-Window of 4 Months VS. a Prophet-Model with an Expanding-Window (full past). OR changes in the covariates, e.g. a model that includes an important covariate, while the other model does not. This will allow you to draw conclusions regarding the selection of ‚Äúthe best‚Äù model. It allows you to assess the performance of different machine-learning methods. In a classification-setting for example, you can use the confusion-matrix. Cross-Validation for Time Series This picture shows an example of a 3-fold cross-validation for a time-series. 2.4.4 Normalisierung der Daten Was versteht man unter Normalisierung? Was sollte man dabei beachten? Warum wird in einem Pre-Processing Schritt eine Normalisierung durchgef√ºhrt? Normalisierung == Subtrahiere den Mittelwert und dividiere durch die Standardabweichung jedes Merkmals. Es sollte beachtet werden, dass der Mittelwert und die Standardabweichung nur anhand der Trainings-Daten berechnet werden sollte, damit die Modelle keinen Zugriff auf die Werte in den Validierungs- und Tests√§tzen haben. Es ist wichtig, Features zu skalieren, bevor ein neuronales Netzwerk trainiert wird. Normalisierung ist eine g√§ngige Methode f√ºr diese Skalierung. 2.4.5 RNN Was macht ein Reccurrent Neural Network (RNN)? Ein Beispiel f√ºr ein RNN w√§re ein Long Short Term Memory Modell (LSTM Modell). Dabei nimmt das RNN zun√§chst ein ganz kleines Vergangenheits-Intervall, macht eine Modell-Estimation und dann - im n√§chsten Schritt - wird ein gr√∂sseres Vergangenheits-Intervall verwendet (inkl. predicted Y-Variable aus dem vorherigen Modell), um eine neue Modell-Estimation zu machen etc. Beispiel eines RNN: hier ein LSTM 2.4.6 Data-Pipelines How to create good Data-Pipelines in Scikit-Learn? Ziel von Data-Pipeline: Write more clean // readable code, especially when you do data cleaning. A datapipeline is basically a way of standardizing your code. Warum sind Data-Pipelines so geil?: Because you can compare many different regression-models (Linear-Regression Vs. Logistic-Regression Vs. RandomForrest ‚Ä¶), applying different ‚Äúscaling-techniques‚Äù (= normalize a variable with mean 0 and standard-deviation of 1), as well as using ‚Äúdata cleaning techniques‚Äù (= reduce dimensions via PCA, reduce missing-values etc‚Ä¶). Another cool thing to note is, that you can choose the order, in which the cleaning, scaling and fitting occures! See also the summary of the guy on Youtube ab 10:00-11:00. Link to Github for an example: Jupyter-Notebook code-example on how to create a little Data-Pipeline by yourself 2.5 Programming Theory 2.5.1 Data-Types In R oder Python ist es wichtig zu verstehen, dass gewisse Funktionen nur dann funktionieren, wenn die Inputs, die wir in die Funktion eingeben wollen, einen bestimmten Data-Type aufweisen m√ºssen. On the website W3-Schools, I found this extremely good overview of all data-types, which is crucial concept to understand when doing data cleaning. Data-Types are a key-thing to understand. Otherwise, you won‚Äôt be able to apply some algorithms on your dataset! 2.5.2 Global Variables VS. Local Variables Variables that are created outside of a function are known as global variables. Global variables can be used by everyone, both inside of functions and outside. Example of a global variable: x = &quot;awesome&quot; def myfunc(): print(&quot;Python is &quot; + x) myfunc() &gt;&gt;&gt; Python is awesome In contrast, if you create a variable with the same name inside a function, this variable will be local, and can only be used inside the function. The global variable with the same name will remain as it was, global and with the original value. Example of a local variable: x = &quot;awesome&quot; def myfunc(): x = &quot;fantastic&quot; print(&quot;Python is &quot; + x) myfunc() print(&quot;Python is &quot; + x) Output of this: click here 2.5.3 Array What is an array? An Array is a List of Data. In a DataFrame-Object, you can think of a column or a row to be arrays. It is a data structure, which contains ‚Äún‚Äù objects within a list. - Quelle: The Coding Train 3:10-3:22 2.6 Statistics-Theory 2.6.1 P-Hacking Was ist p-hacking? In der Statistik gibt es den p-Wert ein: Man nimmt an die Hypothese sei wahr und berechnet dann die Wahrscheinlichkeit, dass die beobachtete Statistik mindestens so extrem ausfallen w√ºrde (f√ºr die Gegner von Wischi-Waschi hier die Wikipedia-Definition). Falls diese Wahrscheinlichkeit unter 5% liegt, dann sei das Resultat ‚Äústatistisch signifikant‚Äù (yay!) und die Nullhypothese kann verworfen werden, was oftmals die Absicht ist. Das Problem ist nur: Hypothesen gibt es viele und z.T. auch recht √§hnliche. Wenn man genug Hypothesen aufstellt - vor allem, nachdem man sich die Daten angeschaut hat - dann ist es durchaus m√∂glich, dass man ein statistisch signifikantes Resultat erh√§lt, unabh√§ngig davon, ob das Resultat tats√§chlich auch stimmt. Das nennt man p-Hacking. Es kommt h√§ufig in der Forschung vor, aber es kommt sicher auch in der SBB vor (dennoch hier eine +1 f√ºr Hypothesen-basiertes arbeiten!). Wie einfach man in die ‚Äúfalsche Signifikanz Falle‚Äù tappen kann, wird h√ºbsch in dieser Gallerie falscher Korrelationen illustriert. 2.7 Appendix for the Future Welche Zeitperiode sind am geeignetsten f√ºr Zeitreihenanalysen mit Machine Learning? "],["python-libraries.html", "Chapter 3 Python Libraries 3.1 List of Useful Python-Libraries 3.2 Necessary Foundations 3.3 Time-Series Forecasting", " Chapter 3 Python Libraries 3.1 List of Useful Python-Libraries 3.1.1 Put a time-stamp on each Python-Cell The ipython-autotime library is particularly useful to get an overview of how long each Python-Cell takes to be executed. You can even use it for debugging in combination with the datetime-library in order to use print()-statements that gives you the run-time of - for example - each model-fiting iteration (in a loop). 3.1.1.1 Installation To install this wonderful pip install ipython-autotime 3.1.1.2 Activation It uses a Python Magic-Command in order to be able to use this library: %load_ext autotime 3.2 Necessary Foundations 3.2.1 Pandas 3.2.2 loc- VS. iloc-Selection loc &amp; iloc are the ‚Äúaccessor operators‚Äù in the pandas-library. With these,, you can select rows and columns in your dataframe: For loc: Based on the name of the rows (= row-label // row-index) and columns. For iloc: Based on the position // where the specific rows &amp; columns are within the dataset. 3.3 Time-Series Forecasting Here, I will explore different libraries that will allow you to make forecasts into the future. 3.3.1 Facebook Prophet Aus einer didaktischen Perspektive ist die offizielle Dokumentation der Prophet-Library wunderbar, um die Unterschiede zwischen R &amp; Python (Objekt-Orientierte Programmierung) zu entdecken. Link zur offiziellen Dokumentation: https://facebook.github.io/prophet/docs/quick_start.html 3.3.2 SkLearn In some functions, you will need to set the option random_state. If you want reproducible results, how do you need to handle random_state? Just set random_state to an integer. Dieser integer kann beliebig gew√§hlt werden, das ist SkLearn egal! 3.3.3 SkTime 3.3.3.1 SkTime API √úberischt zum API in sktime? Grunds√§tzlich verwendet sktime fit-, predict-, und transform-class-methods. Um zu verstehen, was dies genau bedeutet, hier eine globalere √úbersicht mit Hilfe einer Visualisierung veranschaulicht: API of sktime For estimator classes (a.k.a. model classes), sktime provides: a fit-method (= goal: training // estimating the model) and a predict-method (= goal: generate new predictions). For transformer classes, sktime provides: various fit-methods, various transform-methods to transform data that comes in series. 3.3.3.2 Reduction What does it mean: ‚ÄúReduction is composable‚Äù? Ein Synonym w√§re: ‚Äúaddieren‚Äù ‚Üí E.g. you can split a difficult task into a bunch of smaller tasks (= reduction) and ‚Äúadd‚Äù them together to solve the bigger task at the end (= ‚Äúreduction is composable‚Äù). 3.3.3.3 Forecasting-Horizon Welche Arten von Forecasting-Horizon gibt es? Es gibt einen relativen forecasting-horizon (FH), dh ‚Äúrelativ‚Äù zur Trainings-Periode ist hier gemeint! Es gibt auch einen absoluten FH. Hier werden die absolute time-points in the future verwendet f√ºr die Prediction. Quelle: Im ‚Äúexamples‚Äù-Repository auf Github zur Sktime-Library &gt; 01_forecasting.ipynd 3.3.3.4 Train-Test Split What do you need for parameters // inputs to write a train-test split function for time series data? You need 3 arguments // inputs for such a function in time series: the data the window length, e.g. how many periods the training dataset should have. the length of the forecasting horizon, e.g. how many periods into the future our validation-period go. Quelle: Youtube-Video ab 46:25 3.3.3.5 Konkurrenz-Libraries f√ºr Time-Series What are other useful libraries when working with Time Series in Python? Besides Sktime, there are 5 other libraries in Python which you can use for different purposes: Stop this Video at 5:35 um zu sehen, f√ºr welche Zwecke sie sich am besten eignen. 3.3.3.6 Example on Github In the example Repository on Github, was ist die Einheit der y-variable in 01_forecasting.ipynd? Einheit der y-Variable: in Monate "],["visualization.html", "Chapter 4 Visualization 4.1 Graphs with Python", " Chapter 4 Visualization When you analyze data, it is crucial to communicate with simplicity what evidence you found. Therefore, this chapter will focus on how to bring your evidence to your audience. 4.1 Graphs with Python When you work with Python, there are three main libraries you need to know: seaborn, which can plot extremely beautiful graphs, without much efforts. matplotlib, for more advanced stuff, this is the library you need to master. plotly, for implementations into websites. Noob. 4.1.1 Seaborn 4.1.1.1 Draw a Time-Series (= Line-Chart) A line-chart is often used to visualize a trend in the data over time. import seabron as sns sns.lineplot(data = spotify_data) 4.1.1.2 Draw a Barplot (= Barchart) import seabron as sns sns.barplot(x = data.Racing, y = data.index) 4.1.1.3 Draw a Heatmap import seabron as sns sns.heatmap(data = flight_data, annot = True) 4.1.1.4 Draw a Scatterplot (Streudiagramm // Punktwolke) You can check, whether you have enough variation in your data to predict the dependent variable. 4.1.1.4.1 With 2 variables (incl. regression-line) import seabron as sns sns.scatterplot(x = health_data[&#39;bmi&#39;], y = health_data[&#39;life_expectancy&#39;]) # include a regression-line: sns.regplot(x = health_data[&#39;bmi&#39;], y = health_data[&#39;life_expectancy&#39;]) 4.1.1.4.2 With 3 variables, where 2 are continuous &amp; 1 is categorical import seabron as sns sns.scatterplot(x = health_data[&#39;bmi&#39;], y = health_data[&#39;life_expectancy&#39;], hue = health_data[&#39;smoker&#39;]) # include a regression-line: sns.lmplot(x = health_data[&#39;bmi&#39;], y = health_data[&#39;life_expectancy&#39;], hue = health_data[&#39;smoker&#39;]) # note that it is not the same, as when you used 2 variables! 4.1.1.5 Draw a Histogram A histogram sorts the data, then it is putting the data into intervalls of data (= batches) and finally counts the frequency those batches occur. Useful to check the distribution of the data 4.1.1.5.1 Discrete Version import seabron as sns sns.distplot( a = iris_data[&#39;Petal Length (cm)&#39;], # a column you would like to plot label = &quot;Rose&quot;, kde = False # &quot;Kernel Density Estimate&quot; (kde): always provide this input when creating a histogram ) 4.1.1.5.2 Continuous Version (Kernel Density Estimate) import seabron as sns ### ---- Standard KDE-Plot sns.kdeplot( data = iris_data[&#39;Petal Length (cm)&#39;], shade = True # colors the area below the curve ) ### ---- 2-Dimensional KDE-Plot, when using more than 1 column sns.jointplot( x = iris_data[&#39;Petal Length (cm)&#39;, y = iris_data[&#39;Septal Width (cm)&#39;], kind = &quot;kde&quot; ) 4.1.1.6 Change Style of different Seaborn-Plots Key:Set the new style BEFORE you run your code for the actual graph! import seabron as sns ### ---- Example for changing the colors // styles with a new style &quot;dark&quot;: sns.set_style(&quot;dark&quot;) # Possibile styles to choose from: {&quot;darkgrid&quot;, &quot;whitegrid&quot;, &quot;dark&quot;, &quot;white&quot;, &quot;ticks&quot;} 4.1.2 Matplotlib 4.1.2.1 Set Width &amp; Height of Graph import matplotlib.pyplot as plt plt.figure(figsize=(10,6)) # 1. width, 2. height 4.1.2.2 Set title of Graph import matplotlib.pyplot as plt plt.title(&#39;Hello World&#39;) 4.1.2.3 Set Label of Axes import matplotlib.pyplot as plt plt.ylabel(&#39;Average Gaming Score&#39;) plt.xlabel(&#39;Date&#39;) 4.1.2.4 Force Legend to appear import matplotlib.pyplot as plt plt.legend() "],["improve-yourself-constantly.html", "Chapter 5 Improve Yourself Constantly 5.1 To Share", " Chapter 5 Improve Yourself Constantly Like everything in Software and Informatics: you constantly need to acquire new skills to get the job done. Here, I listed different examples of what you will need to master, in order to improve yourself as a data-scientist: Git Cheat-Sheet? PDF zum Git Cheat-Sheet: klicke hier Twitter crawler via R? Link zur Webseite Monte-Carlo Simulation explained &amp; how to implement in Python? Link zur Webseite How to create a ‚Äûreproducable example‚Äú in order to post it on Stackoverflow? Link zur Webseite 5.1 To Share Create a Website (Hugo): Link zur Webseite "]]
