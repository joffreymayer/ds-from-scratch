<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Machine Learning | Data Science from Scratch Code</title>
  <meta name="description" content="Chapter 9 Machine Learning | Data Science from Scratch Code" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Machine Learning | Data Science from Scratch Code" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Machine Learning | Data Science from Scratch Code" />
  
  
  

<meta name="author" content="Joffrey Anthony" />


<meta name="date" content="2022-05-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="econometrics.html"/>
<link rel="next" href="mengenlehre.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DS from Scratch Codes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Computer Set-Up</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#mac-tricks"><i class="fa fa-check"></i><b>1.1</b> Mac Tricks</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#öffne-die-developer-tools-von-google-chrome"><i class="fa fa-check"></i><b>1.1.1</b> Öffne die Developer-Tools von Google-Chrome</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#speichern"><i class="fa fa-check"></i><b>1.1.2</b> Speichern</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#speichern-unter"><i class="fa fa-check"></i><b>1.1.3</b> Speichern Unter</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#finder"><i class="fa fa-check"></i><b>1.1.4</b> Finder</a></li>
<li class="chapter" data-level="1.1.5" data-path="index.html"><a href="index.html#programm-schliessen"><i class="fa fa-check"></i><b>1.1.5</b> Programm schliessen</a></li>
<li class="chapter" data-level="1.1.6" data-path="index.html"><a href="index.html#neuer-ordner"><i class="fa fa-check"></i><b>1.1.6</b> Neuer Ordner</a></li>
<li class="chapter" data-level="1.1.7" data-path="index.html"><a href="index.html#tilde-zeichen"><i class="fa fa-check"></i><b>1.1.7</b> Tilde Zeichen</a></li>
<li class="chapter" data-level="1.1.8" data-path="index.html"><a href="index.html#backslash"><i class="fa fa-check"></i><b>1.1.8</b> Backslash</a></li>
<li class="chapter" data-level="1.1.9" data-path="index.html"><a href="index.html#screenshot-vom-bildschirm"><i class="fa fa-check"></i><b>1.1.9</b> Screenshot vom Bildschirm</a></li>
<li class="chapter" data-level="1.1.10" data-path="index.html"><a href="index.html#teil-des-bildschirms-screen-schoten"><i class="fa fa-check"></i><b>1.1.10</b> Teil des Bildschirms Screen-Schoten</a></li>
<li class="chapter" data-level="1.1.11" data-path="index.html"><a href="index.html#verlauf-löschen-in-chrome-browser"><i class="fa fa-check"></i><b>1.1.11</b> Verlauf löschen in Chrome Browser</a></li>
<li class="chapter" data-level="1.1.12" data-path="index.html"><a href="index.html#verlauf-löschen-safari"><i class="fa fa-check"></i><b>1.1.12</b> Verlauf löschen Safari</a></li>
<li class="chapter" data-level="1.1.13" data-path="index.html"><a href="index.html#bildschirm-aufnahme"><i class="fa fa-check"></i><b>1.1.13</b> Bildschirm Aufnahme</a></li>
<li class="chapter" data-level="1.1.14" data-path="index.html"><a href="index.html#lesezeichen-in-google-chrome"><i class="fa fa-check"></i><b>1.1.14</b> Lesezeichen in Google Chrome</a></li>
<li class="chapter" data-level="1.1.15" data-path="index.html"><a href="index.html#search-console-pop-up"><i class="fa fa-check"></i><b>1.1.15</b> Search Console Pop Up</a></li>
<li class="chapter" data-level="1.1.16" data-path="index.html"><a href="index.html#format-kopieren-einer-zelle-in-numbers"><i class="fa fa-check"></i><b>1.1.16</b> Format Kopieren einer Zelle (in Numbers)</a></li>
<li class="chapter" data-level="1.1.17" data-path="index.html"><a href="index.html#format-übertragen-einer-zelle-in-numbers"><i class="fa fa-check"></i><b>1.1.17</b> Format übertragen einer Zelle (in Numbers)</a></li>
<li class="chapter" data-level="1.1.18" data-path="index.html"><a href="index.html#switch-between-applications-on-your-computer"><i class="fa fa-check"></i><b>1.1.18</b> Switch between Applications on your computer</a></li>
<li class="chapter" data-level="1.1.19" data-path="index.html"><a href="index.html#move-forward-through-tabs"><i class="fa fa-check"></i><b>1.1.19</b> Move Forward through Tabs</a></li>
<li class="chapter" data-level="1.1.20" data-path="index.html"><a href="index.html#zahl-als-exponent"><i class="fa fa-check"></i><b>1.1.20</b> Zahl als Exponent</a></li>
<li class="chapter" data-level="1.1.21" data-path="index.html"><a href="index.html#source-code-einer-webseite-aufschalten"><i class="fa fa-check"></i><b>1.1.21</b> Source-Code einer Webseite aufschalten</a></li>
<li class="chapter" data-level="1.1.22" data-path="index.html"><a href="index.html#interaktive-code-ansicht-für-das-abchecken-von-webseiten"><i class="fa fa-check"></i><b>1.1.22</b> Interaktive Code-Ansicht für das Abchecken von Webseiten</a></li>
<li class="chapter" data-level="1.1.23" data-path="index.html"><a href="index.html#approximate-symbol"><i class="fa fa-check"></i><b>1.1.23</b> Approximate Symbol <code>≈</code></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#virtual-environment"><i class="fa fa-check"></i><b>1.2</b> Virtual Environment</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#create-a-venv"><i class="fa fa-check"></i><b>1.2.1</b> Create a <code>venv</code></a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#activate-your-newly-created-venv"><i class="fa fa-check"></i><b>1.2.2</b> Activate your newly created <code>venv</code></a></li>
<li class="chapter" data-level="1.2.3" data-path="index.html"><a href="index.html#install-packages"><i class="fa fa-check"></i><b>1.2.3</b> Install packages</a></li>
<li class="chapter" data-level="1.2.4" data-path="index.html"><a href="index.html#overview-of-packages"><i class="fa fa-check"></i><b>1.2.4</b> Overview of packages</a></li>
<li class="chapter" data-level="1.2.5" data-path="index.html"><a href="index.html#overview-of-every-venv"><i class="fa fa-check"></i><b>1.2.5</b> Overview of every <code>venv</code></a></li>
<li class="chapter" data-level="1.2.6" data-path="index.html"><a href="index.html#execute-any-python-skript"><i class="fa fa-check"></i><b>1.2.6</b> Execute any python skript</a></li>
<li class="chapter" data-level="1.2.7" data-path="index.html"><a href="index.html#deactivate-the-venv"><i class="fa fa-check"></i><b>1.2.7</b> Deactivate the <code>venv</code></a></li>
<li class="chapter" data-level="1.2.8" data-path="index.html"><a href="index.html#delete-a-venv"><i class="fa fa-check"></i><b>1.2.8</b> Delete a <code>venv</code></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-to-efficiently-manage-a-project"><i class="fa fa-check"></i><b>1.3</b> How to efficiently manage a Project?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#create-a-website-on-github-for-free"><i class="fa fa-check"></i><b>1.3.1</b> Create a Website on Github (for free)</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#r-markdown-syntax"><i class="fa fa-check"></i><b>1.3.2</b> R Markdown Syntax</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#terminal-commands"><i class="fa fa-check"></i><b>1.4</b> Terminal-Commands:</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#aktuelle-position-directory"><i class="fa fa-check"></i><b>1.4.1</b> Aktuelle Position // Directory?</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#showing-the-child-directories-inside-the-directory-you-are-currently-in"><i class="fa fa-check"></i><b>1.4.2</b> Showing the child-directories inside the directory you are currently in?</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#delete-everything-you-wrote-in-your-terminal-up-until-now"><i class="fa fa-check"></i><b>1.4.3</b> Delete everything you wrote in your <code>Terminal</code> up until now?</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#change-directory"><i class="fa fa-check"></i><b>1.4.4</b> Change directory?</a></li>
<li class="chapter" data-level="1.4.5" data-path="index.html"><a href="index.html#creating-a-new-directory"><i class="fa fa-check"></i><b>1.4.5</b> Creating a new directory?</a></li>
<li class="chapter" data-level="1.4.6" data-path="index.html"><a href="index.html#create-a-new-file"><i class="fa fa-check"></i><b>1.4.6</b> Create a new file?</a></li>
<li class="chapter" data-level="1.4.7" data-path="index.html"><a href="index.html#remove-files"><i class="fa fa-check"></i><b>1.4.7</b> Remove files?</a></li>
<li class="chapter" data-level="1.4.8" data-path="index.html"><a href="index.html#open-the-current-directory-you-are-in"><i class="fa fa-check"></i><b>1.4.8</b> Open the current directory you are in?</a></li>
<li class="chapter" data-level="1.4.9" data-path="index.html"><a href="index.html#show-invisible-files"><i class="fa fa-check"></i><b>1.4.9</b> Show invisible Files</a></li>
<li class="chapter" data-level="1.4.10" data-path="index.html"><a href="index.html#terminal-magic-commands-for-being-faster"><i class="fa fa-check"></i><b>1.4.10</b> Terminal Magic-Commands for being faster?</a></li>
<li class="chapter" data-level="1.4.11" data-path="index.html"><a href="index.html#syntax-im-terminal"><i class="fa fa-check"></i><b>1.4.11</b> Syntax im Terminal</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#how-to-activate-use-python"><i class="fa fa-check"></i><b>1.5</b> How to activate &amp; use Python?</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#latex"><i class="fa fa-check"></i><b>1.6</b> LaTeX</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#what-is-the-latex-code-for-haty"><i class="fa fa-check"></i><b>1.6.1</b> What is the LaTeX-Code for <span class="math inline">\(\hat{y}\)</span>?</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#useful-websites"><i class="fa fa-check"></i><b>1.6.2</b> Useful Websites</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#wörterbuch"><i class="fa fa-check"></i><b>1.7</b> Wörterbuch</a><ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#data-science-vs.-mein-economics-studium"><i class="fa fa-check"></i><b>1.7.1</b> Data Science VS. mein Economics-Studium</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#why-data-science-starts-with-data-visualization-the-key-thing-i-learned"><i class="fa fa-check"></i><b>1.8</b> Why Data-Science starts with Data-Visualization | The Key-Thing I learned</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#ausblick"><i class="fa fa-check"></i><b>1.9</b> Ausblick</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html"><i class="fa fa-check"></i><b>2</b> Foundatios of Programming</a><ul>
<li class="chapter" data-level="2.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#how-to-program"><i class="fa fa-check"></i><b>2.1</b> How to Program?</a></li>
<li class="chapter" data-level="2.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#wörterbuch-1"><i class="fa fa-check"></i><b>2.2</b> Wörterbuch</a><ul>
<li class="chapter" data-level="2.2.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#synonyme"><i class="fa fa-check"></i><b>2.2.1</b> Synonyme</a></li>
<li class="chapter" data-level="2.2.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#programming"><i class="fa fa-check"></i><b>2.2.2</b> Programming</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#data-types"><i class="fa fa-check"></i><b>2.3</b> Data-Types</a></li>
<li class="chapter" data-level="2.4" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#global-variables-vs.-local-variables"><i class="fa fa-check"></i><b>2.4</b> Global Variables VS. Local Variables</a></li>
<li class="chapter" data-level="2.5" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#what-is-python-the-context"><i class="fa fa-check"></i><b>2.5</b> What is Python? | The Context</a><ul>
<li class="chapter" data-level="2.5.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#types-of-programming-languages"><i class="fa fa-check"></i><b>2.5.1</b> Types of Programming Languages</a></li>
<li class="chapter" data-level="2.5.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#programming-paradigms-of-a-programming-language"><i class="fa fa-check"></i><b>2.5.2</b> Programming-Paradigms of a Programming-Language</a></li>
<li class="chapter" data-level="2.5.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#purpose-based-vs.-general-purpose-programming-languages"><i class="fa fa-check"></i><b>2.5.3</b> Purpose-Based VS. General-Purpose Programming Languages</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#python-basics"><i class="fa fa-check"></i><b>2.6</b> Python-Basics</a><ul>
<li class="chapter" data-level="2.6.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#magic-commands-in-python-keyboard-shortcuts"><i class="fa fa-check"></i><b>2.6.1</b> Magic Commands in Python | Keyboard-Shortcuts</a></li>
<li class="chapter" data-level="2.6.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#wörterbuch-2"><i class="fa fa-check"></i><b>2.6.2</b> Wörterbuch</a></li>
<li class="chapter" data-level="2.6.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#tricks"><i class="fa fa-check"></i><b>2.6.3</b> Tricks</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#object-oriented-programming"><i class="fa fa-check"></i><b>2.7</b> Object Oriented Programming</a><ul>
<li class="chapter" data-level="2.7.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#reason-why-we-use-oop"><i class="fa fa-check"></i><b>2.7.1</b> Reason why, we use OOP</a></li>
<li class="chapter" data-level="2.7.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#konzept"><i class="fa fa-check"></i><b>2.7.2</b> Konzept</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#r-as-your-ide"><i class="fa fa-check"></i><b>2.8</b> R as your IDE</a><ul>
<li class="chapter" data-level="2.8.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#pipe-operator-in-r"><i class="fa fa-check"></i><b>2.8.1</b> Pipe-Operator in R</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#restful-api"><i class="fa fa-check"></i><b>2.9</b> Restful API</a></li>
<li class="chapter" data-level="2.10" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#more-advanced-topics"><i class="fa fa-check"></i><b>2.10</b> More advanced Topics</a><ul>
<li class="chapter" data-level="2.10.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#data-pipeline"><i class="fa fa-check"></i><b>2.10.1</b> Data Pipeline</a></li>
<li class="chapter" data-level="2.10.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#fundamental-daten"><i class="fa fa-check"></i><b>2.10.2</b> Fundamental-Daten</a></li>
<li class="chapter" data-level="2.10.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#data-flow"><i class="fa fa-check"></i><b>2.10.3</b> Data-Flow</a></li>
<li class="chapter" data-level="2.10.4" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#docker"><i class="fa fa-check"></i><b>2.10.4</b> Docker</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html"><i class="fa fa-check"></i><b>3</b> Foundations of Data Science</a><ul>
<li class="chapter" data-level="3.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#allgemeine-roadmap-für-data-science-projekte"><i class="fa fa-check"></i><b>3.1</b> Allgemeine Roadmap für Data-Science Projekte</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#management-eines-ds-projektes-the-step-by-step-guide"><i class="fa fa-check"></i><b>3.2</b> Management eines DS-Projektes | The Step-by-Step Guide</a><ul>
<li class="chapter" data-level="3.2.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-0---correct-initialization-of-a-project"><i class="fa fa-check"></i><b>3.2.1</b> Phase 0 - Correct initialization of a Project</a></li>
<li class="chapter" data-level="3.2.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-1---get-the-data-erste-recherchearbeit"><i class="fa fa-check"></i><b>3.2.2</b> Phase 1 - Get the Data &amp; erste Recherchearbeit</a></li>
<li class="chapter" data-level="3.2.3" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-2---load-the-data-vanilla-exploration"><i class="fa fa-check"></i><b>3.2.3</b> Phase 2 - Load the Data &amp; Vanilla Exploration</a></li>
<li class="chapter" data-level="3.2.4" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-3---after-having-concluded-my-data-is-ok-wie-geht-es-weiter"><i class="fa fa-check"></i><b>3.2.4</b> Phase 3 - After having concluded: “My data is OK!” | Wie geht es weiter?</a></li>
<li class="chapter" data-level="3.2.5" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-4---model-estimation-applying-machine-learning-on-the-data"><i class="fa fa-check"></i><b>3.2.5</b> Phase 4 - Model Estimation | Applying Machine-Learning on the Data</a></li>
<li class="chapter" data-level="3.2.6" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-5---deployment-erstellung-eines-minimal-viable-product-abschluss-des-projektes"><i class="fa fa-check"></i><b>3.2.6</b> Phase 5 - Deployment: Erstellung eines Minimal Viable Product | Abschluss des Projektes</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#fragestellungen-beantworten"><i class="fa fa-check"></i><b>3.3</b> Fragestellungen beantworten</a><ul>
<li class="chapter" data-level="3.3.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#methoden-liste-an-diverser-technologien-um-fragestellungen-zu-beantworten"><i class="fa fa-check"></i><b>3.3.1</b> Methoden | Liste an diverser Technologien, um Fragestellungen zu beantworten</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#find-data"><i class="fa fa-check"></i><b>3.4</b> Find Data</a><ul>
<li class="chapter" data-level="3.4.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#sport-daten"><i class="fa fa-check"></i><b>3.4.1</b> Sport-Daten</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#die-kunst-des-feature-engineering-für-gute-modellierung-effizienter-modellieren"><i class="fa fa-check"></i><b>3.5</b> Die “Kunst des Feature-Engineering” für gute Modellierung | Effizienter Modellieren</a><ul>
<li class="chapter" data-level="3.5.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#geographie"><i class="fa fa-check"></i><b>3.5.1</b> Geographie</a></li>
<li class="chapter" data-level="3.5.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#finance"><i class="fa fa-check"></i><b>3.5.2</b> Finance</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#allgemeine-schwächen-von-data-science"><i class="fa fa-check"></i><b>3.6</b> Allgemeine Schwächen von Data-Science</a><ul>
<li class="chapter" data-level="3.6.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#visualisierungen-für-erklärungen-verwenden"><i class="fa fa-check"></i><b>3.6.1</b> Visualisierungen für Erklärungen verwenden</a></li>
<li class="chapter" data-level="3.6.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#nur-20-der-data-science-projekte-haben-erfolg-apropos-geld"><i class="fa fa-check"></i><b>3.6.2</b> Nur 20% der Data-Science Projekte haben “Erfolg” | Apropos Geld…</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#appendix-for-the-future"><i class="fa fa-check"></i><b>3.7</b> Appendix for the Future</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="python-libraries.html"><a href="python-libraries.html"><i class="fa fa-check"></i><b>4</b> Python Libraries</a><ul>
<li class="chapter" data-level="4.1" data-path="python-libraries.html"><a href="python-libraries.html#list-of-useful-python-libraries"><i class="fa fa-check"></i><b>4.1</b> List of Useful Python-Libraries</a></li>
<li class="chapter" data-level="4.2" data-path="python-libraries.html"><a href="python-libraries.html#python-mustercodes-für-data-science"><i class="fa fa-check"></i><b>4.2</b> <code>Python</code>-Mustercodes für Data-Science</a></li>
<li class="chapter" data-level="4.3" data-path="python-libraries.html"><a href="python-libraries.html#basic-python"><i class="fa fa-check"></i><b>4.3</b> Basic <code>Python</code></a><ul>
<li class="chapter" data-level="4.3.1" data-path="python-libraries.html"><a href="python-libraries.html#put-a-time-stamp-on-each-python-cell"><i class="fa fa-check"></i><b>4.3.1</b> Put a time-stamp on each Python-Cell</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="python-libraries.html"><a href="python-libraries.html#pandas-library"><i class="fa fa-check"></i><b>4.4</b> Pandas Library</a><ul>
<li class="chapter" data-level="4.4.1" data-path="python-libraries.html"><a href="python-libraries.html#padas-dataframe"><i class="fa fa-check"></i><b>4.4.1</b> Padas DataFrame</a></li>
<li class="chapter" data-level="4.4.2" data-path="python-libraries.html"><a href="python-libraries.html#how-to-display-all-the-columns"><i class="fa fa-check"></i><b>4.4.2</b> How to display all the columns?</a></li>
<li class="chapter" data-level="4.4.3" data-path="python-libraries.html"><a href="python-libraries.html#drop-missing-values"><i class="fa fa-check"></i><b>4.4.3</b> Drop Missing-values?</a></li>
<li class="chapter" data-level="4.4.4" data-path="python-libraries.html"><a href="python-libraries.html#loc--vs.-iloc-selection"><i class="fa fa-check"></i><b>4.4.4</b> <code>loc</code>- VS. <code>iloc</code>-Selection</a></li>
<li class="chapter" data-level="4.4.5" data-path="python-libraries.html"><a href="python-libraries.html#drop-a-column-with-the-pop-method"><i class="fa fa-check"></i><b>4.4.5</b> Drop a Column with the <code>pop()</code>-Method</a></li>
<li class="chapter" data-level="4.4.6" data-path="python-libraries.html"><a href="python-libraries.html#convert-into-date-time-format-with-the-to_datetime-method"><i class="fa fa-check"></i><b>4.4.6</b> Convert into “Date-Time”-format with the <code>to_datetime()</code>-Method</a></li>
<li class="chapter" data-level="4.4.7" data-path="python-libraries.html"><a href="python-libraries.html#umgekehrt-use-the-strftime-method-to-convert-a-date-column-back-into-a-string-format"><i class="fa fa-check"></i><b>4.4.7</b> <u>Umgekehrt</u>: Use the <code>strftime()</code>-Method to convert a Date-Column back into a “String”-Format</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="python-libraries.html"><a href="python-libraries.html#statsmodels"><i class="fa fa-check"></i><b>4.5</b> Statsmodels</a><ul>
<li class="chapter" data-level="4.5.1" data-path="python-libraries.html"><a href="python-libraries.html#useful-nice-to-knows"><i class="fa fa-check"></i><b>4.5.1</b> Useful Nice-to-Knows</a></li>
<li class="chapter" data-level="4.5.2" data-path="python-libraries.html"><a href="python-libraries.html#define-the-y-variable-x-variables"><i class="fa fa-check"></i><b>4.5.2</b> Define the <code>y</code>-variable &amp; <code>X</code>-variable<u>s</u></a></li>
<li class="chapter" data-level="4.5.3" data-path="python-libraries.html"><a href="python-libraries.html#estimate-a-model"><i class="fa fa-check"></i><b>4.5.3</b> Estimate a Model</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="python-libraries.html"><a href="python-libraries.html#time-series-forecasting"><i class="fa fa-check"></i><b>4.6</b> Time-Series Forecasting</a><ul>
<li class="chapter" data-level="4.6.1" data-path="python-libraries.html"><a href="python-libraries.html#working-with-date-columns"><i class="fa fa-check"></i><b>4.6.1</b> Working with <code>Date</code>-Columns</a></li>
<li class="chapter" data-level="4.6.2" data-path="python-libraries.html"><a href="python-libraries.html#facebook-prophet-library"><i class="fa fa-check"></i><b>4.6.2</b> Facebook Prophet Library</a></li>
<li class="chapter" data-level="4.6.3" data-path="python-libraries.html"><a href="python-libraries.html#sklearn-library"><i class="fa fa-check"></i><b>4.6.3</b> SkLearn Library</a></li>
<li class="chapter" data-level="4.6.4" data-path="python-libraries.html"><a href="python-libraries.html#sktime-library"><i class="fa fa-check"></i><b>4.6.4</b> SkTime Library</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="python-libraries.html"><a href="python-libraries.html#tensorflow"><i class="fa fa-check"></i><b>4.7</b> Tensorflow</a><ul>
<li class="chapter" data-level="4.7.1" data-path="python-libraries.html"><a href="python-libraries.html#definition"><i class="fa fa-check"></i><b>4.7.1</b> Definition</a></li>
<li class="chapter" data-level="4.7.2" data-path="python-libraries.html"><a href="python-libraries.html#tensorflow-vs.-pytorch"><i class="fa fa-check"></i><b>4.7.2</b> Tensorflow VS. PyTorch</a></li>
<li class="chapter" data-level="4.7.3" data-path="python-libraries.html"><a href="python-libraries.html#data-windowing-konzept-erklärung-mittels-beispielen"><i class="fa fa-check"></i><b>4.7.3</b> Data-Windowing Konzept | Erklärung mittels Beispielen</a></li>
<li class="chapter" data-level="4.7.4" data-path="python-libraries.html"><a href="python-libraries.html#wörterbuch-3"><i class="fa fa-check"></i><b>4.7.4</b> Wörterbuch</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>5</b> Visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="visualization.html"><a href="visualization.html#graphs-with-python"><i class="fa fa-check"></i><b>5.1</b> Graphs with Python</a><ul>
<li class="chapter" data-level="5.1.1" data-path="visualization.html"><a href="visualization.html#seaborn"><i class="fa fa-check"></i><b>5.1.1</b> Seaborn</a></li>
<li class="chapter" data-level="5.1.2" data-path="visualization.html"><a href="visualization.html#matplotlib"><i class="fa fa-check"></i><b>5.1.2</b> Matplotlib</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="visualization.html"><a href="visualization.html#statistics"><i class="fa fa-check"></i><b>5.2</b> Statistics</a><ul>
<li class="chapter" data-level="5.2.1" data-path="visualization.html"><a href="visualization.html#the-normal-distribution"><i class="fa fa-check"></i><b>5.2.1</b> The Normal Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="improve-yourself-constantly.html"><a href="improve-yourself-constantly.html"><i class="fa fa-check"></i><b>6</b> Improve Yourself Constantly</a><ul>
<li class="chapter" data-level="6.1" data-path="improve-yourself-constantly.html"><a href="improve-yourself-constantly.html#to-share"><i class="fa fa-check"></i><b>6.1</b> To Share</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html"><i class="fa fa-check"></i><b>7</b> Git Versioncontrol</a><ul>
<li class="chapter" data-level="7.1" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#wörterbuch-4"><i class="fa fa-check"></i><b>7.1</b> Wörterbuch</a></li>
<li class="chapter" data-level="7.2" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#first-time-using-git-github"><i class="fa fa-check"></i><b>7.2</b> First time using Git &amp; Github</a></li>
<li class="chapter" data-level="7.3" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#key-concepts-in-git"><i class="fa fa-check"></i><b>7.3</b> 2 Key concepts in Git</a><ul>
<li class="chapter" data-level="7.3.1" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#start-project-via-github-remote-possibility"><i class="fa fa-check"></i><b>7.3.1</b> Start Project via Github | Remote-Possibility</a></li>
<li class="chapter" data-level="7.3.2" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#start-project-via-local-computer-local-possibility"><i class="fa fa-check"></i><b>7.3.2</b> Start Project via local computer | Local-Possibility</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#working-with-branches"><i class="fa fa-check"></i><b>7.4</b> Working with Branches</a></li>
<li class="chapter" data-level="7.5" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#set-up-an-ssh-key-for-github"><i class="fa fa-check"></i><b>7.5</b> Set-Up an SSH-Key for Github</a></li>
<li class="chapter" data-level="7.6" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#create-a-.gitignore-file"><i class="fa fa-check"></i><b>7.6</b> Create a <code>.gitignore</code>-file</a></li>
<li class="chapter" data-level="7.7" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#speicherplatz-verwendet-durch-git-history"><i class="fa fa-check"></i><b>7.7</b> Speicherplatz verwendet durch <code>Git</code>-History</a></li>
<li class="chapter" data-level="7.8" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#unstage-everything"><i class="fa fa-check"></i><b>7.8</b> Unstage everything</a></li>
<li class="chapter" data-level="7.9" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#stage-only-a-certain-type-of-file---for-example---only-.html-files"><i class="fa fa-check"></i><b>7.9</b> Stage only a certain type of file - for example - only <code>.html</code>-files</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="econometrics.html"><a href="econometrics.html"><i class="fa fa-check"></i><b>8</b> Econometrics</a><ul>
<li class="chapter" data-level="8.1" data-path="econometrics.html"><a href="econometrics.html#synonyme-2"><i class="fa fa-check"></i><b>8.1</b> Synonyme:</a></li>
<li class="chapter" data-level="8.2" data-path="econometrics.html"><a href="econometrics.html#english-words-synonyme"><i class="fa fa-check"></i><b>8.2</b> English Words Synonyme</a></li>
<li class="chapter" data-level="8.3" data-path="econometrics.html"><a href="econometrics.html#allgemeines"><i class="fa fa-check"></i><b>8.3</b> Allgemeines</a></li>
<li class="chapter" data-level="8.4" data-path="econometrics.html"><a href="econometrics.html#statistics-formulas"><i class="fa fa-check"></i><b>8.4</b> Statistics Formulas</a></li>
<li class="chapter" data-level="8.5" data-path="econometrics.html"><a href="econometrics.html#definitionen"><i class="fa fa-check"></i><b>8.5</b> Definitionen</a></li>
<li class="chapter" data-level="8.6" data-path="econometrics.html"><a href="econometrics.html#different-tests-vorgehen-bei-den-tests"><i class="fa fa-check"></i><b>8.6</b> Different Tests // Vorgehen bei den Tests</a></li>
<li class="chapter" data-level="8.7" data-path="econometrics.html"><a href="econometrics.html#diverse-berechnungen"><i class="fa fa-check"></i><b>8.7</b> Diverse Berechnungen</a></li>
<li class="chapter" data-level="8.8" data-path="econometrics.html"><a href="econometrics.html#accept-reject-null-hypothesis"><i class="fa fa-check"></i><b>8.8</b> Accept // Reject Null-Hypothesis</a></li>
<li class="chapter" data-level="8.9" data-path="econometrics.html"><a href="econometrics.html#formulierungen"><i class="fa fa-check"></i><b>8.9</b> Formulierungen</a></li>
<li class="chapter" data-level="8.10" data-path="econometrics.html"><a href="econometrics.html#coefficient-interpretation"><i class="fa fa-check"></i><b>8.10</b> Coefficient Interpretation</a></li>
<li class="chapter" data-level="8.11" data-path="econometrics.html"><a href="econometrics.html#nice-to-know"><i class="fa fa-check"></i><b>8.11</b> Nice to Know</a></li>
<li class="chapter" data-level="8.12" data-path="econometrics.html"><a href="econometrics.html#allgemeine-regeln"><i class="fa fa-check"></i><b>8.12</b> Allgemeine Regeln</a></li>
<li class="chapter" data-level="8.13" data-path="econometrics.html"><a href="econometrics.html#ommitted-variable-bias-ovb"><i class="fa fa-check"></i><b>8.13</b> Ommitted Variable Bias = OVB</a></li>
<li class="chapter" data-level="8.14" data-path="econometrics.html"><a href="econometrics.html#randomization"><i class="fa fa-check"></i><b>8.14</b> Randomization</a></li>
<li class="chapter" data-level="8.15" data-path="econometrics.html"><a href="econometrics.html#dummy-variables"><i class="fa fa-check"></i><b>8.15</b> Dummy Variables</a></li>
<li class="chapter" data-level="8.16" data-path="econometrics.html"><a href="econometrics.html#implication-of-statistically-significant-coefficients"><i class="fa fa-check"></i><b>8.16</b> Implication of statistically significant coefficients</a></li>
<li class="chapter" data-level="8.17" data-path="econometrics.html"><a href="econometrics.html#linear-probability-model-vs.-probit-model-comparison"><i class="fa fa-check"></i><b>8.17</b> Linear probability model VS. Probit model: comparison</a></li>
<li class="chapter" data-level="8.18" data-path="econometrics.html"><a href="econometrics.html#heterogeneous-treatment-effects-interaction-terms"><i class="fa fa-check"></i><b>8.18</b> Heterogeneous treatment effects // interaction terms</a></li>
<li class="chapter" data-level="8.19" data-path="econometrics.html"><a href="econometrics.html#definitions-of-bad-controls"><i class="fa fa-check"></i><b>8.19</b> Definitions of “bad controls”</a></li>
<li class="chapter" data-level="8.20" data-path="econometrics.html"><a href="econometrics.html#fixed-effects-fe"><i class="fa fa-check"></i><b>8.20</b> Fixed effects // FE</a></li>
<li class="chapter" data-level="8.21" data-path="econometrics.html"><a href="econometrics.html#cross-sectional-data"><i class="fa fa-check"></i><b>8.21</b> Cross-sectional Data</a></li>
<li class="chapter" data-level="8.22" data-path="econometrics.html"><a href="econometrics.html#panel-data"><i class="fa fa-check"></i><b>8.22</b> Panel Data</a></li>
<li class="chapter" data-level="8.23" data-path="econometrics.html"><a href="econometrics.html#difference-in-differences"><i class="fa fa-check"></i><b>8.23</b> Difference-in-Differences</a></li>
<li class="chapter" data-level="8.24" data-path="econometrics.html"><a href="econometrics.html#instrumental-variables-iv"><i class="fa fa-check"></i><b>8.24</b> Instrumental variables // IV</a></li>
<li class="chapter" data-level="8.25" data-path="econometrics.html"><a href="econometrics.html#regression-discontinuity-design-rdd"><i class="fa fa-check"></i><b>8.25</b> Regression discontinuity design // RDD</a></li>
<li class="chapter" data-level="8.26" data-path="econometrics.html"><a href="econometrics.html#time-series"><i class="fa fa-check"></i><b>8.26</b> Time Series</a><ul>
<li class="chapter" data-level="8.26.1" data-path="econometrics.html"><a href="econometrics.html#wörterbuch-5"><i class="fa fa-check"></i><b>8.26.1</b> Wörterbuch</a></li>
<li class="chapter" data-level="8.26.2" data-path="econometrics.html"><a href="econometrics.html#seasonality"><i class="fa fa-check"></i><b>8.26.2</b> Seasonality</a></li>
<li class="chapter" data-level="8.26.3" data-path="econometrics.html"><a href="econometrics.html#cycles"><i class="fa fa-check"></i><b>8.26.3</b> Cycles</a></li>
<li class="chapter" data-level="8.26.4" data-path="econometrics.html"><a href="econometrics.html#partial-auto-correlation"><i class="fa fa-check"></i><b>8.26.4</b> Partial Auto-Correlation</a></li>
<li class="chapter" data-level="8.26.5" data-path="econometrics.html"><a href="econometrics.html#how-to-create-a-simple-benchmark-time-series-model"><i class="fa fa-check"></i><b>8.26.5</b> How to create a simple Benchmark Time-Series Model?</a></li>
<li class="chapter" data-level="8.26.6" data-path="econometrics.html"><a href="econometrics.html#machine-learning"><i class="fa fa-check"></i><b>8.26.6</b> Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="8.27" data-path="econometrics.html"><a href="econometrics.html#coded-algorithms-r-functions"><i class="fa fa-check"></i><b>8.27</b> Coded Algorithms &amp; R-Functions</a></li>
<li class="chapter" data-level="8.28" data-path="econometrics.html"><a href="econometrics.html#nützliche-funktionen-r"><i class="fa fa-check"></i><b>8.28</b> Nützliche Funktionen R:</a></li>
<li class="chapter" data-level="8.29" data-path="econometrics.html"><a href="econometrics.html#useful-econometrics-documents"><i class="fa fa-check"></i><b>8.29</b> Useful Econometrics documents:</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machine-learning-1.html"><a href="machine-learning-1.html"><i class="fa fa-check"></i><b>9</b> Machine Learning</a><ul>
<li class="chapter" data-level="9.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#typen-von-machine-learning"><i class="fa fa-check"></i><b>9.1</b> Typen von Machine Learning</a></li>
<li class="chapter" data-level="9.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#supervised-learning"><i class="fa fa-check"></i><b>9.2</b> Supervised Learning</a></li>
<li class="chapter" data-level="9.3" data-path="machine-learning-1.html"><a href="machine-learning-1.html#methods"><i class="fa fa-check"></i><b>9.3</b> Methods</a></li>
<li class="chapter" data-level="9.4" data-path="machine-learning-1.html"><a href="machine-learning-1.html#wichtige-funktionen"><i class="fa fa-check"></i><b>9.4</b> Wichtige Funktionen</a></li>
<li class="chapter" data-level="9.5" data-path="machine-learning-1.html"><a href="machine-learning-1.html#difference-between-training--validation--test-dataset"><i class="fa fa-check"></i><b>9.5</b> Difference between Training-, Validation- &amp; Test-dataset</a><ul>
<li class="chapter" data-level="9.5.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#validation-set-vs.-test-set"><i class="fa fa-check"></i><b>9.5.1</b> Validation-Set VS. Test-Set</a></li>
<li class="chapter" data-level="9.5.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#reason-for-a-validation-set"><i class="fa fa-check"></i><b>9.5.2</b> Reason for a Validation-Set</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machine-learning-1.html"><a href="machine-learning-1.html#concept-of-stratification"><i class="fa fa-check"></i><b>9.6</b> Concept of Stratification</a></li>
<li class="chapter" data-level="9.7" data-path="machine-learning-1.html"><a href="machine-learning-1.html#cross-validation"><i class="fa fa-check"></i><b>9.7</b> Cross-Validation</a><ul>
<li class="chapter" data-level="9.7.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#special-case-cross-validation-for-time-series-data"><i class="fa fa-check"></i><b>9.7.1</b> <u>Special Case</u>: Cross-Validation for Time-Series Data</a></li>
<li class="chapter" data-level="9.7.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#why-do-we-use-cross-validation"><i class="fa fa-check"></i><b>9.7.2</b> Why do we use Cross-Validation?</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="machine-learning-1.html"><a href="machine-learning-1.html#normalisierung-der-daten"><i class="fa fa-check"></i><b>9.8</b> Normalisierung der Daten</a></li>
<li class="chapter" data-level="9.9" data-path="machine-learning-1.html"><a href="machine-learning-1.html#rnn"><i class="fa fa-check"></i><b>9.9</b> RNN</a></li>
<li class="chapter" data-level="9.10" data-path="machine-learning-1.html"><a href="machine-learning-1.html#data-pipelines"><i class="fa fa-check"></i><b>9.10</b> Data-Pipelines</a></li>
<li class="chapter" data-level="9.11" data-path="machine-learning-1.html"><a href="machine-learning-1.html#uni-kurs-neural-networks-deep-learning"><i class="fa fa-check"></i><b>9.11</b> Uni-Kurs <code>Neural Networks &amp; Deep Learning</code></a><ul>
<li class="chapter" data-level="9.11.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#notation-neural-networks"><i class="fa fa-check"></i><b>9.11.1</b> Notation Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="machine-learning-1.html"><a href="machine-learning-1.html#wörterbuch-6"><i class="fa fa-check"></i><b>9.12</b> Wörterbuch</a><ul>
<li class="chapter" data-level="9.12.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#synonyme-3"><i class="fa fa-check"></i><b>9.12.1</b> Synonyme</a></li>
<li class="chapter" data-level="9.12.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#data-science"><i class="fa fa-check"></i><b>9.12.2</b> Data Science</a></li>
<li class="chapter" data-level="9.12.3" data-path="machine-learning-1.html"><a href="machine-learning-1.html#time-series-1"><i class="fa fa-check"></i><b>9.12.3</b> Time-Series</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="machine-learning-1.html"><a href="machine-learning-1.html#quellen"><i class="fa fa-check"></i><b>9.13</b> Quellen</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mengenlehre.html"><a href="mengenlehre.html"><i class="fa fa-check"></i><b>10</b> Mengenlehre</a><ul>
<li class="chapter" data-level="10.1" data-path="mengenlehre.html"><a href="mengenlehre.html#wörterbuch-7"><i class="fa fa-check"></i><b>10.1</b> Wörterbuch</a></li>
<li class="chapter" data-level="10.2" data-path="mengenlehre.html"><a href="mengenlehre.html#mathematische-schrift-lesen"><i class="fa fa-check"></i><b>10.2</b> Mathematische “Schrift” lesen</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html"><i class="fa fa-check"></i><b>11</b> Business | Die Welt der Unternehmen</a><ul>
<li class="chapter" data-level="11.1" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#wörterbuch-8"><i class="fa fa-check"></i><b>11.1</b> Wörterbuch</a><ul>
<li class="chapter" data-level="11.1.1" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#it-software-development"><i class="fa fa-check"></i><b>11.1.1</b> IT &amp; Software-Development</a></li>
<li class="chapter" data-level="11.1.2" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#organisation"><i class="fa fa-check"></i><b>11.1.2</b> Organisation</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#projekt-management"><i class="fa fa-check"></i><b>11.2</b> Projekt-Management</a></li>
<li class="chapter" data-level="11.3" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#meetings"><i class="fa fa-check"></i><b>11.3</b> Meetings</a></li>
<li class="chapter" data-level="11.4" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#abschluss-präsentation"><i class="fa fa-check"></i><b>11.4</b> Abschluss-Präsentation</a></li>
<li class="chapter" data-level="11.5" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#job-interviews"><i class="fa fa-check"></i><b>11.5</b> Job-Interviews</a><ul>
<li class="chapter" data-level="11.5.1" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#praxis"><i class="fa fa-check"></i><b>11.5.1</b> Praxis</a></li>
<li class="chapter" data-level="11.5.2" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#vorteil-von-data-science-projekten-punkte-auf-die-du-unbedingt-zu-sprechen-kommen-solltest"><i class="fa fa-check"></i><b>11.5.2</b> Vorteil von Data-Science Projekten | Punkte, auf die du unbedingt zu Sprechen kommen solltest…</a></li>
<li class="chapter" data-level="11.5.3" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#quellen-1"><i class="fa fa-check"></i><b>11.5.3</b> Quellen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="openai.html"><a href="openai.html"><i class="fa fa-check"></i><b>12</b> OpenAI</a><ul>
<li class="chapter" data-level="12.1" data-path="openai.html"><a href="openai.html#what-can-openai-do-the-output"><i class="fa fa-check"></i><b>12.1</b> What can <code>OpenAI</code> do? | The Output</a></li>
<li class="chapter" data-level="12.2" data-path="openai.html"><a href="openai.html#how-does-the-model-work-the-blueprint"><i class="fa fa-check"></i><b>12.2</b> How does the Model work? | The Blueprint</a></li>
<li class="chapter" data-level="12.3" data-path="openai.html"><a href="openai.html#terminology-of-openai-api-wörterbuch"><i class="fa fa-check"></i><b>12.3</b> Terminology of <code>OpenAI</code>-API | Wörterbuch</a></li>
<li class="chapter" data-level="12.4" data-path="openai.html"><a href="openai.html#technology-behind-it-quellen"><i class="fa fa-check"></i><b>12.4</b> Technology behind it | Quellen</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science from Scratch Code</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning-1" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Machine Learning</h1>
<p>In diesem Kapitel, werde ich vertiefter in das Thema “Machine Learning” eingehen.</p>
<div id="typen-von-machine-learning" class="section level2">
<h2><span class="header-section-number">9.1</span> Typen von Machine Learning</h2>
<p>Es gibt grundsätzlich <strong>2 Kategorien</strong>, in denen die verschiedenen <em>Methoden in Machine Learning</em> eingeordnet werden:</p>
<ol style="list-style-type: decimal">
<li><strong>Supervised Learning</strong>
<ul>
<li><u>Goal 1</u>: <strong>Classification</strong>
<ul>
<li>Image Classification</li>
</ul></li>
<li><u>Goal 2</u>: <strong>Predictions</strong> with Regressions
<ul>
<li>Translation (zum Beispiel angewendet in Deepl.com)</li>
<li>Image Captioning (siehe Bild): <img src="./bilder/machine-learning/example-image-captioning.jpg" alt="Beispiel zu Image Captioning" /></li>
</ul></li>
</ul></li>
<li><strong>Unsupervised Learning</strong>
<ul>
<li>Clustering:
<ul>
<li>Matching // K-Means Clustering</li>
</ul></li>
<li>Dimension Reduction:
<ul>
<li>Principal Component Analysis (PCA)</li>
</ul></li>
<li>Outlier Detection</li>
</ul></li>
</ol>
</div>
<div id="supervised-learning" class="section level2">
<h2><span class="header-section-number">9.2</span> Supervised Learning</h2>
<p><strong>Bei Supervised Learning</strong> wird die <strong>Annahme</strong> gemacht, <em>dass man die Funktion ‘f’ <strong>kennt</strong>, um mittels den Werten der Zufallsvariablen ‘X’ die Werte der Zufallsvariablen ‘Y’ herauszufinden</em>.</p>
<p><u>Mathematisch ausgedrückt</u>: <code>f : X -&gt; Y</code>.</p>
</div>
<div id="methods" class="section level2">
<h2><span class="header-section-number">9.3</span> Methods</h2>
<p>Hier soll eine Auflistung aller Vorgehen bei Machine Learning aufgelistet werden:</p>
<ul>
<li><p><strong><u>Algorithm for “best fit” to find the weights</u></strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Guess some random weights.</p></li>
<li><p>“Go downhill”, e.g. <strong>apply a <em>learning rate</em></strong> when using the method <strong>gradient descent</strong>.</p></li>
<li><p>Is the <strong>fitted line good enough?</strong></p>
<ul>
<li>If the <em>answer is “no”</em>, then go <strong>back to point 2)</strong>.</li>
</ul></li>
</ol></li>
</ul>
</div>
<div id="wichtige-funktionen" class="section level2">
<h2><span class="header-section-number">9.4</span> Wichtige Funktionen</h2>
<p>Da Machine Learning mittels Aktivierungsfunktionen funktioniert, folgt eine Übersicht zu verschiedenen Funktionen:</p>
<ul>
<li><strong><u>Identity Function</u></strong>: damit ist die Funktion <code>f(x) = x</code> bzw. <code>y = x</code> gemeint:</li>
</ul>
<p><img src="bookdownproj_files/figure-html/identity-function-1.png" width="672" /></p>
<ul>
<li><strong><u>Logitstic Function // Sigmoid Function // S-Shaped Function</u></strong>: damit ist die Funktion <span class="math inline">\(\sigma(x) = \frac{1}{1 + e^{-x}}\)</span> gemeint:</li>
</ul>
<p><img src="bookdownproj_files/figure-html/input-only-2-1.png" width="672" /></p>
</div>
<div id="difference-between-training--validation--test-dataset" class="section level2">
<h2><span class="header-section-number">9.5</span> Difference between Training-, Validation- &amp; Test-dataset</h2>
<p>Since I started with Machine Learning, I was always confused about the concept of <strong>data splitting</strong>, e.g. which sub-set of the <em>entire</em> dataset is now considered to be the <em>training dataset</em>, which one is the <em>validation dataset</em> and which one is the <em>testing dataset</em>.</p>
<p><u>In the graph below, you see how it is defined correctly</u>:</p>
<div class="figure">
<img src="./bilder/machine-learning/training-VS-validation-VS-test-ddset.jpg" alt="" />
<p class="caption">Training Set VS. Validation Set VS. Test Set</p>
</div>
<ul>
<li><u>Important to note</u>: There is oftentimes confusion between the definition of <em>validation dataset</em> VS. <em>testing dataset</em>, because there is no consens about it. <strong>Therefore - and if we take the above picture as the “true” definition - some people will call the <em>validation dataset</em> the “test dataset” and vice versa, e.g. the <em>test data</em> as the “validation data”! xD</strong></li>
</ul>
<div id="validation-set-vs.-test-set" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Validation-Set VS. Test-Set</h3>
<blockquote>
<p>What is the difference between a <code>Validation Dataset</code> and a <code>Testing Dataset</code>?</p>
</blockquote>
<p>Es gibt keinen Konsens dafür, was nun das <code>validation dataset</code> und welches das <code>test set</code> genau ist. <strong>Nima</strong> (= mein Mentor bei der SBB) verwendet den Begriff <code>test set</code> für dasjenige Dataset, welches <code>hold out</code> // separat für die (spätere) <code>Prediction</code> verwendet wird.</p>
<ul>
<li><u>Regel zu Unterscheidung der beiden Terme</u>: Wenn steht: <code>we hold out [name of the set]</code>, dann ist es das <code>testing dataset</code>.</li>
</ul>
</div>
<div id="reason-for-a-validation-set" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Reason for a Validation-Set</h3>
<blockquote>
<p>Why do we need <code>validation set</code>?</p>
</blockquote>
<p>At the end, you want the best model possible. If you want to tune your hyperparameters, you will need your <code>test set</code>. <strong>The big problem here, however, is that - <em>if we use the test-set more than once when wanting to find out the best hyperparameters</em> - our model will know the data by heart and the predictions will be too good, <u>but only</u> on this dataset that you are currently using</strong>! The model will not generalize well on new data.</p>
<p><em>That’s why we need this additional subsetting of the training-dataset!</em></p>
</div>
</div>
<div id="concept-of-stratification" class="section level2">
<h2><span class="header-section-number">9.6</span> Concept of Stratification</h2>
<p>Angenommen du hast eine <em>kategorische</em> Y-Variable, welche entweder Nullen oder Einsen als Werte annimmt. Nehme nun an, dass - <em>im Training-Dataset</em> - der Anteil der Nullen 60% beträgt. Wenn du nun ein <code>stratified Sample</code> willst, dann wird das <em>Test-Dataset</em> ebenfalls einen Anteil von 60% an Nullen enthalten!</p>
<ul>
<li><u>Quelle</u>: <a href="https://www.youtube.com/watch?v=KEBS7Kyc0Po">Train-Test-Split in Sklearn and Cross-Validation</a></li>
</ul>
</div>
<div id="cross-validation" class="section level2">
<h2><span class="header-section-number">9.7</span> Cross-Validation</h2>
<p>The concept of <em>cross-validation</em> can be splitted into 2 parts:</p>
<ul>
<li><u>Step 1</u>: Split your dataset into 1 training- &amp; 1 test-set.
<ul>
<li><u>Rule of Thumb</u>: Usually, the split is <strong>70-90% training set</strong> and <strong>10-30% for the test-set</strong>.</li>
<li><u>Code Example</u>:</li>
</ul></li>
</ul>
<div class="figure">
<img src="./bilder/machine-learning/code-example-cross-validation.jpg" alt="" />
<p class="caption">Example of Code for Train-Test Split</p>
</div>
<ul>
<li><u>Step 2</u>: Now, we divide the <em>training set</em> further, such that it will contain - <em>if we assume a 3-fold cross-validation as an example</em> - <strong>3 <u>different</u> validation sets</strong> and <strong>3 training sets</strong>.</li>
</ul>
<div class="figure">
<img src="./bilder/machine-learning/example-of-a-general-3-fold-cross-validation.jpg" alt="" />
<p class="caption">Allgemeine Cross-Validation</p>
</div>
<div id="special-case-cross-validation-for-time-series-data" class="section level3">
<h3><span class="header-section-number">9.7.1</span> <u>Special Case</u>: Cross-Validation for Time-Series Data</h3>
<p>Because time-series are <em>ordered</em>, since <em>the flow of time</em> is only going forward, the graph shown above for <em>step 2</em> is <u>not</u> valid and we need another approach!</p>
<div class="figure">
<img src="./bilder/machine-learning/example-3-fold-cross-validation-for-time-series.jpg" alt="" />
<p class="caption">Cross-Validation for Time Series</p>
</div>
<p>This picture shows <strong>an example of a 3-fold cross-validation for a time-series</strong>.</p>
<div id="the-expanding-window-cross-validation-variante-1" class="section level4">
<h4><span class="header-section-number">9.7.1.1</span> The Expanding-Window Cross-Validation | Variante 1</h4>
<p>One version of the special-case “CV for time-series” is the so-called <code>Expanding-Window Cross-Validation</code>.</p>
<p><em>In this CV, we expand the number of training-data progressively, until we reach the end of the training-set</em>.</p>
<div class="figure">
<img src="./bilder/econ/3-fold-cv-for-ts.png" alt="" />
<p class="caption">Visuelle Darstellung, wie der verschiedenen Validierungs-Fehler (MAPE, MAE oder RMSE) berechnet werden auf dem Trainingsset.</p>
</div>
<ul>
<li><u>Achtung</u>: Vergesse nicht, dass jeweils bloss ein durchschnittswert pro Tabular-Regression ausgerechnet wird! _Wenn du also nicht zufriedenstellende Prognosen</li>
</ul>
</div>
<div id="the-sliding-window-cross-validation-variante-2" class="section level4">
<h4><span class="header-section-number">9.7.1.2</span> The Sliding-Window Cross-Validation | Variante 2</h4>
<p><em>In this CV, we start with a first BIG sub-training dataset. For the <strong>second</strong> fold - however we only take the most recent past data to predict the. the number of training-data progressively, until we reach the end of the training-set</em>.</p>
<div class="figure">
<img src="./bilder/machine-learning/sliding-window.png" alt="" />
<p class="caption">Example of a 18-fold Sliding-Window Cross-Validation</p>
</div>
</div>
<div id="what-are-the-advantages-disadvantages-of-those-two-types-of-cross-validation" class="section level4">
<h4><span class="header-section-number">9.7.1.3</span> What are the Advantages / Disadvantages of those two types of Cross-Validation?</h4>
<ul>
<li>The <code>Expanding Windows Splitter</code> is **<u>less volatile</u> when a <em>big macroeconomic shock</em> occurs, like the COVID-19 crisis. However, the model <em>reacts more slowly</em> // is more sluggish (= träge), when it enters a “Regime-Wechsel” (= Zustandsänderung an den Märkten).</li>
<li>The <code>Sliding Windows Splitter</code>, it is the opposite: **<u>(much) more volatile</u> when a <em>big macroeconomic shock</em> occurs, like the COVID-19 crisis. However, the model <em>reacts more quickly</em>, when it enters a “Regime-Wechsel” (= Zustandsänderung an den Märkten).</li>
</ul>
<div class="figure">
<img src="./bilder/machine-learning/sliding-window-VS-expanding-window.png" alt="" />
<p class="caption">Expanding-Window VS. Sliding-Window: Vergleiche jeweils hell-rot mit dunkel-rot ODER hell-blau mit dunkel-blau, um den Verlgeich zwischen Expanding- &amp; Sliding-Window zu sehen.</p>
</div>
</div>
</div>
<div id="why-do-we-use-cross-validation" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Why do we use Cross-Validation?</h3>
<p>There are 2 reasons:</p>
<ol style="list-style-type: decimal">
<li>It allows us <strong>to compare the score (MAPE, MAE or RMSE) of different model set-ups</strong>, for example:</li>
</ol>
<ul>
<li><em>CV-Scheme changes</em>, e.g. a <em>Time-Series</em> Prophet-Model with a <code>Sliding-Window</code> of 4 Months VS. a Prophet-Model with an <code>Expanding-Window</code> (full past).</li>
<li>OR <em>changes in the covariates</em>, e.g. a model that includes an important covariate, while the other model does not.
<strong>This will allow you to draw conclusions regarding the selection of “the best” model</strong>.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>It allows you <strong>to assess the performance</strong> of different machine-learning methods. In a <em>classification-setting</em> for example, you can use the <em>confusion-matrix</em>.</li>
</ol>
</div>
</div>
<div id="normalisierung-der-daten" class="section level2">
<h2><span class="header-section-number">9.8</span> Normalisierung der Daten</h2>
<blockquote>
<p>Was versteht man unter <code>Normalisierung</code>? Was sollte man dabei beachten? Warum wird in einem Pre-Processing Schritt eine Normalisierung durchgeführt?</p>
</blockquote>
<p><code>Normalisierung</code> == <strong>Subtrahiere den Mittelwert und dividiere durch die Standardabweichung jedes Merkmals</strong>. Es sollte beachtet werden, dass der Mittelwert und die Standardabweichung <strong>nur anhand der Trainings-Daten berechnet werden sollte</strong>, damit die Modelle keinen Zugriff auf die Werte in den Validierungs- und Testsätzen haben.</p>
<p><strong>Es ist wichtig, Features zu skalieren, bevor ein neuronales Netzwerk trainiert wird</strong>. Normalisierung ist eine gängige Methode für diese Skalierung.</p>
</div>
<div id="rnn" class="section level2">
<h2><span class="header-section-number">9.9</span> RNN</h2>
<blockquote>
<p>Was macht ein <code>Reccurrent Neural Network (RNN)</code>?</p>
</blockquote>
<p>Ein Beispiel für ein RNN wäre ein <code>Long Short Term Memory</code> Modell (LSTM Modell). Dabei nimmt das RNN zunächst ein ganz kleines Vergangenheits-Intervall, macht eine Modell-Estimation und dann - im nächsten Schritt - wird ein grösseres Vergangenheits-Intervall verwendet (<strong>inkl. predicted Y-Variable aus dem vorherigen Modell</strong>), um eine neue Modell-Estimation zu machen etc.</p>
<div class="figure">
<img src="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/lstm_many_window.png?raw=1" alt="" />
<p class="caption">Beispiel eines RNN: hier ein LSTM</p>
</div>
</div>
<div id="data-pipelines" class="section level2">
<h2><span class="header-section-number">9.10</span> Data-Pipelines</h2>
<p><strong>Data Pipelines use an input to produce an output and then - on a second step - use the produced output as an input to produce another output etc…</strong></p>
<ul>
<li><u>Visualisierung</u>: Du kannst dir unter <em>Data Pipelines</em> nichts anderes als eine “Guetzli Fabrik” vorstellen, welche diverse Produktionsmaschinen verwendet - zum Beispiel einen Teig-Cutter, dann einen Butter-Schmierer, sowie einen fetten Ofen und einen Sortierer von “guten VS. schlechte Guetzli” - um die Inputs immer weiter zu verarbeiten, sodass schlussendlich ein Endprodukt (= die fertigen “Guetzli”) ensteht, dass man verkaufen kann.</li>
</ul>
<blockquote>
<p><a href="https://www.youtube.com/watch?v=w9IGkBfOoic">How to create good Data-Pipelines in Scikit-Learn?</a></p>
</blockquote>
<ul>
<li><u>Ziel von Data-Pipeline</u>: Write more clean // readable code, especially when you do <em>data cleaning</em>. <strong>A datapipeline is basically a way of standardizing your code</strong>.</li>
<li><u>Warum sind Data-Pipelines so geil?</u>: Because you can <strong>compare many different regression-models (Linear-Regression Vs. Logistic-Regression Vs. RandomForrest …), applying different “scaling-techniques” (= normalize a variable with mean 0 and standard-deviation of 1), as well as using “data cleaning techniques” (= reduce dimensions via PCA, reduce missing-values etc…)</strong>. Another cool thing to note is, that <strong>you can choose the order, in which the cleaning, scaling and fitting occures!</strong>
<ul>
<li>See also the summary of the guy <a href="https://www.youtube.com/watch?v=w9IGkBfOoic">on Youtube ab 10:00-11:00</a>.</li>
</ul></li>
<li><u>Link to Github for an example</u>: <a href="https://github.com/krishnaik06/Pipelines-Using-Sklearn/blob/master/SklearnPipeline.ipynb" target="_blank">Jupyter-Notebook code-example on how to create a little Data-Pipeline by yourself</a></li>
</ul>
</div>
<div id="uni-kurs-neural-networks-deep-learning" class="section level2">
<h2><span class="header-section-number">9.11</span> Uni-Kurs <code>Neural Networks &amp; Deep Learning</code></h2>
<div id="notation-neural-networks" class="section level3">
<h3><span class="header-section-number">9.11.1</span> Notation Neural Networks</h3>
<p><strong>Machine Learning verwendet unterschiedliche Begriffe für diverse gleiche Konzepte &amp; Definitionen aus den Wirtschaftswissenschaften</strong>. Nun geht es darum, die korrekte Übersetzungen für diese Wörter aufzulisten:</p>
<ul>
<li>weights = Beta-Coefficients = parameters = a, b = neurons</li>
<li>Input units = independent variables “x”</li>
<li>inputs = Anzahl Observations in Total</li>
<li>Output unit = Dependent variable “y” = labels</li>
<li>Activation function (AF) = you need this function to plug in your <u>estimated</u> regression model.
<ul>
<li><u><strong>Examples of AF</strong></u>:
<ul>
<li>logit,</li>
<li>probit,</li>
<li>relu,</li>
<li>simple “threshold” AF etc…</li>
</ul></li>
</ul></li>
<li>Perceptron = Linear Binary Classifier = usually, the perceptron is a <u>linear</u> separator (= line that separates group in a regression) = <em>Perceptron</em> is a <strong>single layer neural network</strong></li>
<li>Multi-layer perceptron == <em>Neural Networks</em>.
<ul>
<li><u>Example</u>:
<img src="./bilder/machine-learning/example-of-a-multi-layer-network.jpg" alt="Neural Network with 3 Layers" /></li>
</ul></li>
<li>learning rate = how far to go in a particular direction</li>
<li>features = inputs = independent variables “x” = X<sub>ki</sub></li>
<li>labels = this is the “true Y” you observe in the real world = output = dependent variable</li>
<li>“going downhill” = this is the learning process that you get by using the method “gradient decent” (<a href="https://www.youtube.com/watch?v=L-Lsfu4ab74">look youtube video of user called “the coding train” at ca. 17:30</a>) &amp; applying a “learning rate” to it</li>
<li>y<sub>k</sub> = this is the <u>estimated</u> regression function</li>
<li>z<sub>k</sub> = “logits”, e.g. this is the whole <em>sum of the weights multiplied by the x-variables (= entire regression)</em>, but this time we <strong>put this entire regression as an <em>input</em> into the logistic function</strong> –&gt; <u>in other words</u>: the same as y<sub>k</sub> but we then apply the specific activation function “logit function” to the estimated z<sub>k</sub> // <span class="math inline">\(\hat{y}\)</span></li>
<li>Input Layer = Layer 0 = very first set of Neuron</li>
<li>Output Layer = Last Layer = last set of Neurons</li>
<li>Hidden Layers = All Layers between the input &amp; output Layer</li>
<li>input node = nodes at the input layer</li>
<li>output node = nodes at the output layer</li>
<li>hidden nodes = nodes, which are in the hidden layers or at the output layer &amp; don’t give out outputs</li>
<li>Feed forward neural networks = connections only between layer i and layer i+1</li>
<li>Convolutional neural networks = a type of feed-foward network</li>
<li>Recurrent neural networks = connections flow backwards to previous layers as well</li>
<li>supervised learning = function estimation
<ul>
<li><u>There are 2 different types</u>:
<ol style="list-style-type: decimal">
<li>regression,</li>
<li>classification</li>
</ol></li>
</ul></li>
<li>unsupervised learning = structure the data into groups (very subjective) // detecting patterns.
<ul>
<li>Can also be used for:
<ol style="list-style-type: decimal">
<li>data reduction,</li>
<li>outlier detection</li>
</ol></li>
</ul></li>
<li>loss-function = cost-function = [TRUE y - ESTIMATED <span class="math inline">\(\hat{Y}\)</span>]<sup>2</sup> = error –&gt; we define the loss-function be the “least squares”</li>
<li>identity function = y = x bzw. f(x) = x</li>
<li>sigmoid function = logit function</li>
<li>bias term = error term
<ul>
<li><u>Note</u>: Oftmals wird der <strong>“input” für den bias term als Zahl “1”</strong> angegeben (siehe Bild oben “Example of Multi-Layer Network”, wo der bias term als Zahl “1” angegeben ist.)</li>
</ul></li>
<li>Epoch = means we go through the whole data set once –&gt; default is ten epochs</li>
<li>Net Input Function = Regressionsmodell als Ganzes = sum of all weighted inputs // “x”</li>
<li>kernel = (starting) values for the weights</li>
<li>regularizers = penalties that are used to reduce overfitting (of the starting values for the weights?)</li>
<li>backpropagation = back pass = when we have our error-term, we can calculate the gradient and - if the error was too big - we can backpass the error-term with the help of the <em>learning rate</em> to a previous layer and estimate new // better weights</li>
<li>breaking symmetry = principle, which says that you need to have different initial weights for hidden units with the same activation function and same inputs</li>
<li>batches = these are smaller samples that you take from the whole dataset, e.g. you take only a fraction of the dataset –&gt; you use batches because the computation gets faster rather than putting the whole dataset into the machine
learning “Apparat” –&gt; Rule: the higher the batch size, the better estimates you get</li>
<li>decay = In Machine Learning, it has become kind of standard to make learning rates dynamic, e.g. first have bigger learning rates, because you can be very wrong at the beginning with the random weights, but then - towards the end of estimation - you adapt the learning rate only very smoothly, since you slowly go towards the optimum –&gt; typically, this decay will make the learning rate smaller as the training continues.</li>
<li>momentum = makes learning rates dynamic –&gt; If you see that - in the history of gradients - the gradients point generally in the same direction, momentum will adjust the learning rate by increasing the step size</li>
<li>hyperparameters = <u>examples are</u>:
<ul>
<li>Learning rate,</li>
<li>Learning Rate Decay,</li>
<li>Momentum,</li>
<li>Batch Size,</li>
<li>Weight / Bias initialization</li>
</ul></li>
<li>Confusion Matrix = C = shows - in the diagonal of the matrix - how many times your predicted outcome was the same as the actual outcome. All the other numbers are saying that your model’s prediction was not in line with the actual outcome</li>
<li>Precision = if i look at a guess // prediction, how many % my algorithm guessed correctly? –&gt; E.g. Anteil der predicted outcome <span class="math inline">\(\hat{y}\)</span>, welche korrekt mit den ture outcomes übereinstimmen.
<ul>
<li><u>Mathematisch ausgedrückt</u>: Im Zähler die Anzahl an übereinstimmenden predicted outcomes <span class="math inline">\(\hat{y}\)</span> &amp; im Nenner Totale Anzahl an predicted Outcomes <span class="math inline">\(\hat{y}\)</span>.</li>
</ul></li>
<li>Recall = if i look at an actual true outcome, how many % where guessed correctly? –&gt; E.g. Anteil der true outcome Y, welche korrekt vorhergesagt wurden
<ul>
<li><u>Mathematisch ausgedrückt</u>: Im Zähler die Anzahl an korrekt vorhergesehenen true outcomes &amp; im Nenner Totale Anzahl an True Outcomes.</li>
</ul></li>
<li>Training data = Training set is the one on which we train and fit our model basically to fit the parameters.</li>
<li>Testing data = Testing Data is used only to assess performance of the model.</li>
<li>Variance = Overfit = you use too much X’s // features in your model –&gt; you get too much variance in your predictions</li>
<li>Bagging = Train the same architecture on different subsets of data</li>
<li>Boosting = Train different model architectures on the same data</li>
<li>data augmentation = get more data by adding noise on the input layer</li>
<li>weight tying = Make the weights similar</li>
</ul>
<div id="alphabetisch-sortiert" class="section level4">
<h4><span class="header-section-number">9.11.1.1</span> Alphabetisch sortiert:</h4>
<p>Um die Begriffe noch leichter zu finden, habe ich sie hier noch alphabetisch sortiert:</p>
<ul>
<li>Activation function = you need this function to plug in your estimated regression model. Examples of AF = logit, probit, relu, simple “threshold” AF etc…</li>
<li>backpropagation = back pass = when we have our error-term, we can calculate the gradient and - if the error was too big - we can backpass the error-term with
the helplearning rate to a previous layer and estimate new // better weights</li>
<li>batches = these are samples from the whole dataset –&gt; you use batches because the computation gets faster rather than putting the whole dataset into the machine
learning “Apparat” –&gt; Rule: the higher the batch size, the better estimates you get</li>
<li>bias term = error term</li>
<li>breaking symmetry = principle, which says that you need to have different initial weights for hidden units with the same activation function and same inputs</li>
<li>Confusion Matrix = C = shows - in the diagonal of the matrix - how many times your predicted outcome was the same as the actual outcome. All the other numbers are saying that your model’s prediction was not in line with the actual outcome</li>
<li>Convolutional neural networks = a type of feed fowardnetwork</li>
<li>decay = make learning rates dynamic –&gt; typically, this decay will make the learning rate smaller as the training continues.</li>
<li>Epoch = means we go through the whole data set once –&gt; default is ten epochs</li>
<li>features = inputs = independent variables “x” = X(ki)</li>
<li>Feed forward neural networks = connections only between layer i and layer i+1</li>
<li>“going downhill” = this is the learning process that you get by using the method “gradient decent” (look youtube video by “the coding train” at ca. 17:30) &amp; applying a “learning rate” to it</li>
<li>Hidden Layers = All Layers between the input &amp; output Layer</li>
<li>hidden nodes = nodes, which are in the hidden layers or at the output layer &amp; don’t give out outputs</li>
<li>hyperparameters = examples are: Learning rate, Learning Rate Decay, Momentum, Batch Size, Weight / Bias initialization</li>
<li>identity function = y = x bzw. f(x) = x</li>
<li>inputs = Anzahl Observations in Total</li>
<li>Input Layer = Layer 0 = very first set of Neuron</li>
<li>input node = nodes at the input layer</li>
<li>Input units = independent variables “x”</li>
<li>kernel = (starting) values for the weights</li>
<li>labels = this is the “true Y” you observe in the real world = output = dependent variable</li>
<li>learning rate = how far to go in a particular direction</li>
<li>loss-function = cost-function = [TRUE y - ESTIMATED Y(hat)]^2 = error –&gt; we define the loss-function be the “least squares”</li>
<li>Net Input Function = Regressionsmodell als Ganzes = sum of all weighted inputs // “x”</li>
<li>momentum = makes learning rates dynamic –&gt; If you see that - in the history of gradients - the gradients point generally in the same direction, momentum will adjust the learning rate by increasing the step size</li>
<li>Output Layer = Last Layer = last set of Neurons</li>
<li>output node = node at the output layer</li>
<li>Perceptron = Linear Binary Classifier = linear seperator (= line that separates group in a regression) = Perceptron is a single layer neural network and a multi-layer perceptron is called Neural Networks.</li>
<li>Precision = if i look at a guess // prediction, how many % my algorithm guessed correctly?</li>
<li>Recall = if i look at an actual true outcome, how many % where guessed correctly</li>
<li>Recurrent neural networks = connections flow backwards to previous layers as well</li>
<li>regularizers = penalties that are used to reduce overfitting (of the starting values for the weights?)</li>
<li>sigmoid function = logit function</li>
<li>saling = pre-processing data</li>
<li>supervised learning = function estimation –&gt; 2 different types: 1) regression; 2) classification</li>
<li>Training data = Training set is the one on which we train and fit our model basically to fit the parameters.</li>
<li>Testing data = Testing Data is used only to assess performance of the model.
unsupervised learning = structure the data into groups (very subjective) // detecting patterns // data reduction</li>
<li>weights = Beta-Coefficients = parameters = a, b = neurons</li>
<li>y(k) = this is the estimated(!!) regresion function</li>
<li>z(k) = “logits” –&gt; the same as y(k) but we then apply the specific activation function “logit function” to the estimated z(k) // y(hat)</li>
</ul>
</div>
</div>
</div>
<div id="wörterbuch-6" class="section level2">
<h2><span class="header-section-number">9.12</span> Wörterbuch</h2>
<div id="synonyme-3" class="section level3">
<h3><span class="header-section-number">9.12.1</span> Synonyme</h3>
<ul>
<li>Training Dataset // Training Set</li>
<li>Testing Dataset // Test Set</li>
<li>generalize // extrapolate</li>
<li>relativ zu // im Verhältnis zu</li>
<li>feed in // plug in</li>
<li>shape // dimension</li>
<li>target // predicted y-value</li>
<li>Treiber // x-Variablen</li>
<li>Score // Error</li>
<li>Cross-Validation Score // Validation Error</li>
<li>Volume // Speicherplatz</li>
<li>Weights // estimated coefficients</li>
<li>Parameter Tuning // Grid-Search</li>
<li>tweakable parameters // veränderbare Parameter (wenn du Parameter-Tuning)</li>
</ul>
</div>
<div id="data-science" class="section level3">
<h3><span class="header-section-number">9.12.2</span> Data Science</h3>
<ul>
<li><strong>Samples</strong> == number of rows // number of observations within a dataset.</li>
<li><strong>Instance</strong>: value within a cell –&gt; konkreter “x”-Wert, welcher angenommen wird und du - beispielsweise - für eine Prediction verwenden kannst.</li>
</ul>
<div class="figure">
<img src="./bilder/python-lib/pandas-df.jpg" alt="" />
<p class="caption">This is the overview of a <code>Pandas</code> DataFrame, where an instance would be nothing else but a “value”.</p>
</div>
<ul>
<li><strong>Label</strong>: <em>true</em> y-value</li>
<li><strong>Forcasted data</strong>: These are the predictions that you do via the help of a model (–&gt; by plugging in concrete x-values), that you’ve built.</li>
<li><strong>Training Dataset</strong>: This is the sample, that you use to estimate your model.</li>
<li><strong>Testing Dataset</strong>: This is the <code>hold out</code>-set, which you use at the end, to check whether your model is able to generalize // extrapolate well to new data.</li>
<li><strong>“The model is learning”</strong>: What is meant by “learning” is –&gt; given some Datenpunkt-Wolke, the computer will try and fit the “best line” [oftentimes by minimizing the sum of the squared residuals, if you use <code>OLS</code> (= Ordinary Least Squared) OR by using the <em>Gradient Descend Method</em>, when you have more data] to construct the “best model” possible.</li>
<li><strong>Training</strong>: You are estimating a model on the trainig-dataset, such that the model “learns” from the data.</li>
<li><strong>Bias</strong>: When a modl displays “bias”, then it means that your model is too simpel (not enough <code>X</code>-variables included, for example) and - as a result - your estimated <code>sample regression function</code> is not able to approximate the (true) underlying (unknown) <code>population regression function</code>.
<img src="./bilder/home/def-bias-from-google.png" alt="Alternatively, this is the definition, Google-Researchers gave to bias." /></li>
<li><strong>Overfitting</strong>: The problem of overfitting occurs when a model is <strong>too complex and captures too much detail</strong> from the <em>training</em> data. This can lead to the model being unable to generalize to new, unseen data.
<ul>
<li><u>Fazit</u>: This is like the problem of “<strong>low external validity</strong>”. You may have a high “internal validity”, but external validity is <em>low</em>!</li>
</ul></li>
<li><strong>Shuffle</strong>: englisches Wort für “mischen”. In the context of <code>splitting the dataset into test- &amp; training-data</code>, it is common practice to <code>shuffle</code> your observations within your dataset first.
<ul>
<li><u>Reason why you <code>shuffle</code></u>?: Shuffling data serves the purpose of
<ul>
<li>reducing variance AND</li>
<li>making sure that models remain general AND</li>
<li>overfit less.</li>
</ul></li>
<li><u>Merke</u>: When dealing with <em>time-series</em>, you should not use <code>shuffle</code> when <code>splitting the data</code> into training- &amp; testing-data.</li>
</ul></li>
<li><strong>Training Score OR Test Error</strong>: This error // score is the [oftentimes squared] difference between the <em>true</em> Y-variable and <em>predicted</em> Y-variable (= <span class="math inline">\(\hat{y}\)</span>).
<ul>
<li>Note that the for the formula <span class="math inline">\(\sum_i^N{(y_i-\hat{y_i})}\)</span>, the <strong><span class="math inline">\(y_i\)</span></strong> can be either related to:
<ul>
<li>The <strong>test</strong>-set, when you are evaluating the <em>final</em> model-performance, OR</li>
<li>The <strong>validation</strong>-dataset, when you are evaluating how well the model is “performing” with the help of <em>Cross Validation</em>, e.g. how the model performs with an increasingly bigger <code>training dataset</code>.</li>
</ul></li>
</ul></li>
<li><strong>Cross-Validation Score</strong>: This is the <em>mean</em> error // score that <strong>measures // evaluates how the model is “learning” over increasingly bigger <code>training datasets</code></strong>.
<ul>
<li>It is important to highlight the fact that this metric is only a <em>mean</em>, e.g. you don’t see the <em>individual</em> forecast that was being made.</li>
<li>The <strong>main purpose</strong> of this metric is to be able <strong>to judge the model-performance very quickly: with only 1 single number, namely the mean error (by an increasing amount of sample-size)</strong>.</li>
<li>If you have a “bad” model - e.g. a high mean error - you will need to look at the <em>individual</em> errors (and not just the mean error), in order to understand what went wrong with the model!</li>
</ul></li>
<li><strong>Fold</strong> == <strong>subset</strong> of the <code>training dataset</code>.
<ul>
<li><u>Example</u>: In a <code>K-Fold Cross-Validation</code>, you <em>randomly</em> split the <u>training set</u> into <strong>10 distinct subsets</strong>, which are called <code>folds</code>.</li>
</ul></li>
<li><strong>Grid</strong>: Das ist nichts anderes als die <strong>Optimierung von diversen “Modell-Parametern”</strong>.
- <u>Beispiel</u>: Bei Random-Forrest Modellen kann man zum Beispiel die Tiefe eines Modells bestimmen, dh die relevante Frage, welche ein Forscher sich stellt, ist: <strong><em>wie viele Baum-Zweigungen die geeignesten Predictions bringen?</em></strong>. Mit Funktionen, wie zum Beispiel <code>GridSearchCV()</code> kann dieses Problem geregelt werden.</li>
<li><strong>Classifiers</strong>: These are simply Regression-Functions, where <strong>the Y-variable is binary</strong>, e.g. die Y-Variable kann nur <code>Y = 0</code> <u>oder</u> <code>Y= = 1</code> als Werte annehmen.
<ul>
<li><u>Beispiele</u>:
<ul>
<li>Logit-Regression</li>
<li>Probit-Regression</li>
<li>Naive Bayes</li>
<li>etc…</li>
<li><u>Example</u>: Logit- &amp; Probit-Regression, or Naiv Bayes, etc…</li>
</ul></li>
</ul></li>
<li><strong>feed in</strong>: Häufig im Zusammenhang mit Einsetzen von konkreten Werten für die x-Variablen in das <em>geschätzte</em> Modell, um Predictions zu erhalten.</li>
<li><strong>Batch</strong>: sample-size when you train your model with a dataset.</li>
<li><strong>Granularität</strong> (Beispiel): Angenommen, man möchte wissen, wie viele Tage, Stunden, Minuten und Sekunden innerhalb von 20’044 Sekunden enthalten sind → hier haben wir also <em>Granularität von 4</em> →
<ul>
<li><u>Lösung</u>: 4 Tage, 18 Stunden, 37 Minuten, 44 Sekunden</li>
</ul></li>
<li><strong>Kalibrierung des Modells</strong>: Wie wurde das Modell programmiert im Allgemeinen? → Dazu gehört - beim <code>preisprog</code>-Projekt der SBB - die Anpassung der Prognose.</li>
<li><strong>Extrapolation</strong>: Das ist eine <em>Prediction</em>, welche mittels X-Variablen ermittelt werden, welche <u>zuvor nicht im Datensatz</u> waren.</li>
<li><strong>Interpolation</strong>: Das ist eine <em>Prediction</em>, welche mittels X-Variablen ermittelt werden, welche <u>bereits im Datensatz</u> waren, als die Schätzung getätigt wurde.
<strong>Pearson Korrelation</strong> == <u>Lineare</u> Korrelation</li>
</ul>
<div class="figure">
<img src="./bilder/machine-learning/pearson-corr-matrix.png" alt="" />
<p class="caption">Beispiel einer Pearson-Korrelations Matrix</p>
</div>
</div>
<div id="time-series-1" class="section level3">
<h3><span class="header-section-number">9.12.3</span> Time-Series</h3>
<ul>
<li><strong>Sliding Window</strong>: This is just a way to tell python <strong>how to do a particular type of cross-validation</strong> and have equal lengths of time series where we can learn on.</li>
<li><strong>Forecasting Horizon</strong>: These are the points in time (in the future), for which you want to make a prediction (= <span class="math inline">\(\hat{y}\)</span>). This is something, you need to define, when you want to estimate your model in a <em>time-series</em> setting.</li>
<li><strong>Learning Task</strong>: Forecasting Task // Extrapolation [in Time Series] –&gt; <em>not sure if this is correct</em>… xD</li>
<li><strong>Time Heterogenous Data</strong>: These are different time-series datasets, that have different time stamps.
<ul>
<li><u>Quelle</u>: Ab 27:05 (Link: <a href="http://www.youtube.com/watch?v=Wf2naBHRo8Q&amp;t=27m05s" class="uri">http://www.youtube.com/watch?v=Wf2naBHRo8Q&amp;t=27m05s</a>)</li>
</ul></li>
<li><strong>Seasonal Periodicity</strong>: The number of times per year, in which the forecaster expects to see a seasonal pattern.
<ul>
<li><u>Concrete Example</u>: In Philipp’s Notebook, he had a seasonal periodicity of 2, e.g. he said that in winter &amp; sommer, he expects a seasonal pattern.</li>
</ul></li>
<li><strong>“Reduction is composable”</strong>: Synonym wäre “addieren” → E.g. you can split a difficult task into a bunch of smaller tasks (= <code>reduction</code>) and “add” them together to solve the bigger task at the end → “reduction is composable”…</li>
</ul>
</div>
</div>
<div id="quellen" class="section level2">
<h2><span class="header-section-number">9.13</span> Quellen</h2>
<ul>
<li><a href="https://blog.exxactcorp.com/lets-learn-the-difference-between-a-deep-learning-cnn-and-rnn/" class="uri">https://blog.exxactcorp.com/lets-learn-the-difference-between-a-deep-learning-cnn-and-rnn/</a>
<a href="https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/notes/Sonia_Hornik.pdf" class="uri">https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/notes/Sonia_Hornik.pdf</a></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="econometrics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mengenlehre.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/joffreymayer/ds-from-scratch/edit/master/09-machine-learning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/joffreymayer/ds-from-scratch/blob/master/09-machine-learning.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
