<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Econometrics | Data Science from Scratch Code</title>
  <meta name="description" content="Chapter 8 Econometrics | Data Science from Scratch Code" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Econometrics | Data Science from Scratch Code" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Econometrics | Data Science from Scratch Code" />
  
  
  

<meta name="author" content="Joffrey Anthony" />


<meta name="date" content="2022-05-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="git-versioncontrol.html"/>
<link rel="next" href="machine-learning-1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DS from Scratch Codes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Computer Set-Up</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#mac-tricks"><i class="fa fa-check"></i><b>1.1</b> Mac Tricks</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#öffne-die-developer-tools-von-google-chrome"><i class="fa fa-check"></i><b>1.1.1</b> Öffne die Developer-Tools von Google-Chrome</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#speichern"><i class="fa fa-check"></i><b>1.1.2</b> Speichern</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#speichern-unter"><i class="fa fa-check"></i><b>1.1.3</b> Speichern Unter</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#finder"><i class="fa fa-check"></i><b>1.1.4</b> Finder</a></li>
<li class="chapter" data-level="1.1.5" data-path="index.html"><a href="index.html#programm-schliessen"><i class="fa fa-check"></i><b>1.1.5</b> Programm schliessen</a></li>
<li class="chapter" data-level="1.1.6" data-path="index.html"><a href="index.html#neuer-ordner"><i class="fa fa-check"></i><b>1.1.6</b> Neuer Ordner</a></li>
<li class="chapter" data-level="1.1.7" data-path="index.html"><a href="index.html#tilde-zeichen"><i class="fa fa-check"></i><b>1.1.7</b> Tilde Zeichen</a></li>
<li class="chapter" data-level="1.1.8" data-path="index.html"><a href="index.html#backslash"><i class="fa fa-check"></i><b>1.1.8</b> Backslash</a></li>
<li class="chapter" data-level="1.1.9" data-path="index.html"><a href="index.html#screenshot-vom-bildschirm"><i class="fa fa-check"></i><b>1.1.9</b> Screenshot vom Bildschirm</a></li>
<li class="chapter" data-level="1.1.10" data-path="index.html"><a href="index.html#teil-des-bildschirms-screen-schoten"><i class="fa fa-check"></i><b>1.1.10</b> Teil des Bildschirms Screen-Schoten</a></li>
<li class="chapter" data-level="1.1.11" data-path="index.html"><a href="index.html#verlauf-löschen-in-chrome-browser"><i class="fa fa-check"></i><b>1.1.11</b> Verlauf löschen in Chrome Browser</a></li>
<li class="chapter" data-level="1.1.12" data-path="index.html"><a href="index.html#verlauf-löschen-safari"><i class="fa fa-check"></i><b>1.1.12</b> Verlauf löschen Safari</a></li>
<li class="chapter" data-level="1.1.13" data-path="index.html"><a href="index.html#bildschirm-aufnahme"><i class="fa fa-check"></i><b>1.1.13</b> Bildschirm Aufnahme</a></li>
<li class="chapter" data-level="1.1.14" data-path="index.html"><a href="index.html#lesezeichen-in-google-chrome"><i class="fa fa-check"></i><b>1.1.14</b> Lesezeichen in Google Chrome</a></li>
<li class="chapter" data-level="1.1.15" data-path="index.html"><a href="index.html#search-console-pop-up"><i class="fa fa-check"></i><b>1.1.15</b> Search Console Pop Up</a></li>
<li class="chapter" data-level="1.1.16" data-path="index.html"><a href="index.html#format-kopieren-einer-zelle-in-numbers"><i class="fa fa-check"></i><b>1.1.16</b> Format Kopieren einer Zelle (in Numbers)</a></li>
<li class="chapter" data-level="1.1.17" data-path="index.html"><a href="index.html#format-übertragen-einer-zelle-in-numbers"><i class="fa fa-check"></i><b>1.1.17</b> Format übertragen einer Zelle (in Numbers)</a></li>
<li class="chapter" data-level="1.1.18" data-path="index.html"><a href="index.html#switch-between-applications-on-your-computer"><i class="fa fa-check"></i><b>1.1.18</b> Switch between Applications on your computer</a></li>
<li class="chapter" data-level="1.1.19" data-path="index.html"><a href="index.html#move-forward-through-tabs"><i class="fa fa-check"></i><b>1.1.19</b> Move Forward through Tabs</a></li>
<li class="chapter" data-level="1.1.20" data-path="index.html"><a href="index.html#zahl-als-exponent"><i class="fa fa-check"></i><b>1.1.20</b> Zahl als Exponent</a></li>
<li class="chapter" data-level="1.1.21" data-path="index.html"><a href="index.html#source-code-einer-webseite-aufschalten"><i class="fa fa-check"></i><b>1.1.21</b> Source-Code einer Webseite aufschalten</a></li>
<li class="chapter" data-level="1.1.22" data-path="index.html"><a href="index.html#interaktive-code-ansicht-für-das-abchecken-von-webseiten"><i class="fa fa-check"></i><b>1.1.22</b> Interaktive Code-Ansicht für das Abchecken von Webseiten</a></li>
<li class="chapter" data-level="1.1.23" data-path="index.html"><a href="index.html#approximate-symbol"><i class="fa fa-check"></i><b>1.1.23</b> Approximate Symbol <code>≈</code></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#virtual-environment"><i class="fa fa-check"></i><b>1.2</b> Virtual Environment</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#create-a-venv"><i class="fa fa-check"></i><b>1.2.1</b> Create a <code>venv</code></a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#activate-your-newly-created-venv"><i class="fa fa-check"></i><b>1.2.2</b> Activate your newly created <code>venv</code></a></li>
<li class="chapter" data-level="1.2.3" data-path="index.html"><a href="index.html#install-packages"><i class="fa fa-check"></i><b>1.2.3</b> Install packages</a></li>
<li class="chapter" data-level="1.2.4" data-path="index.html"><a href="index.html#overview-of-packages"><i class="fa fa-check"></i><b>1.2.4</b> Overview of packages</a></li>
<li class="chapter" data-level="1.2.5" data-path="index.html"><a href="index.html#overview-of-every-venv"><i class="fa fa-check"></i><b>1.2.5</b> Overview of every <code>venv</code></a></li>
<li class="chapter" data-level="1.2.6" data-path="index.html"><a href="index.html#execute-any-python-skript"><i class="fa fa-check"></i><b>1.2.6</b> Execute any python skript</a></li>
<li class="chapter" data-level="1.2.7" data-path="index.html"><a href="index.html#deactivate-the-venv"><i class="fa fa-check"></i><b>1.2.7</b> Deactivate the <code>venv</code></a></li>
<li class="chapter" data-level="1.2.8" data-path="index.html"><a href="index.html#delete-a-venv"><i class="fa fa-check"></i><b>1.2.8</b> Delete a <code>venv</code></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-to-efficiently-manage-a-project"><i class="fa fa-check"></i><b>1.3</b> How to efficiently manage a Project?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#create-a-website-on-github-for-free"><i class="fa fa-check"></i><b>1.3.1</b> Create a Website on Github (for free)</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#r-markdown-syntax"><i class="fa fa-check"></i><b>1.3.2</b> R Markdown Syntax</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#terminal-commands"><i class="fa fa-check"></i><b>1.4</b> Terminal-Commands:</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#aktuelle-position-directory"><i class="fa fa-check"></i><b>1.4.1</b> Aktuelle Position // Directory?</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#showing-the-child-directories-inside-the-directory-you-are-currently-in"><i class="fa fa-check"></i><b>1.4.2</b> Showing the child-directories inside the directory you are currently in?</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#delete-everything-you-wrote-in-your-terminal-up-until-now"><i class="fa fa-check"></i><b>1.4.3</b> Delete everything you wrote in your <code>Terminal</code> up until now?</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#change-directory"><i class="fa fa-check"></i><b>1.4.4</b> Change directory?</a></li>
<li class="chapter" data-level="1.4.5" data-path="index.html"><a href="index.html#creating-a-new-directory"><i class="fa fa-check"></i><b>1.4.5</b> Creating a new directory?</a></li>
<li class="chapter" data-level="1.4.6" data-path="index.html"><a href="index.html#create-a-new-file"><i class="fa fa-check"></i><b>1.4.6</b> Create a new file?</a></li>
<li class="chapter" data-level="1.4.7" data-path="index.html"><a href="index.html#remove-files"><i class="fa fa-check"></i><b>1.4.7</b> Remove files?</a></li>
<li class="chapter" data-level="1.4.8" data-path="index.html"><a href="index.html#open-the-current-directory-you-are-in"><i class="fa fa-check"></i><b>1.4.8</b> Open the current directory you are in?</a></li>
<li class="chapter" data-level="1.4.9" data-path="index.html"><a href="index.html#terminal-magic-commands-for-being-faster"><i class="fa fa-check"></i><b>1.4.9</b> Terminal Magic-Commands for being faster?</a></li>
<li class="chapter" data-level="1.4.10" data-path="index.html"><a href="index.html#syntax-im-terminal"><i class="fa fa-check"></i><b>1.4.10</b> Syntax im Terminal</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#how-to-activate-use-python"><i class="fa fa-check"></i><b>1.5</b> How to activate &amp; use Python?</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#latex"><i class="fa fa-check"></i><b>1.6</b> LaTeX</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#what-is-the-latex-code-for-haty"><i class="fa fa-check"></i><b>1.6.1</b> What is the LaTeX-Code for <span class="math inline">\(\hat{y}\)</span>?</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#useful-websites"><i class="fa fa-check"></i><b>1.6.2</b> Useful Websites</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#wörterbuch"><i class="fa fa-check"></i><b>1.7</b> Wörterbuch</a><ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#data-science-vs.-mein-economics-studium"><i class="fa fa-check"></i><b>1.7.1</b> Data Science VS. mein Economics-Studium</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#why-data-science-starts-with-data-visualization-the-key-thing-i-learned"><i class="fa fa-check"></i><b>1.8</b> Why Data-Science starts with Data-Visualization | The Key-Thing I learned</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#ausblick"><i class="fa fa-check"></i><b>1.9</b> Ausblick</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html"><i class="fa fa-check"></i><b>2</b> Foundatios of Programming</a><ul>
<li class="chapter" data-level="2.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#how-to-program"><i class="fa fa-check"></i><b>2.1</b> How to Program?</a></li>
<li class="chapter" data-level="2.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#wörterbuch-1"><i class="fa fa-check"></i><b>2.2</b> Wörterbuch</a><ul>
<li class="chapter" data-level="2.2.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#synonyme"><i class="fa fa-check"></i><b>2.2.1</b> Synonyme</a></li>
<li class="chapter" data-level="2.2.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#programming"><i class="fa fa-check"></i><b>2.2.2</b> Programming</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#data-types"><i class="fa fa-check"></i><b>2.3</b> Data-Types</a></li>
<li class="chapter" data-level="2.4" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#global-variables-vs.-local-variables"><i class="fa fa-check"></i><b>2.4</b> Global Variables VS. Local Variables</a></li>
<li class="chapter" data-level="2.5" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#what-is-python-the-context"><i class="fa fa-check"></i><b>2.5</b> What is Python? | The Context</a><ul>
<li class="chapter" data-level="2.5.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#types-of-programming-languages"><i class="fa fa-check"></i><b>2.5.1</b> Types of Programming Languages</a></li>
<li class="chapter" data-level="2.5.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#programming-paradigms-of-a-programming-language"><i class="fa fa-check"></i><b>2.5.2</b> Programming-Paradigms of a Programming-Language</a></li>
<li class="chapter" data-level="2.5.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#purpose-based-vs.-general-purpose-programming-languages"><i class="fa fa-check"></i><b>2.5.3</b> Purpose-Based VS. General-Purpose Programming Languages</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#python-basics"><i class="fa fa-check"></i><b>2.6</b> Python-Basics</a><ul>
<li class="chapter" data-level="2.6.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#magic-commands-in-python-keyboard-shortcuts"><i class="fa fa-check"></i><b>2.6.1</b> Magic Commands in Python | Keyboard-Shortcuts</a></li>
<li class="chapter" data-level="2.6.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#wörterbuch-2"><i class="fa fa-check"></i><b>2.6.2</b> Wörterbuch</a></li>
<li class="chapter" data-level="2.6.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#tricks"><i class="fa fa-check"></i><b>2.6.3</b> Tricks</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#object-oriented-programming"><i class="fa fa-check"></i><b>2.7</b> Object Oriented Programming</a><ul>
<li class="chapter" data-level="2.7.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#reason-why-we-use-oop"><i class="fa fa-check"></i><b>2.7.1</b> Reason why, we use OOP</a></li>
<li class="chapter" data-level="2.7.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#konzept"><i class="fa fa-check"></i><b>2.7.2</b> Konzept</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#r-as-your-ide"><i class="fa fa-check"></i><b>2.8</b> R as your IDE</a><ul>
<li class="chapter" data-level="2.8.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#pipe-operator-in-r"><i class="fa fa-check"></i><b>2.8.1</b> Pipe-Operator in R</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#restful-api"><i class="fa fa-check"></i><b>2.9</b> Restful API</a></li>
<li class="chapter" data-level="2.10" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#more-advanced-topics"><i class="fa fa-check"></i><b>2.10</b> More advanced Topics</a><ul>
<li class="chapter" data-level="2.10.1" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#data-pipeline"><i class="fa fa-check"></i><b>2.10.1</b> Data Pipeline</a></li>
<li class="chapter" data-level="2.10.2" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#fundamental-daten"><i class="fa fa-check"></i><b>2.10.2</b> Fundamental-Daten</a></li>
<li class="chapter" data-level="2.10.3" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#data-flow"><i class="fa fa-check"></i><b>2.10.3</b> Data-Flow</a></li>
<li class="chapter" data-level="2.10.4" data-path="foundatios-of-programming.html"><a href="foundatios-of-programming.html#docker"><i class="fa fa-check"></i><b>2.10.4</b> Docker</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html"><i class="fa fa-check"></i><b>3</b> Foundations of Data Science</a><ul>
<li class="chapter" data-level="3.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#allgemeine-roadmap-für-data-science-projekte"><i class="fa fa-check"></i><b>3.1</b> Allgemeine Roadmap für Data-Science Projekte</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#management-eines-ds-projektes-the-step-by-step-guide"><i class="fa fa-check"></i><b>3.2</b> Management eines DS-Projektes | The Step-by-Step Guide</a><ul>
<li class="chapter" data-level="3.2.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-0---correct-initialization-of-a-project"><i class="fa fa-check"></i><b>3.2.1</b> Phase 0 - Correct initialization of a Project</a></li>
<li class="chapter" data-level="3.2.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-1---get-the-data-erste-recherchearbeit"><i class="fa fa-check"></i><b>3.2.2</b> Phase 1 - Get the Data &amp; erste Recherchearbeit</a></li>
<li class="chapter" data-level="3.2.3" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-2---load-the-data-vanilla-exploration"><i class="fa fa-check"></i><b>3.2.3</b> Phase 2 - Load the Data &amp; Vanilla Exploration</a></li>
<li class="chapter" data-level="3.2.4" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-3---after-having-concluded-my-data-is-ok-wie-geht-es-weiter"><i class="fa fa-check"></i><b>3.2.4</b> Phase 3 - After having concluded: “My data is OK!” | Wie geht es weiter?</a></li>
<li class="chapter" data-level="3.2.5" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-4---model-estimation-applying-machine-learning-on-the-data"><i class="fa fa-check"></i><b>3.2.5</b> Phase 4 - Model Estimation | Applying Machine-Learning on the Data</a></li>
<li class="chapter" data-level="3.2.6" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#phase-5---deployment-erstellung-eines-minimal-viable-product-abschluss-des-projektes"><i class="fa fa-check"></i><b>3.2.6</b> Phase 5 - Deployment: Erstellung eines Minimal Viable Product | Abschluss des Projektes</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#fragestellungen-beantworten"><i class="fa fa-check"></i><b>3.3</b> Fragestellungen beantworten</a><ul>
<li class="chapter" data-level="3.3.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#methoden-liste-an-diverser-technologien-um-fragestellungen-zu-beantworten"><i class="fa fa-check"></i><b>3.3.1</b> Methoden | Liste an diverser Technologien, um Fragestellungen zu beantworten</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#find-data"><i class="fa fa-check"></i><b>3.4</b> Find Data</a><ul>
<li class="chapter" data-level="3.4.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#sport-daten"><i class="fa fa-check"></i><b>3.4.1</b> Sport-Daten</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#die-kunst-des-feature-engineering-für-gute-modellierung-effizienter-modellieren"><i class="fa fa-check"></i><b>3.5</b> Die “Kunst des Feature-Engineering” für gute Modellierung | Effizienter Modellieren</a><ul>
<li class="chapter" data-level="3.5.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#geographie"><i class="fa fa-check"></i><b>3.5.1</b> Geographie</a></li>
<li class="chapter" data-level="3.5.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#finance"><i class="fa fa-check"></i><b>3.5.2</b> Finance</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#allgemeine-schwächen-von-data-science"><i class="fa fa-check"></i><b>3.6</b> Allgemeine Schwächen von Data-Science</a><ul>
<li class="chapter" data-level="3.6.1" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#visualisierungen-für-erklärungen-verwenden"><i class="fa fa-check"></i><b>3.6.1</b> Visualisierungen für Erklärungen verwenden</a></li>
<li class="chapter" data-level="3.6.2" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#nur-20-der-data-science-projekte-haben-erfolg-apropos-geld"><i class="fa fa-check"></i><b>3.6.2</b> Nur 20% der Data-Science Projekte haben “Erfolg” | Apropos Geld…</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="foundations-of-data-science.html"><a href="foundations-of-data-science.html#appendix-for-the-future"><i class="fa fa-check"></i><b>3.7</b> Appendix for the Future</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="python-libraries.html"><a href="python-libraries.html"><i class="fa fa-check"></i><b>4</b> Python Libraries</a><ul>
<li class="chapter" data-level="4.1" data-path="python-libraries.html"><a href="python-libraries.html#list-of-useful-python-libraries"><i class="fa fa-check"></i><b>4.1</b> List of Useful Python-Libraries</a></li>
<li class="chapter" data-level="4.2" data-path="python-libraries.html"><a href="python-libraries.html#python-mustercodes-für-data-science"><i class="fa fa-check"></i><b>4.2</b> <code>Python</code>-Mustercodes für Data-Science</a></li>
<li class="chapter" data-level="4.3" data-path="python-libraries.html"><a href="python-libraries.html#basic-python"><i class="fa fa-check"></i><b>4.3</b> Basic <code>Python</code></a><ul>
<li class="chapter" data-level="4.3.1" data-path="python-libraries.html"><a href="python-libraries.html#put-a-time-stamp-on-each-python-cell"><i class="fa fa-check"></i><b>4.3.1</b> Put a time-stamp on each Python-Cell</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="python-libraries.html"><a href="python-libraries.html#pandas-library"><i class="fa fa-check"></i><b>4.4</b> Pandas Library</a><ul>
<li class="chapter" data-level="4.4.1" data-path="python-libraries.html"><a href="python-libraries.html#padas-dataframe"><i class="fa fa-check"></i><b>4.4.1</b> Padas DataFrame</a></li>
<li class="chapter" data-level="4.4.2" data-path="python-libraries.html"><a href="python-libraries.html#how-to-display-all-the-columns"><i class="fa fa-check"></i><b>4.4.2</b> How to display all the columns?</a></li>
<li class="chapter" data-level="4.4.3" data-path="python-libraries.html"><a href="python-libraries.html#drop-missing-values"><i class="fa fa-check"></i><b>4.4.3</b> Drop Missing-values?</a></li>
<li class="chapter" data-level="4.4.4" data-path="python-libraries.html"><a href="python-libraries.html#loc--vs.-iloc-selection"><i class="fa fa-check"></i><b>4.4.4</b> <code>loc</code>- VS. <code>iloc</code>-Selection</a></li>
<li class="chapter" data-level="4.4.5" data-path="python-libraries.html"><a href="python-libraries.html#drop-a-column-with-the-pop-method"><i class="fa fa-check"></i><b>4.4.5</b> Drop a Column with the <code>pop()</code>-Method</a></li>
<li class="chapter" data-level="4.4.6" data-path="python-libraries.html"><a href="python-libraries.html#convert-into-date-time-format-with-the-to_datetime-method"><i class="fa fa-check"></i><b>4.4.6</b> Convert into “Date-Time”-format with the <code>to_datetime()</code>-Method</a></li>
<li class="chapter" data-level="4.4.7" data-path="python-libraries.html"><a href="python-libraries.html#umgekehrt-use-the-strftime-method-to-convert-a-date-column-back-into-a-string-format"><i class="fa fa-check"></i><b>4.4.7</b> <u>Umgekehrt</u>: Use the <code>strftime()</code>-Method to convert a Date-Column back into a “String”-Format</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="python-libraries.html"><a href="python-libraries.html#statsmodels"><i class="fa fa-check"></i><b>4.5</b> Statsmodels</a><ul>
<li class="chapter" data-level="4.5.1" data-path="python-libraries.html"><a href="python-libraries.html#useful-nice-to-knows"><i class="fa fa-check"></i><b>4.5.1</b> Useful Nice-to-Knows</a></li>
<li class="chapter" data-level="4.5.2" data-path="python-libraries.html"><a href="python-libraries.html#define-the-y-variable-x-variables"><i class="fa fa-check"></i><b>4.5.2</b> Define the <code>y</code>-variable &amp; <code>X</code>-variable<u>s</u></a></li>
<li class="chapter" data-level="4.5.3" data-path="python-libraries.html"><a href="python-libraries.html#estimate-a-model"><i class="fa fa-check"></i><b>4.5.3</b> Estimate a Model</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="python-libraries.html"><a href="python-libraries.html#time-series-forecasting"><i class="fa fa-check"></i><b>4.6</b> Time-Series Forecasting</a><ul>
<li class="chapter" data-level="4.6.1" data-path="python-libraries.html"><a href="python-libraries.html#working-with-date-columns"><i class="fa fa-check"></i><b>4.6.1</b> Working with <code>Date</code>-Columns</a></li>
<li class="chapter" data-level="4.6.2" data-path="python-libraries.html"><a href="python-libraries.html#facebook-prophet-library"><i class="fa fa-check"></i><b>4.6.2</b> Facebook Prophet Library</a></li>
<li class="chapter" data-level="4.6.3" data-path="python-libraries.html"><a href="python-libraries.html#sklearn-library"><i class="fa fa-check"></i><b>4.6.3</b> SkLearn Library</a></li>
<li class="chapter" data-level="4.6.4" data-path="python-libraries.html"><a href="python-libraries.html#sktime-library"><i class="fa fa-check"></i><b>4.6.4</b> SkTime Library</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="python-libraries.html"><a href="python-libraries.html#tensorflow"><i class="fa fa-check"></i><b>4.7</b> Tensorflow</a><ul>
<li class="chapter" data-level="4.7.1" data-path="python-libraries.html"><a href="python-libraries.html#definition"><i class="fa fa-check"></i><b>4.7.1</b> Definition</a></li>
<li class="chapter" data-level="4.7.2" data-path="python-libraries.html"><a href="python-libraries.html#tensorflow-vs.-pytorch"><i class="fa fa-check"></i><b>4.7.2</b> Tensorflow VS. PyTorch</a></li>
<li class="chapter" data-level="4.7.3" data-path="python-libraries.html"><a href="python-libraries.html#data-windowing-konzept-erklärung-mittels-beispielen"><i class="fa fa-check"></i><b>4.7.3</b> Data-Windowing Konzept | Erklärung mittels Beispielen</a></li>
<li class="chapter" data-level="4.7.4" data-path="python-libraries.html"><a href="python-libraries.html#wörterbuch-3"><i class="fa fa-check"></i><b>4.7.4</b> Wörterbuch</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i><b>5</b> Visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="visualization.html"><a href="visualization.html#graphs-with-python"><i class="fa fa-check"></i><b>5.1</b> Graphs with Python</a><ul>
<li class="chapter" data-level="5.1.1" data-path="visualization.html"><a href="visualization.html#seaborn"><i class="fa fa-check"></i><b>5.1.1</b> Seaborn</a></li>
<li class="chapter" data-level="5.1.2" data-path="visualization.html"><a href="visualization.html#matplotlib"><i class="fa fa-check"></i><b>5.1.2</b> Matplotlib</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="visualization.html"><a href="visualization.html#statistics"><i class="fa fa-check"></i><b>5.2</b> Statistics</a><ul>
<li class="chapter" data-level="5.2.1" data-path="visualization.html"><a href="visualization.html#the-normal-distribution"><i class="fa fa-check"></i><b>5.2.1</b> The Normal Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="improve-yourself-constantly.html"><a href="improve-yourself-constantly.html"><i class="fa fa-check"></i><b>6</b> Improve Yourself Constantly</a><ul>
<li class="chapter" data-level="6.1" data-path="improve-yourself-constantly.html"><a href="improve-yourself-constantly.html#to-share"><i class="fa fa-check"></i><b>6.1</b> To Share</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html"><i class="fa fa-check"></i><b>7</b> Git Versioncontrol</a><ul>
<li class="chapter" data-level="7.1" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#wörterbuch-4"><i class="fa fa-check"></i><b>7.1</b> Wörterbuch</a></li>
<li class="chapter" data-level="7.2" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#first-time-using-git-github"><i class="fa fa-check"></i><b>7.2</b> First time using Git &amp; Github</a></li>
<li class="chapter" data-level="7.3" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#key-concepts-in-git"><i class="fa fa-check"></i><b>7.3</b> 2 Key concepts in Git</a><ul>
<li class="chapter" data-level="7.3.1" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#start-project-via-github-remote-possibility"><i class="fa fa-check"></i><b>7.3.1</b> Start Project via Github | Remote-Possibility</a></li>
<li class="chapter" data-level="7.3.2" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#start-project-via-local-computer-local-possibility"><i class="fa fa-check"></i><b>7.3.2</b> Start Project via local computer | Local-Possibility</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#working-with-branches"><i class="fa fa-check"></i><b>7.4</b> Working with Branches</a></li>
<li class="chapter" data-level="7.5" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#set-up-an-ssh-key-for-github"><i class="fa fa-check"></i><b>7.5</b> Set-Up an SSH-Key for Github</a></li>
<li class="chapter" data-level="7.6" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#create-a-.gitignore-file"><i class="fa fa-check"></i><b>7.6</b> Create a <code>.gitignore</code>-file</a></li>
<li class="chapter" data-level="7.7" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#speicherplatz-verwendet-durch-git-history"><i class="fa fa-check"></i><b>7.7</b> Speicherplatz verwendet durch <code>Git</code>-History</a></li>
<li class="chapter" data-level="7.8" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#unstage-everything"><i class="fa fa-check"></i><b>7.8</b> Unstage everything</a></li>
<li class="chapter" data-level="7.9" data-path="git-versioncontrol.html"><a href="git-versioncontrol.html#stage-only-a-certain-type-of-file---for-example---only-.html-files"><i class="fa fa-check"></i><b>7.9</b> Stage only a certain type of file - for example - only <code>.html</code>-files</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="econometrics.html"><a href="econometrics.html"><i class="fa fa-check"></i><b>8</b> Econometrics</a><ul>
<li class="chapter" data-level="8.1" data-path="econometrics.html"><a href="econometrics.html#synonyme-2"><i class="fa fa-check"></i><b>8.1</b> Synonyme:</a></li>
<li class="chapter" data-level="8.2" data-path="econometrics.html"><a href="econometrics.html#english-words-synonyme"><i class="fa fa-check"></i><b>8.2</b> English Words Synonyme</a></li>
<li class="chapter" data-level="8.3" data-path="econometrics.html"><a href="econometrics.html#allgemeines"><i class="fa fa-check"></i><b>8.3</b> Allgemeines</a></li>
<li class="chapter" data-level="8.4" data-path="econometrics.html"><a href="econometrics.html#statistics-formulas"><i class="fa fa-check"></i><b>8.4</b> Statistics Formulas</a></li>
<li class="chapter" data-level="8.5" data-path="econometrics.html"><a href="econometrics.html#definitionen"><i class="fa fa-check"></i><b>8.5</b> Definitionen</a></li>
<li class="chapter" data-level="8.6" data-path="econometrics.html"><a href="econometrics.html#different-tests-vorgehen-bei-den-tests"><i class="fa fa-check"></i><b>8.6</b> Different Tests // Vorgehen bei den Tests</a></li>
<li class="chapter" data-level="8.7" data-path="econometrics.html"><a href="econometrics.html#diverse-berechnungen"><i class="fa fa-check"></i><b>8.7</b> Diverse Berechnungen</a></li>
<li class="chapter" data-level="8.8" data-path="econometrics.html"><a href="econometrics.html#accept-reject-null-hypothesis"><i class="fa fa-check"></i><b>8.8</b> Accept // Reject Null-Hypothesis</a></li>
<li class="chapter" data-level="8.9" data-path="econometrics.html"><a href="econometrics.html#formulierungen"><i class="fa fa-check"></i><b>8.9</b> Formulierungen</a></li>
<li class="chapter" data-level="8.10" data-path="econometrics.html"><a href="econometrics.html#coefficient-interpretation"><i class="fa fa-check"></i><b>8.10</b> Coefficient Interpretation</a></li>
<li class="chapter" data-level="8.11" data-path="econometrics.html"><a href="econometrics.html#nice-to-know"><i class="fa fa-check"></i><b>8.11</b> Nice to Know</a></li>
<li class="chapter" data-level="8.12" data-path="econometrics.html"><a href="econometrics.html#allgemeine-regeln"><i class="fa fa-check"></i><b>8.12</b> Allgemeine Regeln</a></li>
<li class="chapter" data-level="8.13" data-path="econometrics.html"><a href="econometrics.html#ommitted-variable-bias-ovb"><i class="fa fa-check"></i><b>8.13</b> Ommitted Variable Bias = OVB</a></li>
<li class="chapter" data-level="8.14" data-path="econometrics.html"><a href="econometrics.html#randomization"><i class="fa fa-check"></i><b>8.14</b> Randomization</a></li>
<li class="chapter" data-level="8.15" data-path="econometrics.html"><a href="econometrics.html#dummy-variables"><i class="fa fa-check"></i><b>8.15</b> Dummy Variables</a></li>
<li class="chapter" data-level="8.16" data-path="econometrics.html"><a href="econometrics.html#implication-of-statistically-significant-coefficients"><i class="fa fa-check"></i><b>8.16</b> Implication of statistically significant coefficients</a></li>
<li class="chapter" data-level="8.17" data-path="econometrics.html"><a href="econometrics.html#linear-probability-model-vs.-probit-model-comparison"><i class="fa fa-check"></i><b>8.17</b> Linear probability model VS. Probit model: comparison</a></li>
<li class="chapter" data-level="8.18" data-path="econometrics.html"><a href="econometrics.html#heterogeneous-treatment-effects-interaction-terms"><i class="fa fa-check"></i><b>8.18</b> Heterogeneous treatment effects // interaction terms</a></li>
<li class="chapter" data-level="8.19" data-path="econometrics.html"><a href="econometrics.html#definitions-of-bad-controls"><i class="fa fa-check"></i><b>8.19</b> Definitions of “bad controls”</a></li>
<li class="chapter" data-level="8.20" data-path="econometrics.html"><a href="econometrics.html#fixed-effects-fe"><i class="fa fa-check"></i><b>8.20</b> Fixed effects // FE</a></li>
<li class="chapter" data-level="8.21" data-path="econometrics.html"><a href="econometrics.html#cross-sectional-data"><i class="fa fa-check"></i><b>8.21</b> Cross-sectional Data</a></li>
<li class="chapter" data-level="8.22" data-path="econometrics.html"><a href="econometrics.html#panel-data"><i class="fa fa-check"></i><b>8.22</b> Panel Data</a></li>
<li class="chapter" data-level="8.23" data-path="econometrics.html"><a href="econometrics.html#difference-in-differences"><i class="fa fa-check"></i><b>8.23</b> Difference-in-Differences</a></li>
<li class="chapter" data-level="8.24" data-path="econometrics.html"><a href="econometrics.html#instrumental-variables-iv"><i class="fa fa-check"></i><b>8.24</b> Instrumental variables // IV</a></li>
<li class="chapter" data-level="8.25" data-path="econometrics.html"><a href="econometrics.html#regression-discontinuity-design-rdd"><i class="fa fa-check"></i><b>8.25</b> Regression discontinuity design // RDD</a></li>
<li class="chapter" data-level="8.26" data-path="econometrics.html"><a href="econometrics.html#time-series"><i class="fa fa-check"></i><b>8.26</b> Time Series</a><ul>
<li class="chapter" data-level="8.26.1" data-path="econometrics.html"><a href="econometrics.html#wörterbuch-5"><i class="fa fa-check"></i><b>8.26.1</b> Wörterbuch</a></li>
<li class="chapter" data-level="8.26.2" data-path="econometrics.html"><a href="econometrics.html#seasonality"><i class="fa fa-check"></i><b>8.26.2</b> Seasonality</a></li>
<li class="chapter" data-level="8.26.3" data-path="econometrics.html"><a href="econometrics.html#cycles"><i class="fa fa-check"></i><b>8.26.3</b> Cycles</a></li>
<li class="chapter" data-level="8.26.4" data-path="econometrics.html"><a href="econometrics.html#partial-auto-correlation"><i class="fa fa-check"></i><b>8.26.4</b> Partial Auto-Correlation</a></li>
<li class="chapter" data-level="8.26.5" data-path="econometrics.html"><a href="econometrics.html#how-to-create-a-simple-benchmark-time-series-model"><i class="fa fa-check"></i><b>8.26.5</b> How to create a simple Benchmark Time-Series Model?</a></li>
<li class="chapter" data-level="8.26.6" data-path="econometrics.html"><a href="econometrics.html#machine-learning"><i class="fa fa-check"></i><b>8.26.6</b> Machine Learning</a></li>
</ul></li>
<li class="chapter" data-level="8.27" data-path="econometrics.html"><a href="econometrics.html#coded-algorithms-r-functions"><i class="fa fa-check"></i><b>8.27</b> Coded Algorithms &amp; R-Functions</a></li>
<li class="chapter" data-level="8.28" data-path="econometrics.html"><a href="econometrics.html#nützliche-funktionen-r"><i class="fa fa-check"></i><b>8.28</b> Nützliche Funktionen R:</a></li>
<li class="chapter" data-level="8.29" data-path="econometrics.html"><a href="econometrics.html#useful-econometrics-documents"><i class="fa fa-check"></i><b>8.29</b> Useful Econometrics documents:</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machine-learning-1.html"><a href="machine-learning-1.html"><i class="fa fa-check"></i><b>9</b> Machine Learning</a><ul>
<li class="chapter" data-level="9.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#typen-von-machine-learning"><i class="fa fa-check"></i><b>9.1</b> Typen von Machine Learning</a></li>
<li class="chapter" data-level="9.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#supervised-learning"><i class="fa fa-check"></i><b>9.2</b> Supervised Learning</a></li>
<li class="chapter" data-level="9.3" data-path="machine-learning-1.html"><a href="machine-learning-1.html#methods"><i class="fa fa-check"></i><b>9.3</b> Methods</a></li>
<li class="chapter" data-level="9.4" data-path="machine-learning-1.html"><a href="machine-learning-1.html#wichtige-funktionen"><i class="fa fa-check"></i><b>9.4</b> Wichtige Funktionen</a></li>
<li class="chapter" data-level="9.5" data-path="machine-learning-1.html"><a href="machine-learning-1.html#difference-between-training--validation--test-dataset"><i class="fa fa-check"></i><b>9.5</b> Difference between Training-, Validation- &amp; Test-dataset</a><ul>
<li class="chapter" data-level="9.5.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#validation-set-vs.-test-set"><i class="fa fa-check"></i><b>9.5.1</b> Validation-Set VS. Test-Set</a></li>
<li class="chapter" data-level="9.5.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#reason-for-a-validation-set"><i class="fa fa-check"></i><b>9.5.2</b> Reason for a Validation-Set</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machine-learning-1.html"><a href="machine-learning-1.html#concept-of-stratification"><i class="fa fa-check"></i><b>9.6</b> Concept of Stratification</a></li>
<li class="chapter" data-level="9.7" data-path="machine-learning-1.html"><a href="machine-learning-1.html#cross-validation"><i class="fa fa-check"></i><b>9.7</b> Cross-Validation</a><ul>
<li class="chapter" data-level="9.7.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#special-case-cross-validation-for-time-series-data"><i class="fa fa-check"></i><b>9.7.1</b> <u>Special Case</u>: Cross-Validation for Time-Series Data</a></li>
<li class="chapter" data-level="9.7.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#why-do-we-use-cross-validation"><i class="fa fa-check"></i><b>9.7.2</b> Why do we use Cross-Validation?</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="machine-learning-1.html"><a href="machine-learning-1.html#normalisierung-der-daten"><i class="fa fa-check"></i><b>9.8</b> Normalisierung der Daten</a></li>
<li class="chapter" data-level="9.9" data-path="machine-learning-1.html"><a href="machine-learning-1.html#rnn"><i class="fa fa-check"></i><b>9.9</b> RNN</a></li>
<li class="chapter" data-level="9.10" data-path="machine-learning-1.html"><a href="machine-learning-1.html#data-pipelines"><i class="fa fa-check"></i><b>9.10</b> Data-Pipelines</a></li>
<li class="chapter" data-level="9.11" data-path="machine-learning-1.html"><a href="machine-learning-1.html#uni-kurs-neural-networks-deep-learning"><i class="fa fa-check"></i><b>9.11</b> Uni-Kurs <code>Neural Networks &amp; Deep Learning</code></a><ul>
<li class="chapter" data-level="9.11.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#notation-neural-networks"><i class="fa fa-check"></i><b>9.11.1</b> Notation Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="machine-learning-1.html"><a href="machine-learning-1.html#wörterbuch-6"><i class="fa fa-check"></i><b>9.12</b> Wörterbuch</a><ul>
<li class="chapter" data-level="9.12.1" data-path="machine-learning-1.html"><a href="machine-learning-1.html#synonyme-3"><i class="fa fa-check"></i><b>9.12.1</b> Synonyme</a></li>
<li class="chapter" data-level="9.12.2" data-path="machine-learning-1.html"><a href="machine-learning-1.html#data-science"><i class="fa fa-check"></i><b>9.12.2</b> Data Science</a></li>
<li class="chapter" data-level="9.12.3" data-path="machine-learning-1.html"><a href="machine-learning-1.html#time-series-1"><i class="fa fa-check"></i><b>9.12.3</b> Time-Series</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="machine-learning-1.html"><a href="machine-learning-1.html#quellen"><i class="fa fa-check"></i><b>9.13</b> Quellen</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mengenlehre.html"><a href="mengenlehre.html"><i class="fa fa-check"></i><b>10</b> Mengenlehre</a><ul>
<li class="chapter" data-level="10.1" data-path="mengenlehre.html"><a href="mengenlehre.html#wörterbuch-7"><i class="fa fa-check"></i><b>10.1</b> Wörterbuch</a></li>
<li class="chapter" data-level="10.2" data-path="mengenlehre.html"><a href="mengenlehre.html#mathematische-schrift-lesen"><i class="fa fa-check"></i><b>10.2</b> Mathematische “Schrift” lesen</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html"><i class="fa fa-check"></i><b>11</b> Business | Die Welt der Unternehmen</a><ul>
<li class="chapter" data-level="11.1" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#wörterbuch-8"><i class="fa fa-check"></i><b>11.1</b> Wörterbuch</a><ul>
<li class="chapter" data-level="11.1.1" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#it-software-development"><i class="fa fa-check"></i><b>11.1.1</b> IT &amp; Software-Development</a></li>
<li class="chapter" data-level="11.1.2" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#organisation"><i class="fa fa-check"></i><b>11.1.2</b> Organisation</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#projekt-management"><i class="fa fa-check"></i><b>11.2</b> Projekt-Management</a></li>
<li class="chapter" data-level="11.3" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#meetings"><i class="fa fa-check"></i><b>11.3</b> Meetings</a></li>
<li class="chapter" data-level="11.4" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#abschluss-präsentation"><i class="fa fa-check"></i><b>11.4</b> Abschluss-Präsentation</a></li>
<li class="chapter" data-level="11.5" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#job-interviews"><i class="fa fa-check"></i><b>11.5</b> Job-Interviews</a><ul>
<li class="chapter" data-level="11.5.1" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#praxis"><i class="fa fa-check"></i><b>11.5.1</b> Praxis</a></li>
<li class="chapter" data-level="11.5.2" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#vorteil-von-data-science-projekten-punkte-auf-die-du-unbedingt-zu-sprechen-kommen-solltest"><i class="fa fa-check"></i><b>11.5.2</b> Vorteil von Data-Science Projekten | Punkte, auf die du unbedingt zu Sprechen kommen solltest…</a></li>
<li class="chapter" data-level="11.5.3" data-path="business-die-welt-der-unternehmen.html"><a href="business-die-welt-der-unternehmen.html#quellen-1"><i class="fa fa-check"></i><b>11.5.3</b> Quellen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="openai.html"><a href="openai.html"><i class="fa fa-check"></i><b>12</b> OpenAI</a><ul>
<li class="chapter" data-level="12.1" data-path="openai.html"><a href="openai.html#what-can-openai-do-the-output"><i class="fa fa-check"></i><b>12.1</b> What can <code>OpenAI</code> do? | The Output</a></li>
<li class="chapter" data-level="12.2" data-path="openai.html"><a href="openai.html#how-does-the-model-work-the-blueprint"><i class="fa fa-check"></i><b>12.2</b> How does the Model work? | The Blueprint</a></li>
<li class="chapter" data-level="12.3" data-path="openai.html"><a href="openai.html#terminology-of-openai-api-wörterbuch"><i class="fa fa-check"></i><b>12.3</b> Terminology of <code>OpenAI</code>-API | Wörterbuch</a></li>
<li class="chapter" data-level="12.4" data-path="openai.html"><a href="openai.html#technology-behind-it-quellen"><i class="fa fa-check"></i><b>12.4</b> Technology behind it | Quellen</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science from Scratch Code</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="econometrics" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Econometrics</h1>
<div id="synonyme-2" class="section level2">
<h2><span class="header-section-number">8.1</span> Synonyme:</h2>
<ul>
<li>Dependent variable // y-variable // regressand // Y-intercept // outcome variable // response variable // label // ground truth</li>
<li>X-variable // variable of interest // explanatory variable // regressor // covariates // independent variable // predictor // attribute</li>
<li>regression of y on x // regress y on x</li>
<li>slope coefficient // beta</li>
<li>Controlling for // conditional on // holding fixed // holding constant // “certeris paribus” // statistically account</li>
<li>Classical linear regression model // CLRM</li>
<li>Linear probability model // LPM</li>
<li>Probit model // probit regressions</li>
<li>Logit model // logit regressions</li>
<li>(Population) data generating process // Population regression function // PRF // „true“ regression (—&gt; very often unknown)</li>
<li>Sample regression function // SRF // fitted model // estimated model</li>
<li>Range // distribution // histogram</li>
<li>Dummy variable // categorical variable</li>
<li>Endogeneity // Omitted variable Bias // OVB // violation of assumption 2 (= the non-zero mean assumption)</li>
<li>R squared // coefficient of determination</li>
<li>RSS // SSR // residual sum of squares // sum of squared residuals</li>
<li>Fitted value // predicted value // Y(hat)</li>
<li>Validity // internal Validity // external Validity</li>
<li>Randomized experiment // Random Assignment study // social experiment // randomized control trial // randomized trial</li>
<li>Expected value // predicted value</li>
<li>Heterogeneous treatment effects // interaction terms</li>
<li>Fixed Effects // FE</li>
<li>Difference-in-Differences // Diff-in-Diff // DiD</li>
<li>Two stage least squares // 2SLS // Second Stage // IV-Regression</li>
<li>NA // Censored Data // Latent Variable —&gt; can be estimated with a Tobit Model or Heckman Two stage Model (where the dependent variable is censored // has NAs, for example wages of people who don’t work cannot be observed // are censored)</li>
<li>Observation // Row in R // samples // records (in computer science)</li>
<li>Column in R // field (in computer science)</li>
<li>Variable // Column in R</li>
<li>Finite // Definite</li>
<li>Infinite // indefinite</li>
<li>Relativ zu // im Verhältnis zu</li>
<li>Seasonal ARIMA // SARIMA // ARIMA(p,d,q)(P,D,Q)</li>
</ul>
</div>
<div id="english-words-synonyme" class="section level2">
<h2><span class="header-section-number">8.2</span> English Words Synonyme</h2>
<ul>
<li>Among = across</li>
<li>Fixed = not random —&gt; an example would be the <u>true</u> parameters of the population would be fixed // not random, but you don’t know them —&gt; you can only approximate the true parameters by taking a random sample and estimating it’s coefficient to approach the true / fixed coefficient with a random (but estimated) coefficient, which resulted from a sample that the researcher took.</li>
<li>With respect to … = in Bezug auf… = Auf der (z.B. klanglichen) Ebene…</li>
</ul>
</div>
<div id="allgemeines" class="section level2">
<h2><span class="header-section-number">8.3</span> Allgemeines</h2>
<ul>
<li><strong>Numerator</strong> = Zähler</li>
<li><strong>Denominator</strong> = Nenner</li>
<li><strong>Ditto</strong> = ebenfalls</li>
<li><strong>A priori</strong> = When dealing with ommitted variable bias, you need to ask yourself the question: what are the most likely sources of important omitted variable bias in this regression? Answering such a question requires applying economic theory &amp; expert knowledge, and should occur <u><em>before</em></u> you actually runy any regressions; because this step is done before analyzing the data, it is referred to as „<strong>a priori</strong>“ („before the fact“) <strong>reasoning</strong>.</li>
<li><strong>Non-Linearity in X examples</strong>: A regression is not linear in one regressor „x“, if - for example - the „x“ was logarithmic or is an interaction term.</li>
<li><strong>Non-linearity in „beta“ // parameters // coefficients</strong>: An example of a regression function being non-linear in the parameters // coefficients are: 1) logistic regressions, where the dependent variable is between 0 and 1 (you use an s-shape function that can match all x-values between -infinity to +infinity to a y-value between 0 and 1); or 2) negative exponential growth:
<img src="./bilder/econ/nonlinear-in-their-parameters.jpeg" alt="Non-Linearity in Beta illustriert." />
<ul>
<li><u><strong>Importantly</strong></u>, <em>non-linearity</em> in „beta“ cannot be estimated using OLS, but rather, with an extension of OLS called nonlinear least squareds.</li>
</ul></li>
<li><strong>Independence assumption when dealing with probabilities &amp; variances</strong>: Independence has implications on how you calculate in statistics. For example, it affects the calculation of joint probabilities or variances with 2 random variables:
<img src="./bilder/econ/independence-assumption-on-joint-prob.jpeg" alt="Example of the calculation when two random variables are assumed to be independent from each other." /></li>
</ul>
</div>
<div id="statistics-formulas" class="section level2">
<h2><span class="header-section-number">8.4</span> Statistics Formulas</h2>
<ul>
<li><strong>Formula for covariance</strong>:
<img src="./bilder/econ/formula-covariance.jpeg" alt="The Formula for Covariance" /></li>
<li><strong>Formula for (population) variance</strong>:
<img src="./bilder/econ/formula-pop-variance.jpeg" alt="The Formula for the population Variance" /></li>
</ul>
</div>
<div id="definitionen" class="section level2">
<h2><span class="header-section-number">8.5</span> Definitionen</h2>
<ul>
<li><strong>Beliefs</strong>: VL1, Yanazingawa, S.2</li>
<li><strong>Evidence</strong>: VL1, Yanazingawa, S.2</li>
<li><strong>Counterfactual</strong>: VL 1, Yanazingawa, S.5</li>
<li><strong>Validity // internal Validity // external Validity</strong>: VL 1, Yanazingawa, S.7, S.12</li>
<li><strong>Randomized experiment // Random Assignment study // social experiment // randomized control trial // randomized trial</strong>: VL1, Yanazingawa, S.7</li>
<li><strong>Control Group</strong>: it mimics the counterfactual: VL1, Yanazingawa, S.7</li>
<li><strong>Treatment Group</strong>: VL1, Yanazingawa, S.7</li>
<li><strong>Random Assignment (= part of randomization)</strong>: VL1, Yanazingawa, S.7</li>
<li><strong>Random Sampling (= part of randomization)</strong>: VL1, Yanazingawa, S.7</li>
<li><strong>Why is randomization important?</strong>: VL1, Yanazingawa, S.7-8</li>
<li><strong>Observational Study</strong>: VL1, Yanazingawa, S.10 (wichtig für MA, weil es genau in mein Kontext fällt!)</li>
<li><strong>Bivariate Regression</strong>: Vl2, Yanazingawa, S.2</li>
<li><strong>Population Regression Funtion // Sample Regression Function</strong>: VL2, Yanazingawa, S.3</li>
<li><strong>Dependent variable // y-variable // Regressand // Y-intercept</strong>: VL2, Y-intercept, S.3</li>
<li><strong>Independent variable // x-variable // Regressor // Covariate // Explanatory Variable(s)</strong>: VL2, Y-intercept, S.3</li>
<li><strong>Slope Coefficient // Beta</strong>: VL2, Y-intercept, S.3</li>
<li><strong>Interpretation of Slope Coefficient Bivariate Regression</strong>: VL2, Yanazingawa, S.4</li>
<li><strong>Interpretation of Slope Coefficient Multivariate(!) Regression</strong>: VL2, Yanazingawa, S.10</li>
<li><strong>Interpretation of Intercept Bivariate Regression</strong>: VL2, Yanazingawa, S.4</li>
<li><strong>Interpretation of Intercept Multivariate(!) Regression</strong>: VL2, Yanazingawa, S.10</li>
<li><strong>Expected Value // Predicted Value</strong>: VL2, Yanazingawa, S.4</li>
<li><strong>Interpretation p-value (= it’s a bedingte(!!) W’keit)</strong>: VL2, Yanazingawa, S.5</li>
<li><strong>What does it mean to have a small Standard-Error?</strong>: VL2, Yanazingawa, S.6</li>
<li><strong>Statistical Significance &amp; its Implication</strong>: VL2, Yanazingawa, S.7</li>
<li><strong>Understanding “Holding Constant”</strong>: VL2, Yanazingawa, S.12</li>
<li><strong>Positive // Negative Bias Table</strong>: VL3, Yanazingawa, S.5</li>
<li><strong>Overstated // Understated Concept</strong> (Prof does not like the concept…): VL3, Yanazingawa, S.5</li>
<li><strong>Dummy Variable // Categorical Variable</strong>: VL4, Yanazingawa, S.1</li>
<li><strong>Dummy Variable Trap</strong>: VL4, Yanazingawa, S.3 &amp; S.6</li>
<li><strong>Multicolinearity</strong>: VL4, Yanazingawa, S.3</li>
<li><strong>Range // Distribution // Histogram</strong>: Ü1, Yanazingawa</li>
<li><strong>Scatterplot</strong>: Ü1, Yanazingawa</li>
<li><strong>Linear probability Model // LPM</strong>: VL5, Yanazingawa, S.2</li>
<li><strong>Interpretation of Slope Coefficient in Linear Probability Model // Regression</strong>: VL4, Yanazingawa, S.2</li>
<li><strong>Interpretation of Intercept Linear Probability Model // Regression</strong>: VL4, Yanazingawa, S.2</li>
<li><strong>Advantages // Disadvantages of LPM</strong>: VL5, Yanazingawa, S.4</li>
<li><strong>Advantages // Disadvantages of Logit Model</strong>: VL5, Yanazingawa, S.5</li>
<li><strong>Probit Model // Probit Regressions</strong>: VL5, Yanazingawa, S.5</li>
<li><strong>Logit Model // Logit Regressions</strong>: VL5, Yanazingawa, S.13</li>
<li><strong>Implement a Probit Model with Code</strong>: Ü2, Yanazingawa, Question 6</li>
<li><strong>Heterogeneous Treatment Effects // Interaction Terms</strong>: VL6, Yanazingawa, S.1, S.4 (first bullet)</li>
<li><strong>Coefficient Interpretation of Continuous-Dummy Interaction</strong>: VL6, Yanazingawa, S.4-7</li>
<li><strong>Coefficient Interpretation of Dummy-Dummy Interaction</strong>: Vl6, Yanazingawa, S.8</li>
<li><strong>Merge different Datasets together</strong>: Ü3, Yanazingawa, 5) c)</li>
<li><strong>Bad Controls</strong>: Ü3, Yanazingawa, 5) d), siehe Korrektur auf meinem gedruckten Problemset!</li>
<li><strong>Fixed Effects // FE</strong>: VL7, Yanazingawa, S.3 &amp; Zusammenfassung (ZF) auf letzter Seite des Handouts</li>
<li><strong>Difference-in-Differences // Diff-in-Diff // DiD</strong>: VL8, Yanazingawa, S.1</li>
<li><strong>Parallel Trend Assumption</strong>: VL8, Yanazingawa, S.2</li>
<li><strong>Interaction Terms between two FEs</strong>: Ü4, Yanazingawa, Aufgabe 3, Part I = a „country x time FE“ interaction controls for country-specific time-trends. However, to use it, you need 2 observations for each country and year (if we assume the time FE to be years…)</li>
<li><strong>Make Dummy Variables while having multiple Conditions</strong>: for example, the city needs to be between 25 km and 75 km away from the border = Ü4, Yanazingawa, Aufgabe 1, Part II</li>
<li><strong>Clustering the Standard Errors</strong>: Ü4, Aufgabe 1, Part II</li>
<li><strong>Endogeneous Regressor</strong>: VL9, Yanazingawa, S.1</li>
<li><strong>Validity of an Instrument</strong>: VL9, Yanazingawa, S.1</li>
<li><strong>Exclusion Restriction</strong>: VL9, Yanazingawa, S.2</li>
<li><strong>Two Stage Least Squares // 2SLS // Second Stage</strong>: VL9, Yanazingawa, S.6 &amp; S.7</li>
<li><strong>First Stage</strong>: VL9, Yanazingawa, S.6</li>
<li><strong>Reduced Form</strong>: VL9, Yanazingawa, S.6</li>
<li><strong>IV-Regression in R</strong>: Ü5, Yanazingawa, Aufgabe 1 a)</li>
<li><strong>Calculation of Mean while ignoring NAs</strong>: Ü5, Aufgabe 2 a)</li>
<li><strong>Standardize a Variable</strong>: Ü5, Audgabe 2 a)</li>
<li><strong>Interpretation with standardized Variables</strong>: Ü5, Audgabe 3</li>
<li><strong>ATE, ATT, ATUT</strong>: Ü2, Biroli, Aufgabe 2</li>
<li><strong>Selection Problem</strong>: Ü2, Biroli, Aufgabe 3</li>
<li><strong>Histrogram</strong>: zeigt die an, wie häufig ein Wert auftaucht.</li>
<li><strong>Scatter-Plot</strong>: Plot, welcher die Korrelation zwischen zwei Variablen in einem Datensatz aufzeigen.</li>
<li><strong>Dichtefunktion</strong>: W’keit, einen Wert zwischen “Wart a” und “Wert b” zu erhalten (im Kontext von Zufallsvariablen) = verwendet man bei stetigen Massen, wie Gewicht oder Distanz etc…</li>
<li><strong>Cross-Sectional Data</strong>: Observation of an economic agent (for example individuals, firms, households etc.) collected at <u>one</u> point in time; you can have agent FEs, but <u>not</u> time FEs!</li>
<li><strong>Panel Data</strong>: <em>Multiple</em> observations on agents over time (—&gt; you have a <u>time</u> index, as well as an index for individuals!) —&gt; here you can add time FEs and also agent FEs</li>
<li><strong>Confounders // Mediator Variables</strong>: These are the unobservable factors in your regression // in the error term that correlate with your x-variable of interest, as well as your y-vaiable, thus inducing bias when you estimate your model
<img src="./bilder/econ/mediator-variables-illustration.jpeg" alt="Confounders illustrated." />
<ul>
<li><u>Note</u>: The term „Mediator“ is used for independent variables that cause a change in the y-variable.</li>
<li><u>Note 2</u>: The term „Moderator“ are used for interaction terms, e.g. that the effect of an x-variable is modified and depends on the second variable.</li>
</ul></li>
<li><strong>Bivariate Regression</strong>: a regression with only one regressor // x-variable</li>
<li><strong>Multivariate Regression</strong>: a regression with multiple x-variables.</li>
<li><strong>3 Common Reasons for Endogeneity</strong>:
<ul>
<li><u><strong>Simultaneous Causality</strong></u>: x causes a change in y <u>but</u> y also causes a change in x</li>
<li><u><strong>Correlated unobservable Variable</strong></u>: leads to OVB in your coefficient of interest</li>
<li><u><strong>Measurement Error in x</strong></u>: you will have attenuation bias, e.g. bias towards zero
<ul>
<li><u>Note</u>: <strong>There is also the possibility that you have measurement error in y</strong>. In this case, we do <u><strong>not</strong></u> have a bias in the coefficient of interest! —&gt; however, the standard error of the coefficient gets bigger if you have this kind of measurement error!</li>
</ul></li>
</ul></li>
<li><strong>Degrees of Freedom (d.o.f.)</strong>: If we have „N“ observations and „K“ regressors in a regression, then we have: v = N - K „degrees of freedom“</li>
<li><strong>R-Squared</strong>: measures the goodness of fit, e.g. how much of the variance of y can be explained by our model // it is the squared correlation between the population regression function and our predicted SRF.
<ul>
<li><strong>Problem with the measure R-Squared</strong>: if you rescale the y-axis in the regression, for example with a <strong>log-function</strong>, it will lead to a reduction of the variability in Y and increase the R squared <em>without</em> improving the regression.</li>
</ul></li>
<li><strong>Overfitting the Data</strong>: This term is another <strong>problem that comes along with the measure „R squared“</strong>: the thing is, that you <em>always</em> increase the R squared when you add an additional regressors into your regression. With this characterstic, you could think of people adding regressors with almost no correlation to Y but still increasing the R squared without augmenting the precision of the estimated model!</li>
<li><strong>Unbalanced Groups (Kontext: RCTs pr Dummies)</strong>: If the treatment and control group are - on average - different to begin with, then the groups are unbalanced! —&gt; your estimated treatment effect will likely to be biased</li>
<li><strong>BLUE</strong> = best (= efficient), linear, unbiased estimator</li>
<li><strong>Consistency</strong>: if you have an infinite number of observations for your sample, then the estimated coefficient will converge towards the true coefficient of the population with a smaller variance for the estimated coefficient distribution —&gt; we then say that the estimated coefficient is „consistent“ —&gt; <u>Note</u>: the statistical theorem that forms the basis for consistency is called the <em>Law of Large Numbers</em>.</li>
<li><strong>Attenuation Bias</strong>: This is the Bias, when we have measurement error, meaning that the coefficient of interest „beta“ will be biased towards zero —&gt; e.g. if <em>beta &gt; 0</em>, then beta has a <strong>negative bias</strong> (it is smaller than what it should be) <u>or</u> if <em>beta &lt; 0</em>, then beta has a <strong>positive bias</strong> (it is bigger than it should be) —&gt; <u><strong>note</strong></u>: If we have a measurement error in one particular „x“ of a <u>multivariate</u> regression, we will have a higher bias (in absolute value), which is worse than in a simple linear regression case —&gt; <strong>the bias towards zero gets bigger</strong>! (See the formula on page 90 of „sources of bias, Crawford)</li>
<li><strong>Partitioned Regression</strong>: you do a bivariate regression of the residuals of 1) a regression of x(i) on all other x(-k)] on 2) the residuals of a regression of y on all other x(-k)]</li>
<li><strong>Replication Samples // Monte Carlo Simulation</strong>: You (randomly!) draw <em>different</em> samples of size „N“ from the <em>same</em> population many times, for example say you draw them „R“ times. Then, you plot the distribution of the <u><strong>average</strong></u> of <em>each</em> sample —&gt; you will see that, by drawing larger sizes of samples „N“ holding fixed the number of draws „R“ —&gt; the <em>average</em> of the distributed average samples will converge to the true average of the population!</li>
<li><strong>Serial Correlation</strong>: correlation of a variable with a lagged version of itself —&gt; you need this because of the assumption 4 of the CLRM: residuals should not have a serial correlation with one another</li>
<li><strong>Selection Bias</strong>: when an individual selects himself into the treatment- / control-group, because he has an advantage of doing so.</li>
<li><strong>Compliers (in an Instrumental variable setting)</strong>: You usually have compliers appearing, when an instrument is <u><strong>not</strong></u> assigning people <em>randomly</em> between treatment- and cotrol-groups. In this case, the compliers would be the people who choose to get treated (D=1), when they actually get assigned to treatment (Z=1) and decide not to get treated (D=0), when the instrument is not activated (Z=0).</li>
<li><strong>Never Takers (in an Instrumental variable setting)</strong>: People who choose to <em>never</em> get treated, independently whether the instrument is switched on or off! —&gt; D = 0 (always!), if Z = 1 bzw. Z = 0</li>
<li><strong>Always Takers (in an Instrumental variable setting)</strong>: People who choose to <em>always</em> get treated, independently whether the instrument is switched on or off! —&gt; D = 1 (always!), if Z = 1 bzw. Z = 0</li>
<li><strong>Synthetic Control</strong>: This method creates an appropriately weighted average of control units which best approximates the evolution of the outcome in the treated unit <u><em>before</em></u> treatment. —&gt; the key concept of using the synthetic control is that we construct an artificial control group to get a reasonable estimate for our missing counterfactual (= our treatment, which would not have been treated)</li>
<li><strong>RDD with a <code>sharp</code> Design</strong>: This is an RDD where the probability of treatment at the cutoff point changes from 0 to 1.</li>
<li><strong>RDD with a <code>fuzzy</code> Design</strong>: This is an RDD where the probability of getting treated changes (also) discontinuously, but <em>less</em> than 100%.</li>
<li><strong>Saturated Model</strong>: This is a model with a <em>full</em> set of dummies, e.g. in such a model, there is no constant!</li>
<li><strong><code>Type I</code>-Error in statistical Testing</strong>: A type I error happens, when we <em>wrongly</em> conclude that the null hypothesis H(0) is false, when it‘s acutally true (Eselsbrücke —&gt; Jemand sagt die Wahrheit, aber alle meinen, er lügt!)
<ul>
<li>The significance-level „alpha“ is representing the type I error.</li>
<li>Ideally, we want to minimizes both errors: type I and type II</li>
</ul></li>
<li><strong><code>Type II</code>-Error in statistical Testing</strong>: A Type II error happens, when we <em>wrongly</em> conclude that the null hypothesis H(0) is true, when it is actually false (Eselsbrücke —&gt; Jemand erzählt eine Lüge, und alle glauben ihm diese!)
<ul>
<li>Often, the type II error is referred to as „beta“: the probability of concluding that H(0) is true when it‘s actually false. Hence, (<em><code>1-beta</code></em>) is the probability of concluding that H(0) is <strong><u>false</u></strong>, when it is actually // truly false (probabilities sum up to 1, that‘s why we can do this!). This <code>(1- beta)</code> probability is also called the <strong>statistical power</strong>!</li>
<li>Ideally, we want to minimizes both errors: type I and type II</li>
</ul></li>
<li><strong>Statistical Power</strong>: read the first sub-point of type error II just above!
<ul>
<li><u>Grundsätzlich gilt</u>: a small sample size gives us little power to reject the null hypothesis (wahrscheinlich, because you have large standard errors // variance(beta-coefficient) is high), whereas a large sample size gives us more statistical power. —&gt; Usually, we want the power to be <u><strong><em>larger than 50%</em></strong></u>! —&gt; a power between 80 to 90%, e.g. the probability to reject H(0) when it is TRULY false. By the reverse probability, this would also imply that - with a statistical power of 80-90% - we would have a 10 to 20% probability to accept the H(0), even though it is false!</li>
<li><u>Merk-Regel</u>: A high statistical power is what you want, otherwise you would not conduct a study!</li>
</ul></li>
<li><strong>Supplementary Analysis</strong>: supplementary analysis seeks to shed light on the credibility of the primary analysis (= this is for example a DiD method, or IV, or RDD) —&gt; an example of a supplementary analysis is placebo testing</li>
<li><strong>Objective Function</strong>: this is a general function that individuals seek to maximize —&gt; example: a lifetime utility function takes on many values. The individuals seek to choose the maximum value (sometimes the minimum value, if it’s a cost-funtion) out of all those values of this „objective function“.</li>
<li><strong>Resampling</strong>: If you have a classification problem, where you have a y-variable with 9000 cases of „obese“ and 1000 cases of „normal weight“, then you have a problem that „normal weight“ people are under-represented in your sample. Thus, you have imbalanced data and you need to use resampling techniques with - for example - the „imblearn“ library to have a dataset that is equally distributed, e.g. 1000 cases of „normal weight“ and 1000 cases of „obese“.</li>
<li><strong>A staggered Treatment (first time I heard of it was in the context of DiD)</strong>: This means that - for example - an individual can choose to get treated, but once it gets treated, he cannot get out of the treatment (example: COVID vaccines are like that).</li>
</ul>
</div>
<div id="different-tests-vorgehen-bei-den-tests" class="section level2">
<h2><span class="header-section-number">8.6</span> Different Tests // Vorgehen bei den Tests</h2>
<ul>
<li><strong>Check if random Assignment // Randomization into Treatment- &amp; Control-Group was successful</strong>: VL1, Yanazingawa, S.</li>
<li><strong>Placebo Testing</strong>: this test involves demonstrating that your effect does not exist when it really „should not“ exist —&gt; you pick a period where <u>no</u> treatment occured and try to see if your treatment group really did not react to „no treatment“ in this particular period!</li>
</ul>
</div>
<div id="diverse-berechnungen" class="section level2">
<h2><span class="header-section-number">8.7</span> Diverse Berechnungen</h2>
<ul>
<li><strong>Review of Hypothesis-Testing // Testing differences in Means</strong>: Vl1, Yanazingawa, S.9 &amp; S.11</li>
<li><strong>Hypothesis testing “no effect” (= H<sub>0</sub>) VS. “there is an effect”</strong>: VL2, Yanazingawa, S.5</li>
<li><strong>Bias</strong> = short Regression Coeff. - long Regression Coeff. = <code>beta(2)*gamma [= corr(Y, omitted) * corr(X, omitted)]</code></li>
</ul>
</div>
<div id="accept-reject-null-hypothesis" class="section level2">
<h2><span class="header-section-number">8.8</span> Accept // Reject Null-Hypothesis</h2>
<ul>
<li><strong>t-statistic</strong>:
<ul>
<li><em>beidseitiger Test</em>: if t-stat (im Betrag) &gt; crit.-value –&gt; reject the null
<ul>
<li><u>Note</u>: we use Z<sub>(1- [alpha/2])</sub> as the critical value, since we have a two-sided test.</li>
</ul></li>
<li><em>rechtsseitiger Test</em>: if t-stat &gt; crit.-value –&gt; reject the null
<ul>
<li><u>Note</u>: use Z<sub>(1-alpha)</sub> as the crit value, since we have a one-sided test.</li>
</ul></li>
<li><em>linksseitiger Test</em>: if t-stat &lt; critical value –&gt; reject the null
<ul>
<li><u>Note</u>: use Z<sub>(1-alpha)</sub> as the crit value, since we have a one-sided test.</li>
</ul></li>
</ul></li>
<li><strong>Important general fact about hypothesis</strong>: Just because you cannot reject a null-hypothesis does not mean that the null-hypothesis is true. It just means that you don’t have enough empirical evidence to prove that the alternative-hypothesis is true.</li>
<li><strong>p-value</strong>:
<ul>
<li><u>Definition</u>: Gives the probability that we would get our „<strong>sample</strong>-mean“ (= the mean that you just calculated from the data // sample you have drawn) <u><strong><em>IF</em></strong></u> the Null-hypothesis was true!
<ul>
<li><u>Interpretation</u>: This implies - <em>when we have a <strong>very small p-value</strong></em> - that - <em>GIVEN our sample</em> - there is very small probability that we would get this sample mean <u><strong><em>if</em></strong></u> the nullhypothesis was true. —&gt; this is a good result for a researcher, since he / she seeks to reject the null-hypothesis!</li>
</ul></li>
<li><em>beidseitiger Test</em>: if p-value &lt; alpha –&gt; reject the null</li>
<li><em>rechtsseitiger Test</em>:</li>
<li><em>linksseitiger Test</em>:</li>
</ul></li>
<li><strong>Types of Errors in statistical Testing</strong>:
<img src="./bilder/econ/types-of-errors.jpeg" alt="These are all the possible types of errors you encounter." /></li>
</ul>
<blockquote>
<p>Was ist <u>p-hacking</u>?</p>
</blockquote>
<p>In der Statistik gibt es den <strong>p-Wert</strong> ein: <em>Man nimmt an die Hypothese sei wahr und berechnet dann die Wahrscheinlichkeit, dass die beobachtete Statistik mindestens so extrem ausfallen würde (für die Gegner von Wischi-Waschi <a href="https://de.wikipedia.org/wiki/P-Wert#Mathematische_Formulierung">hier die Wikipedia-Definition</a>)</em>. Falls diese Wahrscheinlichkeit unter 5% liegt, dann sei das Resultat “statistisch signifikant” (yay!) und die Nullhypothese kann verworfen werden, was oftmals die Absicht ist.</p>
<p><u>Das <strong>Problem</strong> ist nur</u>: <em>Hypothesen gibt es viele und z.T. auch recht ähnliche</em>. Wenn man genug Hypothesen aufstellt - <strong>vor allem, <u>nachdem</u> man sich die Daten angeschaut hat</strong> - dann ist es durchaus möglich, dass man ein statistisch signifikantes Resultat erhält, unabhängig davon, ob das Resultat tatsächlich auch stimmt. <strong>Das nennt man p-Hacking</strong>. Es kommt häufig in der Forschung vor, aber es kommt sicher auch in der SBB vor (dennoch hier eine +1 für Hypothesen-basiertes arbeiten!). Wie einfach man in die “falsche Signifikanz Falle” tappen kann, wird hübsch in dieser Gallerie falscher Korrelationen illustriert.</p>
</div>
<div id="formulierungen" class="section level2">
<h2><span class="header-section-number">8.9</span> Formulierungen</h2>
<ul>
<li><strong>For “correlation”</strong>:
<ul>
<li>“is correlated with”.</li>
<li>“is associated with”.</li>
</ul></li>
<li><strong>For “causation”</strong>:
<ul>
<li>“lead to…”</li>
<li>“has an effect on..”</li>
</ul></li>
<li><strong>In Regressions</strong>:
<ul>
<li>“hold constant”</li>
<li>“certeris paribus”</li>
<li>“holding fixed”</li>
<li>“controlling for”</li>
<li>“conditional on”</li>
<li>“statistically account for”</li>
</ul></li>
<li><strong>“Y is a function of X”</strong>:
<ul>
<li>y(x)</li>
<li>y = f(x)</li>
<li>y depends on x</li>
<li>y as a function of x</li>
</ul></li>
</ul>
</div>
<div id="coefficient-interpretation" class="section level2">
<h2><span class="header-section-number">8.10</span> Coefficient Interpretation</h2>
<ul>
<li><strong>Lin-Lin</strong>:</li>
<li><strong>Lin-Log</strong>: a 1% increase in X will increase // decrase Y by (<strong><code>beta/100</code></strong>) units!</li>
<li><strong>Log-Lin</strong>: a <em>unit</em> change in X will increase // decrease Y by <strong><code>beta *100</code></strong> percent!</li>
<li><strong>Log-Log</strong>: a <em>1%</em> increase in X will increase // decrease Y by <strong>beta %</strong></li>
<li><strong>Log-Dummy (dh logarithmierter dummy?)</strong>: Here you have to be very careful (<strong>Fallunterscheidung</strong>!):
<ul>
<li><em>If your coefficient on the dummy is very small</em>, then you can do the <u>normal</u> „<strong>Lin-Log</strong>“ interpretation, it will be approximately correct.</li>
<li>However, if your coefficient on the dummy is big, then you need to <strong>transform your coefficient <em>before</em> you do the interpretation</strong>! The formula would be: <code>exp^(estimated beta) -1</code> —&gt; if you multiply this result by 100 <em>then</em> you get the correct %-units and you can procede to do the normal „Lin-Log“ interpretation!</li>
</ul></li>
<li><strong>Coefficient Interpretation (multivariate Case)</strong>: "Beta 1 tells us the average change (, e.g. increase // decrease) in Y associated with a <strong><u>one-unit-change</u></strong> in X(1), holding constant X(2) and all other variables!</li>
<li><strong>Coefficient Interpretation (y-variable in Prozent)</strong>: "A unitary increase in X is associated with a change in Y of XYZ Percentage <em>Points</em>(!!!)</li>
<li><strong>Coefficient Interpretation (x-variable in percent)</strong>: "An <em>1 percentage point</em>(!!) increase (= unitary increase when x-var. is in percent) is associated with a XY unitary change in y.</li>
<li><strong>Coefficient Interpretation of a Linear Probability Model</strong>: "Being 1 year older (= x-variable is age [in years]) increases the probability of getting married. Pay attention: the increase is in percentage points (-&gt; y-variable is a <em>dummy</em>!!! [–&gt; dh the slope coefficient is the change in the probability in a LPM! –&gt; dh you need to multiply the number of the coefficient by 100 to get the result in the change in probability (in percentage points of course…)!])</li>
<li><strong>Coefficient Interpretation of a Probit Model</strong>: you cannot interpret the magnitude (= Grösse des coeff.) directly, you need to transform it first (with a complicated formula for the s-shape function)! However, the sign <strong><u>AND</u></strong> the statistical significance can be directly interpreted from the coefficient of a probit model!</li>
<li><strong>Coefficient Interpretation of a <code>dummy*continuous</code> Interaction</strong>: for example the gender-wage gap –&gt; returns to education can vary depending if you are a man or a female. Hence, the coefficient represents the difference in slopes (for education, e.g. the continuous variable) for males and females.</li>
<li><strong>Coefficient Interpretation of a <code>Dummy-Dummy</code> Interaction Term (hier: <code>female * black // gender * enthnicity</code>)</strong>: when you have 2 dummies, you have - in total - 4 different “states of the world” // 4 different possibilities. Hence, you have 2 different possibilities to do the coefficient interpretation, which is either the differences between black and white males // females, <u><strong>or</strong></u> the differences between white male and females // black male and females. –&gt; these two interpretations are equivalent, but often one is more interesting than the other! –&gt; <u>very important</u>: the <code>dummy*dummy</code>-coefficient = <em>Diff-in-Diff estimator</em>!!</li>
<li><strong>Coefficient Interpretation while “holding constant” FEs</strong>: <em>Within</em>(!!) districts, full RTML reception is associated with a XY unitary change in genocide cases, compared to zero reception. –&gt; Alternative: “holding constant all factors that vary across districts (= FEs)”</li>
<li><strong>Coefficient Interpretation with standardized Measurements in X and in Y</strong>: If corruption increases by one standard deviation, then child mortality will rise by 0.6259 standard deviations or 62.59% of a standard deviation of child mortality.</li>
</ul>
</div>
<div id="nice-to-know" class="section level2">
<h2><span class="header-section-number">8.11</span> Nice to Know</h2>
<ul>
<li><strong>Why do we need statistics in econometrics?</strong> -&gt; Because it is the statistical theory that allows you to make statistical inference from your sample to your underlying population!</li>
<li><strong>Random VS. Non-Randomness of Mean &amp; Variance // Features</strong>: Features of the population are <em>fixed</em>, dh non-random (but <strong>unknown</strong>!), whereas features of the sample are random (but <strong>known</strong>!) —&gt; e.g. if you draw another sample from the population, it is very likely that you get different numbers than in your other sample!</li>
<li><strong>If you want to see, if an estimator is <em>economically</em> meaningful</strong>: This is done by looking at the <em>magnitude</em> of the coefficient.
<ul>
<li><em>How to calculate the magnitude of a coefficient // whether to know if the effect is big or not?</em> —&gt; <u>formula</u>: <em><code>magnitude = coeff. of interest / average estimated Y</code></em> —&gt; make a summary-statistic of your regression to find out this average estimated Y!</li>
</ul></li>
<li><strong>Law of large numbers</strong>: The <em>sample</em> mean converges to the <u>population</u> mean as the sample size „N“ gets large.</li>
<li><strong>Bootstrapping</strong>: when you pick a random sample out of a population, you probably will get a different number than with another sample (of the exact same size &amp; exact same population). This exact method can be done with „Bootstrapping“ —&gt; the goal is to see, if your analysis gets completely different (—&gt; this would be bad…) or stays approximately the same (this is the outcome you want…).</li>
<li><strong>The 5 assumptions in a regression model that must be true (otherwise we get a biased estimator)</strong>:
<ol style="list-style-type: decimal">
<li>The PRF is assumed to take a <u>linear</u> form (—&gt; that‘s why you need to sometimes take the logarithm of a non-linear relationship!)</li>
<li>Key assumption for causal interpretation of the coefficient: Mean zero Error —&gt; the error term has an expected value of zero —&gt; E(error/X) = 0 <em>implies</em> that cov(error, X) = 0 —&gt; in other words: that there is no correlation between the coefficient of interest and „everthing else“ // all unobservables in a regression</li>
<li>Homoskedasticity —&gt; dh the variance of the residuals should always stay the same —&gt; <strong>how to see if A3 is satisfied?</strong> —&gt; look at a scatterplot of the residuals (on y-axis) plotted against a regressor: you want to see „picasso on drugs“, e.g. a variation in the residuals on the y-axis that stays constant with increasing „x“
<img src="./bilder/econ/violation-of-homoscedasticity.jpeg" alt="Here is an example of a violation of the Homoscedasticity-Assumtion" /></li>
<li>A4: No correlation between the lagged residuals —&gt; <strong>how to see if A4 is satisfied?</strong> —&gt; use the Autocorrelation-function in R to see if the residuals are correlated with each other (this is what you <u>don‘t</u> want!)-
<img src="./bilder/econ/autocorr-residuals-a4.jpeg" alt="Here an example of non-correlated residuals across time, which is what we want to see (= no violation)" /></li>
<li>A5: Normality —&gt; residuals should be normally distributed —&gt; <strong>how to see if A5 is satisfied?</strong> —&gt; plot the density function of the residuals, it should look like a normal-distribution! If not, then the assumption is violated!
<img src="./bilder/econ/density-of-residuals-a5.jpeg" alt="Here, we see that the residuals’ distribution does not look like a normal-distribution. Therefore, we can conclude that the normality-assumption of the linear regression model is violated." /></li>
</ol></li>
<li><strong>What happens, if all the above 5 assumptions are satisfied?</strong>
<ol style="list-style-type: decimal">
<li>The coefficient of interest will be unbiased (= <strong>Unbiasedness</strong>)</li>
<li><strong>Efficiency</strong> —&gt; e.g. the variance of the estimated coefficient is the smallest (compared to non-OLS estimation), which is a good thing, because we will always have an <u>estimated</u> coefficient that will be the closest guess to the <u>true</u> beta-coefficient!</li>
<li>Our estimated coefficient will be <strong>normally distributed</strong> (good for hypothesis testing etc…)</li>
</ol></li>
<li><strong>What happens if A1-A5 are violated and how to fix it?</strong>
<ul>
<li><u>Assumption 1 (= Linearity)</u>: This assumption is most certainly violated (the true PRF is very rarely linear) —&gt; fixing it is not such a big deal —&gt; either you can <strong>add non-linearity in x</strong>:
<ul>
<li>log-transform your regressor</li>
<li>Make a polynomial for x (often used in RDD)</li>
<li>OR add interaction terms</li>
</ul></li>
<li><u>or</u> <strong>add non-linearity in beta</strong>:
<ul>
<li>Using nonlinear Least Squares (= these are non-linear models —&gt; look it up in a fat textbook!)</li>
</ul></li>
<li><u>Assumption 2 (= non-zero mean)</u>: This will lead to OVB // your regressor is endogeneous! —&gt; to fix it, you need to control for the unobservable factor <u>OR</u> to use some fancy methods like Fixed effects, IV, RDD or RCT that allows you to control for the unobserved factor!</li>
<li><u>Assumption 3 (homoskedasticity)</u>: if your variance of the error term is heteroskedastic, your assumption 3 is violated —&gt; use a statistical test to see if your variance is homo- or heteroskedastic! —&gt; it‘s not a big deal if this assumption 3 is violated, because the estimated coefficient of interest will still be <strong>unbiased</strong>! <u>But</u> the <strong>standard errors will be wrong</strong> though —&gt; to fix it, you can tell your statistical software to account for heteroscedasticity! —&gt; when you account for heteroscedasticity, you will have to use so called „<strong>robust standard errors</strong>“!
<img src="./bilder/econ/breusch-pagan-test-for-homoscedasticity-check.jpeg" alt="Here is an example of using a “Breusch-Pagan-Test” to see whether there is need to include a counter-measure for heteroscedastic standard-errors. Here, we see that the null-hypothesis (of homogeneous variance) is violated and - hence - we need to include robust standard-errors." /></li>
<li><u>Assumption 4 (correlation between error terms is zero)</u>: if this assumption gets violated, it‘s also not a big deal, because (like A3) the estimated coefficient of interest will also still be <strong>unbiased</strong>! <u>But</u> the <strong>standard errors will again be wrong</strong> though! To fix this, you can tell your statistical software to <strong>cluster the standard errors</strong>.</li>
<li><u>Assumption 5 (normally distributed errors)</u>: very uikely that this assumption is violated, because we have the very powerful „<strong>Central Limit theorem</strong>“ that backs it up! —&gt; prof crawford did not tell us how to fix it, because it is <em>very rarely violated</em>!</li>
</ul></li>
<li><strong>Under which of the above assumptions is an estimated coefficient BLUE?</strong> —&gt; under the Assumptions 1-4 the estimated beta-coefficient will be BLUE!</li>
<li><strong>Why do we take correlations instead of covariances?</strong> —&gt; because correlations have no units (only a number between -1 and +1), while covariances can have strange units like „hours-gradepoints“ xD</li>
<li><strong>If you include an irrelevant variable in the regression, will there be a bias on your estimated coefficient of interest?</strong> —&gt; no, you coefficient stays unbiased, but the coefficient will be inefficient (not the lowest possible variance(beta_hat)) —&gt; if you are not sure whether to include a variable or not: better to include it, rather than ommit it (otherwise OVB in the worst case!)</li>
<li><strong>Dertermine the sign of bias (if you have OVB)</strong>:
<img src="./bilder/econ/determine-sign-of-bias.jpeg" alt="This is the table that you need to know by heart, in order to determine the sign of the bias of a coefficient." />
<ul>
<li>where <code>beta(2)</code> is the correlation between the <em>ommitted</em> variable and the y-variable!</li>
<li><u><strong>Another formula to dertermine the sign of the bias</strong></u>: <code>bias = short regression coeff. - long regression coeff.</code></li>
</ul></li>
<li><strong>“Without loss of generality”?</strong> —&gt; it means that a statement // formula is always true!</li>
<li><strong>Check if an instrument is „strong“ or „weak“</strong>: —&gt; you can do an F-Test: if the instrument has an F-value that <strong><em>exceeds</em> 10</strong>, you have approximately a strong instrument.
<ul>
<li>If you only have one instrument, you can use the t-test. If the value <strong><em>exceeds</em> 3.16</strong>, then you also have a „strong“ instrument (rule of thumb).</li>
</ul></li>
<li><strong>When is the usage of the synthetic-control method optimal?</strong> —&gt; If you have a single unit that is treated (for example a country) and many other units that are not treated, all of which could be a control, but none of which is a perfect one.</li>
</ul>
</div>
<div id="allgemeine-regeln" class="section level2">
<h2><span class="header-section-number">8.12</span> Allgemeine Regeln</h2>
<ul>
<li>“Larger sample sizes yield to smaller standard errors and thus less uncertainty // narrower confidence intervalls // preciser estimates.”</li>
<li>“Larger residuals (= Differenz zwischen durchschnittliches Y und tatsächliches Y = noisier data) yield to larger standard errors and thus more uncertainty.”
<ul>
<li>“Regress Y on X(1), X(2)…X(k)”</li>
<li>“We regress Y on X(1), X(2), … X(k)”</li>
<li>“The impact of X on Y…”</li>
</ul></li>
</ul>
</div>
<div id="ommitted-variable-bias-ovb" class="section level2">
<h2><span class="header-section-number">8.13</span> Ommitted Variable Bias = OVB</h2>
<ul>
<li><strong>Condition for ommitted variable bias</strong>: corr(Y, omm. var.) &gt; // &lt; 0 <u>AND</u> corr(X, omm. var.) &gt; // &lt; 0 –&gt; sign of the OVB</li>
<li><strong>Bias</strong> = short Regression Coeff. - long Regression Coeff. = <code>beta(2)*gamma [= corr(Y, omitted) * corr(X, omitted)]</code>
<ul>
<li><u>Note</u>: if beta(2) = 0 <u><em>OR</em></u> if gamma = 0, there is no bias! –&gt; the higher the magnitude of the bias, the less precise our sample regression funtion (SRF) relative to our population regression function (PRF), thus we have lower internal validity (dh likelyhood of estimating the true causal effect is low, since we have an unprecise SRF)</li>
</ul></li>
</ul>
</div>
<div id="randomization" class="section level2">
<h2><span class="header-section-number">8.14</span> Randomization</h2>
<ul>
<li>If you don’t randomize, there will be a selection problem, e.g. mean untreated outcomes will diﬀer from the mean of the treated outcomes. By randomizing, you will make it impossible for people to self-select in or out of a treatment!</li>
<li>Implementation of “randomization” can be achieved by - for example - tossing a (fair) coin. –&gt; this is difficult to implement because not all people want // need a treatment to begin with (= there are often debates where such “randomized experiments” are seen as unethical!)</li>
</ul>
</div>
<div id="dummy-variables" class="section level2">
<h2><span class="header-section-number">8.15</span> Dummy Variables</h2>
<ul>
<li>You can also use other numbers than 0 or 1 to define a dummy. However, 0 and 1 is easier to interpret.</li>
<li>If you estimate a model <u>without</u>(!!) a constant, then you can include all dummies. However, you cannot add all dummies from a category (for example you cannot add female &amp; male into one regression, when these two are the only gender-dummies), otherwise you will run into a multicolinearity problem.</li>
</ul>
</div>
<div id="implication-of-statistically-significant-coefficients" class="section level2">
<h2><span class="header-section-number">8.16</span> Implication of statistically significant coefficients</h2>
<ul>
<li>If a coefficient is statistically significant, it means that we have strong evidence for an association between X and Y! (very relevant for my Master-Thesis!) –&gt; thus, if you don’t find a statistically significant coefficient, you don’t have, you will never have enough evidence for a causal effect!</li>
</ul>
</div>
<div id="linear-probability-model-vs.-probit-model-comparison" class="section level2">
<h2><span class="header-section-number">8.17</span> Linear probability model VS. Probit model: comparison</h2>
<ul>
<li>A good rule-of-thumb is that the probit model’s prediction are similar to those of the linear probability model <em>near the sample mean of X</em> but can be very different far from the sample mean!</li>
</ul>
</div>
<div id="heterogeneous-treatment-effects-interaction-terms" class="section level2">
<h2><span class="header-section-number">8.18</span> Heterogeneous treatment effects // interaction terms</h2>
<ul>
<li>The three categories of different heterogeneous treatment effects are:
<ol style="list-style-type: decimal">
<li>Continuous * Dummy</li>
<li>Dummy * Dummy</li>
<li>Continuous * Continuous</li>
</ol></li>
</ul>
</div>
<div id="definitions-of-bad-controls" class="section level2">
<h2><span class="header-section-number">8.19</span> Definitions of “bad controls”</h2>
<ul>
<li>If the treatment can strongly influence some of your variables you control for, they are “bad controls”!</li>
</ul>
</div>
<div id="fixed-effects-fe" class="section level2">
<h2><span class="header-section-number">8.20</span> Fixed effects // FE</h2>
<ul>
<li><u>Definition</u>: By using fixed effects, one controlls for all the factors that differ <u>across</u>(!) groups, like districts (if you use for example “district fixed effects”) that are <strong>time-invariant</strong>!Therefore, any differences that vary across districts (and don’t change over time within a particular district) are controlled for. Instead, the regression exploits variation of the X-variable that vary <em>within</em> groups.
<ul>
<li>Note: when you deal with <strong>cross-sectional data</strong> and use FEs, you controll for all the factors that differ <u>across</u>(!) groups. You cannot include time FE in a cross-section, since you only have observations for a particular point in time (not like panel data, where you have multiple observation for an agent over time, and thus there you can include time FE).</li>
</ul></li>
<li>Intuition, why you controll for all factors that vary across districts: in a regression, you want a counterfactual that - ideally - only differs from your population of interest by the treatment. FE is a powerful tool to construct a better counterfactual, because it allows you to group the data and thus make comparisons within those different groups!</li>
<li><strong>What does FEs <em>not</em> control for</strong>? –&gt; However, note that you need to control for all factors which vary <em>within</em> a district if you use FEs!</li>
<li><strong>Key requirement to use FEs</strong>: have multiple observations within a group! However, be aware that there will <strong>ALWAYS</strong> be other unobserved factors that could explain your results. The question is how important those other factors are, and whether they are correlated with the variable of interest (such as RTML reception in Rwanda example).</li>
<li><strong>Intuition for <code>Time FEs</code></strong>: schlecht erklärt in Handouts, aber ich habe eine gute Visualisierung –&gt; stelle dir zwei benachbarte Regionen vor: ZH und Aargau –&gt; wenn ich jetzt Time-FEs habe in einer Regression, kontrolliere ich für folgendes:
<ul>
<li>Alle Faktoren, die sich über die Zeit verändern ABER beide Regionen GLEICH STARK “hitten” (–&gt; zum Beispiel BIP-Growth Rates der SCHWEIZ oder global economic conditions, welche sich über die Zeit verändern, aber wahrscheinlich diese beiden Nachbar-Regionen gleich stark beeinflussen).</li>
<li><strong>Für was hier jedoch <em>NICHT</em> kontrolliert wird</strong>, sind zum Beispiel Faktoren wie <strong>REGIONALE BIP-Growthrates // REGIONALE crime rates // ein Meteoriteinschlag in Zürich, aber NICHT in Aargau</strong>.</li>
<li>Deine Aufgabe als Forscher ist nun herauszufinden: welche dieser Faktoren für dein Modell jetzt relevant? –&gt; folglich weisst du auch, was die Faktoren sind, die durch Time FEs <em>nicht</em> kontrolliert werden und somit kannst du - hoffentlich - dafür kontrollieren!</li>
</ul></li>
<li><strong>Intuition for <code>Region FEs</code></strong>: schlecht erklärt in Handouts, aber ich habe eine gute Visualisierung:
<ul>
<li><u>wie vorher</u>: zwei Nachbar-Regionen, Zürich und Aargau –&gt; nun hat man <code>region FEs</code> in Regression. Diese kontrollieren für:
<ol style="list-style-type: decimal">
<li>Alle Faktoren, die sich zwischen Zürich und Aargau unterscheiden <em>ABER</em> über die Zeit sich nicht verändern // ZEITINVARIABEL sind (–&gt; zum <strong>Beispiel ein SCHWEIZER Gesetz</strong>, das nur auf den Aargau abzielt und welches sich über die (vom Forscher betrachtete // fixierte) Zeitperiode <u>NICHT</u> verändert hat <u>oder</u> die <strong>unterschiedliche Geographie</strong> der beiden Regionen (wird sich wohl kaum verändern über die betrachtete Zeit) <u>oder</u> meistens auch <strong>Bevölkerungszusammensetzung</strong> (unterscheiden sich zwischen ZH und AR, aber bleiben meist konstant über die Betrachtungsperiode).</li>
</ol></li>
</ul></li>
<li><strong>Indexing coefficients</strong>: when you use FEs, the index for the coefficients are the groups. —&gt; <u>example</u>: when you use time-FEs, the index will be time. Or, if you use region-FE, the index will be regions</li>
<li><strong>Usage of causal language</strong>: you can use causal language when interpreting the FEs coefficients if you are convinced that the Fixed effects have eliminated the main threats to internal validity!</li>
<li><strong><code>Controlling for Time FEs</code>, how to make a coefficient interpretation?</strong> –&gt; when interpreting a coefficient while using Time FEs: On average and <strong><code>controlling for time trends</code></strong>(!!), a unitary increase in X is associated with an YZ-change in Y.</li>
</ul>
</div>
<div id="cross-sectional-data" class="section level2">
<h2><span class="header-section-number">8.21</span> Cross-sectional Data</h2>
<ul>
<li><strong>Definition</strong>: Cross-sectional Data is data from one moment in time.</li>
<li><strong>Conditions to use FE for cross-sectional data</strong>: you can use FEs, if your data:
<ol style="list-style-type: decimal">
<li>contains groups AND</li>
<li>if your groups have at least 2 observations</li>
</ol></li>
</ul>
</div>
<div id="panel-data" class="section level2">
<h2><span class="header-section-number">8.22</span> Panel Data</h2>
<ul>
<li><strong>Definition</strong>: Observing outcomes in the same units // of the same individuals // of the same states (etc.) in multiple moments in time (years). –&gt; <u>note</u>: you observe for example the beer-tax over multiple periods of times for many different states, e.g. we can do a cross-section analysis &amp; analysis over time!</li>
<li><strong>Fixed Effects with Panel Data</strong>: panel data allows us to:
<ol style="list-style-type: decimal">
<li>You can do Time Fixed effects, which control for all factors that differ over time but are constant across units, for example globalisation or price level –&gt; both vary over time but are the same across states // units</li>
<li>You can do state fixed effects, e.g. you control for factors that differ across states but stay the same over time (= e.g. needs to be time invariant factors within the state // not change over time within the state).</li>
</ol></li>
</ul>
</div>
<div id="difference-in-differences" class="section level2">
<h2><span class="header-section-number">8.23</span> Difference-in-Differences</h2>
<ul>
<li><strong>Key assumption that needs to be satisfied with DiD</strong>: parallel trend assumption –&gt; this means: <em>in the absence of treatment</em>(!) // policy change, the <strong>treatment group</strong> <em>would have had <u>the same</u> mean change(!!)</em> in outcomes (X) as the control group
<ul>
<li>Wichtige Bemerkungen:
<ol style="list-style-type: decimal">
<li>The parallel assumtion <u><em>cannot be tested</em></u>, because we NEVER observe the counterfactual! BUT what you can do is to observe multiple data-points over time <u>BEFORE</u> treatment and look if the treatment- and control-group have similar trends –&gt; then you can look if they move in the same direction (this is what you want to have a good DiD).</li>
<li>This assumption does <em>not</em> require the treatment group to have the same level(!!) of Y for the treatment and the control group, either before or after, the policy change!</li>
</ol></li>
</ul></li>
<li><strong><em>If the parallel trend assumption is satisfied</em></strong>, then the DiD technique allows you to control for variables that differ across the groups but are constant over time (within the group –&gt; for example district FEs) <u><em>and</em></u> also allows you to control for variables that differ over time but are contstant across the groups (within the determined time period –&gt; e.g. time FEs)</li>
<li><strong>Examples</strong>:
<ol style="list-style-type: decimal">
<li>other policies that <u><em>don’t</em> change over this period</u> but vary across the districts (abgedeckt durch district FEs);</li>
<li>global policies, that affect both regions the same (time FEs absorbs that);</li>
<li>one example that you would absolutely need to control for in a Diff-in-Diff in the Card &amp; Kruger paper would be „distance to New Jersey", because - after treatment - people near the border would start to head to New Jersey to gain more money because the policy changed rised it in New Jersey, but not in the neighboring state Pensylvania.</li>
</ol></li>
<li><strong>Requirements to use Diff-in-Diff</strong>:
<ol style="list-style-type: decimal">
<li>you need to divide the world into 2 time periods: before &amp; after treatment.</li>
<li>You need two groups: 1) treatment-group &amp; 2) control-group.</li>
<li>Parallel trend assumption needs to hold, otherwise the results are biased.</li>
</ol></li>
</ul>
</div>
<div id="instrumental-variables-iv" class="section level2">
<h2><span class="header-section-number">8.24</span> Instrumental variables // IV</h2>
<ul>
<li><strong>Requirements to use IV</strong>: the instrument needs to be valid, which means:
<ol style="list-style-type: decimal">
<li>corr(Z, coefficient of interest X(1)) &gt; OR &lt; 0 &lt;–&gt; <strong>relevance assumption</strong></li>
<li>corr(Z, u) = 0 &lt;–&gt; <strong>exogeneity assumption // exclusion restriction</strong> (= Synonyme)</li>
</ol>
<ul>
<li><u>Wichtige Bemerkung hier</u>: it is NOT possible to test whether an instrument is valid. To be more precise: only the relevance assumption can be tested, but you <strong>cannot</strong>(!!) test the exogeneity assumption // exclusion restriction. —&gt; You can try and convince your readers and argue in favor of the exogeneity assumption by testing if the differences between two groups are not statistically significant from each other (and that the instrument is indeed a random process which is independent from every variable)</li>
</ul></li>
<li><strong>Key (assumption)</strong>: The instrument Z should affect the outcome Y <u>ONLY</u> through the variable X, and not through any <u>other</u>(!) channel (e.g. Z –&gt; u –&gt; Y darf nicht sein!)</li>
<li><strong>What is the First-Stage and why do you have to look at it?</strong>
<ol style="list-style-type: decimal">
<li>you want to show that the relevance assumption is satisfied, e.g. that there is indeed a correlation between your instrument and your coefficient of interest.</li>
<li>you want a strong instrument, e.g. you want to see a statistical significance of at least 5% on your Z-variable.</li>
</ol></li>
<li><strong>What is the Reduced-Form and why do you look at it?</strong> —&gt; You regress the outcome Y <u><em>directly</em></u>(!) on the instrument, without including your “X” in this regression.</li>
<li><strong>What is the “2 Stage-Least-Squares” regression?</strong> —&gt; this is the regression where you regress your Y on your <strong><u>estimated</u></strong>(!!) coefficient of interest (your statistical software skips the first stage). –&gt; by doing this you only use that part of the variation in your coefficient of interest “X”, that is due to the instrument “Z” which only correlates with “X” and <em>NOT</em> with other unobserved variables in the error-term “u”. —&gt; when you do an IV-Regression, you need to show this. It contains a First-Stage, where you regress your X (= coefficient of interest) on your instrument Z and a reduced form</li>
<li><strong>Usage of causal language?</strong> —&gt; at the 2SLS, you can use causal languange, if you assume the instrument to be valid (bzw. if you assume the exclusion restriction holds!)</li>
<li><strong>How to get the 2SLS-coefficient of interest if you only have the coefficients for the Reduced Form and the First Stage?</strong> –&gt; <u><em>Berechnung</em></u>: 2SLS = Reduced Form / First Stage</li>
<li><strong>LATE // Local average treatment effects</strong> –&gt; Estimates generated from instrumental variables are based on the individuals whose behavior is affected by the instrument. Thus, people refer to instrumental variable estimates as “local average treatment effects (= LATE)”, because these estimates are the average effects for a SUBSET (i.e. local part) of the population.</li>
<li><strong>Use of more than 1 instrument</strong>: You can use more than 1 instrument. However, <u>all</u> instrument need to be <em>valid</em> &amp; you need to include <u>all</u> instruments as explanatory variables in the estimation of the first stage.</li>
</ul>
</div>
<div id="regression-discontinuity-design-rdd" class="section level2">
<h2><span class="header-section-number">8.25</span> Regression discontinuity design // RDD</h2>
<ul>
<li><strong>Requirement to RDD?</strong> –&gt; You need to have a “Cutoff Score” (= Assignment variable? –&gt; Synonyme?) which decides whether you get treated or not. This cutoff score needs to be a continuous variable.</li>
<li><strong>3 Assumptions for the RDD that you need to check</strong>:
<ol style="list-style-type: decimal">
<li>Whether an individual gets treated should <em>ONLY</em> depend on the cutoff score! If - for example - an individual can still decide whether he participates in the treatment or not <u>AFTER</u> he knows his cutoff score, this assumotion is violated!</li>
<li>The individuals <em>cannot</em>(!) perfectly control the cutoff score.</li>
<li>The assignment variable // cutoff score <u><em>cannot</em></u>(!) be caused by the treatment or the outcome (of the treatment?) –&gt; reverse causality –&gt; Y-variable wird zur X-variable und X-variable zur Y-Variable…</li>
</ol></li>
<li><strong>Which people do we compare in an RDD?</strong> —&gt; In a RDD, we only compare our individuals exactly above and below the treatment. That’s why we can say that - whether these indivuals receive the treatment or not - is basically random! The fact that those two individual being treated or not is random is nice, because the variable becomes basically independent (no correlation) from all other factors that we cannot conrtrol for.</li>
<li><strong>External validity with RDD?</strong> In an RDD, we compare the two individuals just above &amp; below the threshold value, e.g. we compare the very first person that does not get the treatment with the last person who gets treated. <em>Generally</em>, this generates precise and valid estimates (that are causal) –&gt; <strong>high internal validity</strong>. But because we look at two precise individuals when estimating our effect, the estimated effects are not generalizable, but rather: they estimate a local treatment effect, which can at most be applied to the individuals just around the threshold, but not for the rest of the sample!</li>
</ul>
</div>
<div id="time-series" class="section level2">
<h2><span class="header-section-number">8.26</span> Time Series</h2>
<div id="wörterbuch-5" class="section level3">
<h3><span class="header-section-number">8.26.1</span> Wörterbuch</h3>
<ul>
<li><strong>Univariate Forecasting</strong>: Verwende nur die <strong>vergangenen</strong> Preise der (<em>eigenen</em>) Zeitreihe, um die Preise der Zukunft zu forecasten.</li>
<li><strong>Multivariate Forecasting</strong>: Verwende - <strong><u>nebst</u> vergangenen Preise</strong> der (eigenen Zeitreihe) - auch noch <strong>andere Zeitreihen</strong>, um die Preise der Zukunft zu forecasten.</li>
<li><strong>Cross-Correlation</strong>: Das ist die Korrelation zwischen dem Preis “heute” und einem bestimmten Lag einer anderen Zeitreihe.
<ul>
<li><u>Mathematisch ausgedrückt</u>: <em>Corr(<span class="math inline">\(Y_t\)</span>, <span class="math inline">\(X_{t-n}\)</span>)</em>, wobei n = {1, 2, …, n}</li>
<li><u>Bemerkung</u>: Leider habe ich <u>kein</u> Python-Package gefunden, welches die <strong>partielle</strong> Cross-Correlation berechnet, was sehr schade ist!</li>
</ul></li>
<li><strong><u>What is the “MA”-Term // q-Parameter in the ARIMA-Modell?</u></strong>: You make a forecast based on the <u>past errors</u> in the time series (= “error lags”).</li>
</ul>
</div>
<div id="seasonality" class="section level3">
<h3><span class="header-section-number">8.26.2</span> Seasonality</h3>
<blockquote>
<p>What is Seasonality?</p>
</blockquote>
<p>A <strong>repeating pattern</strong> <u>within a year</u>.
- <u>Example 1</u>: You see a “M”-shape every day –&gt; <em>Daily Seasonality</em></p>
<div class="figure">
<img src="./bilder/econ/tages-seasonality.jpg" alt="" />
<p class="caption">Beispiel einer Tages-Saisonalität</p>
</div>
<ul>
<li><u>Example 2</u>: You see an “Buckel” for each day of the weak –&gt; <em>Weekly Seasonality</em></li>
</ul>
<div class="figure">
<img src="./bilder/econ/weekly-seasonality.jpg" alt="" />
<p class="caption">Beispiel einer Wochen-Saisonalität</p>
</div>
<ul>
<li><u>Example 3</u>: You see an the same “Abwärtsbewegung” <strong>for the first 3 months of the year(!)</strong> –&gt; <em>Monthly Seasonality</em></li>
</ul>
<div class="figure">
<img src="./bilder/econ/monats-seasonality.jpg" alt="" />
<p class="caption">Beispiel einer Monats-Saisonalität</p>
</div>
<blockquote>
<p>How to get rid // account for Seasonality in the Data?</p>
</blockquote>
<ul>
<li><u>There are <strong>2 possibilities</strong></u>:
<ul>
<li>Use already de-seasonalized data: for example, <em>unemployment rates</em>.</li>
<li>Include all year-, month- or week-dummies (exclude one, otherwise: Dummy-Variable Trap…).</li>
</ul></li>
</ul>
</div>
<div id="cycles" class="section level3">
<h3><span class="header-section-number">8.26.3</span> Cycles</h3>
<blockquote>
<p>What is a Cycle?</p>
</blockquote>
<p>A cycle is NOT the same thing as seasonality! Cycles <strong>take place over the course of several year</strong>, rather than <em>within</em> a year for seasonality. Generally, <strong>cycles are not predictable</strong>.
- <u>Example</u>: <em>Given a time-seroes</em>, there may be a 1st cycle that takes place over the course of 3 years, while another cycle can take 1.25 years to complete –&gt; there is no general rule, to quantify their duration!</p>
</div>
<div id="partial-auto-correlation" class="section level3">
<h3><span class="header-section-number">8.26.4</span> Partial Auto-Correlation</h3>
<blockquote>
<p>Definition?</p>
</blockquote>
<p>Misst den <em>direkten</em> Effekt zwischen dem Preis “jetzt” und dem Preis vor “n”-Stunden (= deshalb “auto”-Korrelation), nachdem der <strong>indirekte</strong> Effekt einer oder mehrerer Kontroll-Variablen (deshalb “partielle”-Korrelation) entfernt wurde.</p>
<div class="figure">
<img src="./bilder/econ/direkt-und-indirekter-effekt.png" alt="" />
<p class="caption">Visualisierung des direkten VS. indirekten Effektes</p>
</div>
<ul>
<li><u>Mathematisch ausgedrückt</u>: <em>Corr(<span class="math inline">\(Y_t\)</span>, <span class="math inline">\(Y_{t-n}\)</span>)</em>, wobei n = {1, 2, …, n}</li>
</ul>
<div class="figure">
<img src="./bilder/econ/partielle-auto-korr-plot.jpg" alt="" />
<p class="caption">Hier ein Beispiel eines partiellen Auto-Korrelations Plot</p>
</div>
</div>
<div id="how-to-create-a-simple-benchmark-time-series-model" class="section level3">
<h3><span class="header-section-number">8.26.5</span> How to create a simple Benchmark Time-Series Model?</h3>
<blockquote>
<p>Vorgehen?</p>
</blockquote>
<p>Erstelle ein simples <code>Mono-Copy</code>-Modell, welches einfach - beispielsweise, bei einer Zeitreihe in <em>Stunden-Einheiten</em> - jeweils die letzten 24 Werte aus der Vergangenheit nimmt, um einen Forecast zu erstellen.</p>
<div class="figure">
<img src="./bilder/econ/monocopy-modell.png" alt="" />
<p class="caption">Monocopy-Modell illustriert</p>
</div>
</div>
<div id="machine-learning" class="section level3">
<h3><span class="header-section-number">8.26.6</span> Machine Learning</h3>
<ul>
<li><strong>Data Splitting</strong>: Weil Zeitreihen-daten die Eigenschaft besitzen, <strong>geordnet</strong> zu sein, muss beim <code>Train-Test Split</code> aufpassen: it is done <u>without</u> <code>shuffling</code> (= randomisation), weil wir ansonsten ein <em>Data Leakage Problem</em> hätten!</li>
</ul>
<div class="figure">
<img src="./bilder/econ/data-leakage-problem-ts.jpg" alt="" />
<p class="caption">Darstellung des Data Leakage Problems bei Time Series: das Modell kann leichte Vorhersagen machen, weil es Teile der Zukunft sieht! xD</p>
</div>
<p>### Cross-Validation for Time-Series</p>
<blockquote>
<p>Berechnung der <em>Validation</em>-Errors?</p>
</blockquote>
<div class="figure">
<img src="./bilder/econ/3-fold-cv-for-ts.png" alt="" />
<p class="caption">Visuelle Darstellung, wie der verschiedenen Validierungs-Fehler (MAPE, MAE oder RMSE) berechnet werden auf dem Trainingsset. Vergesse nicht, dass jeweils bloss ein durchschnittswert pro Tabular-Regression ausgerechnet wird!</p>
</div>
<blockquote>
<p>Berechnung der Test-Fehler?</p>
</blockquote>
<div class="figure">
<img src="./bilder/econ/test-error-calc-ts.jpg" alt="" />
<p class="caption">Visuelle Darstellung, wie die verschiedenen Test-Fehler (MAPE, MAE oder RMSE) berechnet werden. Vergesse nicht, dass jeweils bloss ein durchschnittswert pro Tabular-Regression ausgerechnet wird!</p>
</div>
</div>
</div>
<div id="coded-algorithms-r-functions" class="section level2">
<h2><span class="header-section-number">8.27</span> Coded Algorithms &amp; R-Functions</h2>
<ul>
<li><strong>Monte Carlo Simulation</strong>: PS1, empirical methods, File: „ExpoR“</li>
<li><strong>Construct a Scatterplot (= Streudiagramm) for the residuals</strong>, where you have the residuals on the Y-axis and a certain regressor on the X-Axis (—&gt; in order to check if A3 is satisfied): PS1, empirical methods, File: „Cigs“: Zeilen 20-33 (—&gt; Bemerkung: viel Zusatz, aber nützlicher Zusatz!)</li>
<li><strong>Construct a normal distribution</strong>: PS1, empirical methods, File: „Cigs“: Zeilen 29-33</li>
<li><strong>Do an F-Test to check joint hypothesis</strong>: PS2, empirical methods, „PS2“: Zeilen 5-9 &amp; 45-49</li>
<li><strong>Make a confidence intervall out of a regression</strong>: PS3, empirical methods, „PS3“: Zeilen 15-28</li>
<li><strong>Only take the coefficient from a summary(regression_1) code</strong>: PS4, empirical methods, „PS4“: Zeilen 35; Zeilen 44-46</li>
<li><strong>Reformulate a dataset, such that the unit of observation is not „the twin“, but rather the „family“</strong>: —&gt; PS4, empirical methods, „PS4“: Zeilen 52</li>
<li><strong>Sort a dataset and only display some information &amp; drop some observations: PS4, empirical methods, „PS4“</strong>: Zeilen 83-84</li>
<li><strong>Ommit NAs by looking at one particular column, from which you want to eliminate every NAs</strong>: Replication of Bonjour stud, lifestyle seminar, „Replication“: Zeilen 81-82</li>
<li><strong>Make a beautiful table with two vectors (which are transformed to a dataframe)</strong>: Replication of Bonjour stud, lifestyle seminar, „Replication“: Zeilen 163-182</li>
<li><strong>Randomly add a person to a treatment group &amp; others to the control group</strong>: PS2, PeCi , „PS2“, Zeilen 119-121, Rmarkdown file</li>
<li><strong>Calculate means for treatment and control groups &amp; apply a t-test to see if they differ from each other in their characteristics</strong>: PS2, PeCi , „PS2“, Zeilen 129-133</li>
<li><strong>Breusch-Pagan Test to test for heteroscedastic variances</strong>: PS3, PeCi, Aufgabe 2 a), Zeilen 66-68</li>
<li><strong>Implementation of heterogeneous Treatment effects</strong>: PS3, PeCi, Aufgabe 4 a), Zeilen 112-118 &amp; 130-133</li>
<li><strong>Calculate the average (total) treatment out of (multiple) heterogeneous treatment effects</strong>: PS3, PeCi, Aufgabe 4 b), Zeilen 137-139</li>
<li><strong>Comparison of means in a DiD setting // summary statistics of a dataset using stargazer</strong>: PS5, Aufgabe 3 a), Zeilen 189-206</li>
</ul>
</div>
<div id="nützliche-funktionen-r" class="section level2">
<h2><span class="header-section-number">8.28</span> Nützliche Funktionen R:</h2>
<ul>
<li><strong>Count number of observations</strong>:
<ul>
<li><code>NROW(dataset)</code>: counts the number of rows (= Zeilen = Anzahl Beobachtungen), <strong>OR</strong></li>
<li><code>dim(dataset)</code>: the first number would be the number of observations, the second one is the number of variables in the dataset</li>
</ul></li>
<li><strong>Summary statistics of <u><em>each</em></u> variable in the dataset</strong>:
<ul>
<li><code>summary(dataset)</code></li>
</ul></li>
<li><strong>Simple linear bivariate regression model</strong>:
<ul>
<li><code>lm(data$cigs ~ data$educ)</code></li>
</ul></li>
<li><strong>Simple linear regression <u><em>without</em></u> a constant</strong>:
<ul>
<li><code>lm(data$cigs ~ data$educ + 0)</code>, wobei hier zu beachten gilt, dass <code>lm(y ~ x)</code></li>
</ul></li>
<li><strong>Simple coefficient summary of a regression model</strong>:
<ul>
<li><code>summary(regression_model)</code></li>
</ul></li>
<li><strong>Autocorrelation-function // ACF</strong>:
<ul>
<li><code>acf(residual, main=„title of the plot)</code>, need this to check A4 of the CLRM</li>
</ul></li>
<li><strong>Create a dummy with one condition</strong>:
<ul>
<li><code>ifelse(data$educ &gt;= 16, 1, 0)</code></li>
</ul></li>
<li><strong>Append new vector (of same length as the dataset) to a dataset</strong>:
<ul>
<li><code>data.frame(dataset, dummy_university, log-educ)</code></li>
</ul></li>
<li><strong>Build a subset of a dataset</strong>:
<ul>
<li><code>subset &lt;- subset(data, data$female ==0)</code></li>
</ul></li>
<li><strong>Make a scatterplot (= Streuungsdiagram)</strong>:
<ul>
<li><code>plot(x, y, options)</code></li>
</ul></li>
<li><strong>Make a histogram</strong>:
<ul>
<li><code>hist(X, options)</code></li>
</ul></li>
<li><strong>Adding new variable to the dataset</strong>:
<ul>
<li><code>data[„new-variable“] &lt;- data$educ*data$noob</code></li>
</ul></li>
<li><strong>Select a particular coefficient in your regression</strong>:
<ul>
<li><code>regression$coefficients[5]</code>, Achtung: bei der selection wird der intercept mit in den code berücksichtigt!! Man hat also scho +1 gemacht, das wäre also der coefficient der 4. Variable!!</li>
</ul></li>
<li><strong>Create a confidence intervall vector</strong>:
<ul>
<li><code>predict(regression, intervall=„confidence“, level=.95)</code></li>
</ul></li>
<li><strong>Delete a whole column (= variable) from a dataset</strong>:
<ul>
<li><code>dataset$female &lt;- NULL</code></li>
</ul></li>
<li><strong>Tell R in which format a date (= Datum) is</strong>:
<ul>
<li><code>dataset$arrest_date &lt;- as.Date(datase$arrest_date, format =„%m/%d/%Y“)</code></li>
</ul></li>
<li><strong>Umbenennung einer Spalte mit einem Spalten-Namen, welcher mehr Sinn macht</strong>:
<ul>
<li><code>data$white_crime &lt;- data$PERP_RACE_WHITE</code></li>
</ul></li>
</ul>
</div>
<div id="useful-econometrics-documents" class="section level2">
<h2><span class="header-section-number">8.29</span> Useful Econometrics documents:</h2>
<ul>
<li><strong>Datascience</strong>:
<ul>
<li>Datascience cheat-sheat:<a href="https://storage.ning.com/topology/rest/1.0/file/get/1211570060?profile=original" class="uri">https://storage.ning.com/topology/rest/1.0/file/get/1211570060?profile=original</a></li>
<li>r-graph-gallery.com</li>
<li>python-graph-gallery.com</li>
</ul></li>
<li><strong>Different Statistical Tests &amp; Models</strong>:
<ul>
<li>Common statistical tests are linear models: <a href="https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf" class="uri">https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf</a></li>
<li>Statistical Power Calculator: <a href="http://powerandsamplesize.com" class="uri">http://powerandsamplesize.com</a></li>
</ul></li>
<li><strong>Difference-in-Differences // DiD</strong>:
<ul>
<li>Revisitting parallel trend assumption: <a href="https://blogs.worldbank.org/impactevaluations/revisiting-difference-differences-parallel-trends-assumption-part-i-pre-trend" class="uri">https://blogs.worldbank.org/impactevaluations/revisiting-difference-differences-parallel-trends-assumption-part-i-pre-trend</a></li>
</ul></li>
<li><strong>Machine Learning</strong>:
<ul>
<li>Fussball Machine Learning code in python: <a href="https://mariamsulakian.com/2018/02/01/machine-learning-predicting-the-2018-epl-matches/" class="uri">https://mariamsulakian.com/2018/02/01/machine-learning-predicting-the-2018-epl-matches/</a></li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="git-versioncontrol.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="machine-learning-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/joffreymayer/ds-from-scratch/edit/master/08-econometrics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/joffreymayer/ds-from-scratch/blob/master/08-econometrics.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
