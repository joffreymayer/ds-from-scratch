# Machine Learning

In diesem Kapitel, werde ich vertiefter in das Thema "Machine Learning" eingehen. 

## Typen von Machine Learning

Es gibt grundsätzlich **2 Kategorien**, in denen die verschiedenen *Methoden in Machine Learning* eingeordnet werden:

1) **Supervised Learning**
    - <u>Goal 1</u>: **Classification**
      - Image Classification
    - <u>Goal 2</u>: **Predictions** with Regressions
      - Translation (zum Beispiel angewendet in Deepl.com)
      - Image Captioning (siehe Bild): ![Beispiel zu Image Captioning](./bilder/machine-learning/example-image-captioning.png)
      
  
2) **Unsupervised Learning**
    - Clustering:
      - Matching // K-Means Clustering
    - Dimension Reduction:
      - Principal Component Analysis (PCA)
    - Outlier Detection
  

## Supervised Learning

**Bei Supervised Learning** wird die **Annahme** gemacht, *dass man die Funktion 'f' **kennt**, um mittels den Werten der Zufallsvariablen 'X' die Werte der Zufallsvariablen 'Y' herauszufinden*. 

<u>Mathematisch ausgedrückt</u>: `f : X -> Y`.

## Methods

Hier soll eine Auflistung aller Vorgehen bei Machine Learning aufgelistet werden:

- **<u>Algorithm for "best fit" to find the weights</u>**:
  
  1) Guess some random weights.
  
  2) "Go downhill", e.g. **apply a _learning rate_** when using the method **gradient descent**.
  
  3) Is the **fitted line good enough?** 
      - If the *answer is "no"*, then go **back to point 2)**.

## Wichtige Funktionen

Da Machine Learning mittels Aktivierungsfunktionen funktioniert, folgt eine Übersicht zu verschiedenen Funktionen:

- **<u>Identity Function</u>**: damit ist die Funktion `f(x) = x` bzw. `y = x` gemeint:

```{r identity-function, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
myfun <- function(xvar) {
  xvar
} # first, I specify the function
ggplot(data.frame(x = c(-10, 10)), aes(x = x)) +
  stat_function(fun = myfun, geom = "line", colour="#FF9999") + # then, pass the above "user-defined function" called 'myfun' as an input into the function stat_function(). Note that I plot the function with a red line, to differentiate it from the x- & y-axis.
  geom_vline(xintercept = 0) + # zeichnet eine vertikale Linie bei 0, um die y-Achse zu verdeutlichen
  geom_hline(yintercept = 0) # zeichnet eine horizontale Linie bei 0, um die y-Achse zu verdeutlichen
```

- **<u>Logitstic Function // Sigmoid Function // S-Shaped Function</u>**: damit ist die Funktion $\sigma(x) = \frac{1}{1 + e^{-x}}$ gemeint:
  
```{r input-only-2, echo=FALSE, message=FALSE, warning=FALSE}
# Here I will plot a Graph with ggplot2:


### 1) Load packages & datasets needed:

library(ggplot2)
library(dplyr)
library(gcookbook)

### 2) Plot a function:

myfun <- function(xvar) {
1 / (1 + exp(-xvar))
} # first, I specify the function

# First, create a dataframe with only 1 variable - e.g. our range of x-values -
# that goes - for example - from 0 to 20 [note that - technically - the command
# x = c(0,20) will only create two values, namely 0 and 20, but NOT the whole
# range of values from 0 to 20!!! However, the code below works anyway!]. Next,
# tell R that you want those numbers 0 & 20 to be plottet on your x-axis -
# -> this is all the code within the 'ggplot()' function:
ggplot(data.frame(x = c(-7, 7)), aes(x = x)) +
  stat_function(fun = myfun, geom = "line", colour="#FF9999") + # then, pass the above "user-defined function" called 'myfun' as an input into the function stat_function()
  geom_vline(xintercept = 0) + # zeichnet eine vertikale Linie bei 0, um die y-Achse zu verdeutlichen
  geom_hline(yintercept = 0) # zeichnet eine horizontale Linie bei 0, um die y-Achse zu verdeutlichen
```


## Difference between Training-, Validation- &amp; Test-dataset

Since I started with Machine Learning, I was always confused about the concept of **data splitting**, e.g. which sub-set of the *entire* dataset is now considered to be the *training dataset*, which one is the *validation dataset* and which one is the *testing dataset*. 

<u>In the graph below, you see how it is defined correctly</u>:

![Training Set VS. Validation Set VS. Test Set](./bilder/training-VS-validation-VS-test-ddset.jpg)

- <u>Important to note</u>: There is oftentimes confusion between the definition of *validation dataset* VS. *testing dataset*, because there is no consens about it. **Therefore - and if we take the above picture as the "true" definition - some people will call the *validation dataset* the "test dataset" and vice versa, e.g. the *test data* as the "validation data"! xD** 

### Validation-Set VS. Test-Set

> What is the difference between a `Validation Dataset` and a `Testing Dataset`?

Es gibt keinen Konsens dafür, was nun das `validation dataset` und welches das `test set` genau ist. **Nima** (= mein Mentor bei der SBB) verwendet den Begriff `test set` für dasjenige Dataset, welches `hold out` // separat für die (spätere) `Prediction` verwendet wird.

- <u>Regel zu Unterscheidung der beiden Terme</u>: Wenn steht: `we hold out [name of the set]`, dann ist es das `testing dataset`.

### Reason for a Validation-Set

> Why do we need `validation set`?

At the end, you want the best model possible. If you want to tune your hyperparameters, you will need your `test set`. **The big problem here, however, is that - *if we use the test-set more than once when wanting to find out the best hyperparameters* - our model will know the data by heart and the predictions will be too good, <u>but only</u> on this dataset that you are currently using**! The model will not generalize well on new data. 

*That's why we need this additional subsetting of the training-dataset!*

## Concept of Stratification

Angenommen du hast eine *kategorische* Y-Variable, welche entweder Nullen oder Einsen als Werte annimmt. Nehme nun an, dass - *im Training-Dataset* - der Anteil der Nullen 60% beträgt. Wenn du nun ein `stratified Sample` willst, dann wird das *Test-Dataset* ebenfalls einen Anteil von 60% an Nullen enthalten!

- <u>Quelle</u>: [Train-Test-Split in Sklearn and Cross-Validation](https://www.youtube.com/watch?v=KEBS7Kyc0Po)

## Cross-Validation

The concept of *cross-validation* can be splitted into 2 parts:

- <u>Step 1</u>: Split your dataset into 1 training- &amp; 1 test-set.
	- <u>Rule of Thumb</u>: Usually, the split is **70-90% training set** and **10-30% for the test-set**.
	- <u>Code Example</u>: 

![Example of Code for Train-Test Split](./bilder/code-example-cross-validation.png)

- <u>Step 2</u>: Now, we divide the *training set* further, such that it will contain - *if we assume a 3-fold cross-validation as an example* -  **3 <u>different</u> validation sets** and **3 training sets**.

![Allgemeine Cross-Validation](./bilder/example-of-a-general-3-fold-cross-validation.png)

### <u>Special Case</u>: Cross-Validation for Time-Series Data

Because time-series are ordered, since *the flow of time* is only going forward, the graph shown above for *step 2* is <u>not</u> valid and we need another approach!

### Why do we use Cross-Validation?

There are 2 reasons:

1) It allows us **to compare the score (MAPE, MAE or RMSE) of different model set-ups**, for example: 
  - *CV-Scheme changes*, e.g. a _Time-Series_ Prophet-Model with a `Sliding-Window` of 4 Months VS. a Prophet-Model with an `Expanding-Window` (full past).
  - OR *changes in the covariates*, e.g. a model that includes an important covariate, while the other model does not.
  **This will allow you to draw conclusions regarding the selection of "the best" model**.
2) It allows you **to assess the performance** of different machine-learning methods. In a _classification-setting_ for example, you can use the _confusion-matrix_. 

![Cross-Validation for Time Series](./bilder/example-3-fold-cross-validation-for-time-series.png)

This picture shows **an example of a 3-fold cross-validation for a time-series**. 


## Normalisierung der Daten

> Was versteht man unter `Normalisierung`? Was sollte man dabei beachten? Warum wird in einem Pre-Processing Schritt eine Normalisierung durchgeführt?

`Normalisierung` == **Subtrahiere den Mittelwert und dividiere durch die Standardabweichung jedes Merkmals**. Es sollte beachtet werden, dass der Mittelwert und die Standardabweichung **nur anhand der Trainings-Daten berechnet werden sollte**, damit die Modelle keinen Zugriff auf die Werte in den Validierungs- und Testsätzen haben.

**Es ist wichtig, Features zu skalieren, bevor ein neuronales Netzwerk trainiert wird**. Normalisierung ist eine gängige Methode für diese Skalierung.

## RNN

> Was macht ein `Reccurrent Neural Network (RNN)`?

Ein Beispiel für ein RNN wäre ein `Long Short Term Memory` Modell (LSTM Modell). Dabei nimmt das RNN zunächst ein ganz kleines Vergangenheits-Intervall, macht eine Modell-Estimation und dann - im nächsten Schritt - wird ein grösseres Vergangenheits-Intervall verwendet (**inkl. predicted Y-Variable aus dem vorherigen Modell**), um eine neue Modell-Estimation zu machen etc.

![Beispiel eines RNN: hier ein LSTM](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/lstm_many_window.png?raw=1)

## Data-Pipelines

**Data Pipelines use an input to produce an output and then - on a second step - use the produced output as an input to produce another output etc...**

- <u>Visualisierung</u>: Du kannst dir unter _Data Pipelines_ nichts anderes als eine "Guetzli Fabrik" vorstellen, welche diverse Produktionsmaschinen verwendet - zum Beispiel einen Teig-Cutter, dann einen Butter-Schmierer, sowie einen fetten Ofen und einen Sortierer von "guten VS. schlechte Guetzli" - um die Inputs immer weiter zu verarbeiten, sodass schlussendlich ein Endprodukt (= die fertigen "Guetzli") ensteht, dass man verkaufen kann.

> [How to create good Data-Pipelines in Scikit-Learn?](https://www.youtube.com/watch?v=w9IGkBfOoic)

 - <u>Ziel von Data-Pipeline</u>: Write more clean // readable code, especially when you do <em>data cleaning</em>. **A datapipeline is basically a way of standardizing your code**.
 - <u>Warum sind Data-Pipelines so geil?</u>: Because you can **compare many different regression-models (Linear-Regression Vs. Logistic-Regression Vs. RandomForrest ...), applying different "scaling-techniques" (= normalize a variable with mean 0 and standard-deviation of 1), as well as using "data cleaning techniques" (= reduce dimensions via PCA, reduce missing-values etc...)**. Another cool thing to note is, that **you can choose the order, in which the cleaning, scaling and fitting occures!**
   - See also the summary of the guy [on Youtube ab 10:00-11:00](https://www.youtube.com/watch?v=w9IGkBfOoic).
- <u>Link to Github for an example</u>: <a href="https://github.com/krishnaik06/Pipelines-Using-Sklearn/blob/master/SklearnPipeline.ipynb" target="_blank">Jupyter-Notebook code-example on how to create a little Data-Pipeline by yourself</a>

## Uni-Kurs `Neural Networks & Deep Learning`

### Notation Neural Networks

**Machine Learning verwendet unterschiedliche Begriffe für diverse gleiche Konzepte & Definitionen aus den Wirtschaftswissenschaften**. Nun geht es darum, die korrekte Übersetzungen für diese Wörter aufzulisten: 

- weights = Beta-Coefficients = parameters = a, b = neurons
- Input units = independent variables "x" 
- inputs = Anzahl Observations in Total
- Output unit = Dependent variable "y" = labels
- Activation function (AF) = you need this function to plug in your <u>estimated</u> regression model. 
  - <u>**Examples of AF**</u>: 
    - logit, 
    - probit, 
    - relu, 
    - simple "threshold" AF etc...
- Perceptron = Linear Binary Classifier = usually, the perceptron is a <u>linear</u> separator (= line that separates group in a regression) = *Perceptron* is a **single layer neural network**
- Multi-layer perceptron == *Neural Networks*.
  - <u>Example</u>: 
  ![Neural Network with 3 Layers](./bilder/machine-learning/example-of-a-multi-layer-network.png)
- learning rate = how far to go in a particular direction
- features = inputs = independent variables "x" = X<sub>ki</sub>
- labels = this is the "true Y" you observe in the real world = output = dependent variable
- "going downhill" = this is the learning process that you get by using the method "gradient decent" ([look youtube video of user called "the coding train" at ca. 17:30](https://www.youtube.com/watch?v=L-Lsfu4ab74)) & applying a "learning rate" to it
- y<sub>k</sub> = this is the <u>estimated</u> regression function
- z<sub>k</sub> = "logits", e.g. this is the whole *sum of the weights multiplied by the x-variables (= entire regression)*, but this time we **put this entire regression as an _input_ into the logistic function** --> <u>in other words</u>: the same as y<sub>k</sub> but we then apply the specific activation function "logit function" to the estimated z<sub>k</sub> // $\hat{y}$
- Input Layer = Layer 0 = very first set of Neuron
- Output Layer = Last Layer = last set of Neurons
- Hidden Layers = All Layers between the input & output Layer
- input node = nodes at the input layer
- output node = nodes at the output layer
- hidden nodes = nodes, which are in the hidden layers or at the output layer & don't give out outputs
- Feed forward neural networks = connections only between layer i and layer i+1
- Convolutional neural networks = a type of feed-foward network
- Recurrent neural networks = connections flow backwards to previous layers as well
- supervised learning = function estimation
  - <u>There are 2 different types</u>: 
    1) regression,
    2) classification
- unsupervised learning = structure the data into groups (very subjective) // detecting patterns. 
  - Can also be used for:
    1) data reduction,
    2) outlier detection
- loss-function = cost-function = [TRUE y - ESTIMATED $\hat{Y}$]<sup>2</sup> = error --> we define the loss-function be the "least squares"
- identity function = y = x bzw. f(x) = x
- sigmoid function = logit function
- bias term = error term 
  - <u>Note</u>: Oftmals wird der **"input" für den bias term als Zahl "1"** angegeben (siehe Bild oben "Example of Multi-Layer Network", wo der bias term als Zahl "1" angegeben ist.)
- Epoch = means we go through the whole data set once --> default is ten epochs
- Net Input Function = Regressionsmodell als Ganzes = sum of all weighted inputs // "x"
- kernel = (starting) values for the weights
- regularizers = penalties that are used to reduce overfitting (of the starting values for the weights?)
- backpropagation = back pass = when we have our error-term, we can calculate the gradient and - if the error was too big - we can backpass the error-term with the help of the *learning rate* to a previous layer and estimate new // better weights
- breaking symmetry = principle, which says that you need to have different initial weights for hidden units with the same activation function and same inputs
- batches = these are smaller samples that you take from the whole dataset, e.g. you take only a fraction of the dataset  --> you use batches because the computation gets faster rather than putting the whole dataset into the machine
learning "Apparat" --> Rule: the higher the batch size, the better estimates you get
- decay = In Machine Learning, it has become kind of standard to make learning rates dynamic, e.g. first have bigger learning rates, because you can be very wrong at the beginning with the random weights, but then - towards the end of estimation - you adapt the learning rate only very smoothly, since you slowly go towards the optimum --> typically, this decay will make the learning rate smaller as the training continues.
- momentum = makes learning rates dynamic --> If you see that - in the history of gradients - the gradients point generally in the same direction, momentum will adjust the learning rate by increasing the step size
- hyperparameters = <u>examples are</u>: 
  - Learning rate, 
  - Learning Rate Decay, 
  - Momentum, 
  - Batch Size, 
  - Weight / Bias initialization
- Confusion Matrix = C = shows - in the diagonal of the matrix - how many times your predicted outcome was the same as the actual outcome. All the other numbers are saying that your model's prediction was not in line with the actual outcome
- Precision = if i look at a guess // prediction, how many % my algorithm guessed correctly? --> E.g. Anteil der predicted outcome $\hat{y}$, welche korrekt mit den ture outcomes übereinstimmen.
  - <u>Mathematisch ausgedrückt</u>: Im Zähler die Anzahl an übereinstimmenden predicted outcomes $\hat{y}$ & im Nenner Totale Anzahl an predicted Outcomes $\hat{y}$.
- Recall = if i look at an actual true outcome, how many % where guessed correctly? --> E.g. Anteil der true outcome Y, welche korrekt vorhergesagt wurden 
  - <u>Mathematisch ausgedrückt</u>: Im Zähler die Anzahl an korrekt vorhergesehenen true outcomes & im Nenner Totale Anzahl an True Outcomes.
- Training data = Training set is the one on which we train and fit our model basically to fit the parameters.
- Testing data = Testing Data is used only to assess performance of the model.
- Variance = Overfit = you use too much X's // features in your model --> you get too much variance in your predictions
- Bagging = Train the same architecture on different subsets of data
- Boosting = Train different model architectures on the same data
- data augmentation = get more data by adding noise on the input layer
- weight tying = Make the weights similar

#### Alphabetisch sortiert:

Um die Begriffe noch leichter zu finden, habe ich sie hier noch alphabetisch sortiert:

- Activation function = you need this function to plug in your estimated regression model. Examples of AF = logit, probit, relu, simple "threshold" AF etc...
- backpropagation = back pass = when we have our error-term, we can calculate the gradient and - if the error was too big - we can backpass the error-term with 
the helplearning rate to a previous layer and estimate new // better weights
- batches = these are samples from the whole dataset --> you use batches because the computation gets faster rather than putting the whole dataset into the machine
learning "Apparat" --> Rule: the higher the batch size, the better estimates you get
- bias term = error term 
- breaking symmetry = principle, which says that you need to have different initial weights for hidden units with the same activation function and same inputs
- Confusion Matrix = C = shows - in the diagonal of the matrix - how many times your predicted outcome was the same as the actual outcome. All the other numbers are saying that your model's prediction was not in line with the actual outcome
- Convolutional neural networks = a type of feed fowardnetwork
- decay = make learning rates dynamic --> typically, this decay will make the learning rate smaller as the training continues.
- Epoch = means we go through the whole data set once --> default is ten epochs
- features = inputs = independent variables "x" = X(ki)
- Feed forward neural networks = connections only between layer i and layer i+1
- "going downhill" = this is the learning process that you get by using the method "gradient decent" (look youtube video by "the coding train" at ca. 17:30) & applying a "learning rate" to it
- Hidden Layers = All Layers between the input & output Layer
- hidden nodes = nodes, which are in the hidden layers or at the output layer & don't give out outputs
- hyperparameters = examples are: Learning rate, Learning Rate Decay, Momentum, Batch Size, Weight / Bias initialization
- identity function = y = x bzw. f(x) = x
- inputs = Anzahl Observations in Total
- Input Layer = Layer 0 = very first set of Neuron
- input node = nodes at the input layer
- Input units = independent variables "x" 
- kernel = (starting) values for the weights
- labels = this is the "true Y" you observe in the real world = output = dependent variable
- learning rate = how far to go in a particular direction
- loss-function = cost-function = [TRUE y - ESTIMATED Y(hat)]^2 = error --> we define the loss-function be the "least squares"
- Net Input Function = Regressionsmodell als Ganzes = sum of all weighted inputs // "x"
- momentum = makes learning rates dynamic --> If you see that - in the history of gradients - the gradients point generally in the same direction, momentum will adjust the learning rate by increasing the step size
- Output Layer = Last Layer = last set of Neurons
- output node = node at the output layer
- Perceptron = Linear Binary Classifier = linear seperator (= line that separates group in a regression) = Perceptron is a single layer neural network and a multi-layer perceptron is called Neural Networks.
- Precision = if i look at a guess // prediction, how many % my algorithm guessed correctly?
- Recall = if i look at an actual true outcome, how many % where guessed correctly
- Recurrent neural networks = connections flow backwards to previous layers as well 
- regularizers = penalties that are used to reduce overfitting (of the starting values for the weights?)
- sigmoid function = logit function
- saling = pre-processing data 
- supervised learning = function estimation --> 2 different types: 1) regression; 2) classification
- Training data = Training set is the one on which we train and fit our model basically to fit the parameters.
- Testing data = Testing Data is used only to assess performance of the model.
unsupervised learning = structure the data into groups (very subjective) // detecting patterns // data reduction
- weights = Beta-Coefficients = parameters = a, b = neurons
- y(k) = this is the estimated(!!) regresion function
- z(k) = "logits" --> the same as y(k) but we then apply the specific activation function "logit function" to the estimated z(k) // y(hat)
    
## Wörterbuch 

### Synonyme

- Training Dataset // Training Set
- Testing Dataset // Test Set
- generalize // extrapolate
- relativ zu // im Verhältnis zu
- feed in // plug in
- shape // dimension 
- target // predicted y-value
- Treiber // x-Variablen
- Score // Error 
- Cross-Validation Score // Validation Error
- Volume // Speicherplatz
- Weights // estimated coefficients
- Parameter Tuning // Grid-Search
- tweakable parameters // veränderbare Parameter (wenn du Parameter-Tuning)

### Data Science

- __Samples__ == number of rows // number of observations within a dataset.
- **Instance**: value within a cell --> konkreter "x"-Wert, welcher angenommen wird und du - beispielsweise - für eine Prediction verwenden kannst.

![This is the overview of a `Pandas` DataFrame, where an instance would be nothing else but a "value".](./bilder/python-lib/pandas-df.jpg)

- __Label__: _true_ y-value
- __Forcasted data__: These are the predictions that you do via the help of a model (--> by plugging in concrete x-values), that you've built.
- __Training Dataset__: This is the sample, that you use to estimate your model.
- __Testing Dataset__: This is the `hold out`-set, which you use at the end, to check whether your model is able to generalize // extrapolate well to new data.
- __"The model is learning"__: What is meant by "learning" is --> given some Datenpunkt-Wolke, the computer will try and fit the "best line" [oftentimes by minimizing the sum of the squared residuals, if you use `OLS` (= Ordinary Least Squared) OR by using the _Gradient Descend Method_, when you have more data] to construct the "best model" possible.
- __Training__: You are estimating a model on the trainig-dataset, such that the model "learns" from the data.
- **Bias**: When a modl displays "bias", then it means that your model is too simpel (not enough `X`-variables included, for example) and - as a result - your estimated `sample regression function` is not able to approximate the (true) underlying (unknown) `population regression function`.
![Alternatively, this is the definition, Google-Researchers gave to `bias`.](./bilder/home/def-bias-from-google.png)
- __Overfitting__: The problem of overfitting occurs when a model is **too complex and captures too much detail** from the _training_ data. This can lead to the model being unable to generalize to new, unseen data.
  - <u>Fazit</u>: This is like the problem of "**low external validity**". You may have a high "internal validity", but external validity is _low_! 
- __Shuffle__: englisches Wort für "mischen". In the context of `splitting the dataset into test- & training-data`, it is common practice to `shuffle` your observations within your dataset first.
	- <u>Reason why you `shuffle`</u>?: Shuffling data serves the purpose of
		- reducing variance AND 
		- making sure that models remain general AND 
		- overfit less.
	- <u>Merke</u>: When dealing with _time-series_, you should not use `shuffle` when `splitting the data` into training- &amp; testing-data.
- __Training Score OR Test Error__: This error // score is the [oftentimes squared] difference between the _true_ Y-variable and _predicted_ Y-variable (= $\hat{y}$).
  - Note that the for the formula $\sum_i^N{(y_i-\hat{y_i})}$, the **$y_i$** can be either related to:
    - The **test**-set, when you are evaluating the _final_ model-performance, OR 
    - The **validation**-dataset, when you are evaluating how well the model is "performing" with the help of _Cross Validation_, e.g. how the model performs with an increasingly bigger `training dataset`.
- __Cross-Validation Score__: This is the _mean_ error // score that **measures // evaluates how the model is "learning" over increasingly bigger `training datasets`**.
  - It is important to highlight the fact that this metric is only a _mean_, e.g. you don't see the _individual_ forecast that was being made. 
  - The **main purpose** of this metric is to be able **to judge the model-performance very quickly: with only 1 single number, namely the mean error (by an increasing amount of sample-size)**. 
  - If you have a "bad" model - e.g. a high mean error - you will need to look at the _individual_ errors (and not just the mean error), in order to understand what went wrong with the model! 
- __Fold__ == **subset** of the `training dataset`.
	- <u>Example</u>: In a `K-Fold Cross-Validation`, you *randomly* split the <u>training set</u> into **10 distinct subsets**, which are called `folds`.
- __Grid__: Das ist nichts anderes als die **Optimierung von diversen "Modell-Parametern"**. 
		- <u>Beispiel</u>: Bei Random-Forrest Modellen kann man zum Beispiel die Tiefe eines Modells bestimmen, dh die relevante Frage, welche ein Forscher sich stellt, ist: ***wie viele Baum-Zweigungen die geeignesten Predictions bringen?***. Mit Funktionen, wie zum Beispiel `GridSearchCV()` kann dieses Problem geregelt werden.
- __Classifiers__: These are simply Regression-Functions, where **the Y-variable is binary**, e.g. die Y-Variable kann nur `Y = 0` <u>oder</u> `Y= = 1` als Werte annehmen. 
  - <u>Beispiele</u>: 
    - Logit-Regression
    - Probit-Regression
    - Naive Bayes
    - etc...
	- <u>Example</u>: Logit- &amp; Probit-Regression, or Naiv Bayes, etc...
- **feed in**: Häufig im Zusammenhang mit Einsetzen von konkreten Werten für die x-Variablen in das _geschätzte_ Modell, um Predictions zu erhalten.
- **Batch**: sample-size when you train your model with a dataset.
- **Granularität** (Beispiel): Angenommen, man möchte wissen, wie viele Tage, Stunden, Minuten und Sekunden innerhalb von 20'044 Sekunden enthalten sind &#8594; hier haben wir also *Granularität von 4* &#8594; 
  - <u>Lösung</u>: 4 Tage, 18 Stunden, 37 Minuten, 44 Sekunden
- **Kalibrierung des Modells**: Wie wurde das Modell programmiert im Allgemeinen? &#8594; Dazu gehört - beim `preisprog`-Projekt der SBB - die Anpassung der Prognose.
- __Extrapolation__: Das ist eine _Prediction_, welche mittels X-Variablen ermittelt werden, welche <u>zuvor nicht im Datensatz</u> waren.
- __Interpolation__: Das ist eine _Prediction_, welche mittels X-Variablen ermittelt werden, welche <u>bereits im Datensatz</u> waren, als die Schätzung getätigt wurde.
__Pearson Korrelation__ == <u>Lineare</u> Korrelation

### Time-Series

- __Sliding Window__: This is just a way to tell python how to do a cross-validation and have equal lengths of time series where we can learn on.
- __Forecasting Horizon__: These are the points in time (in the future), for which you want to make a prediction (= $\hat{y}$). This is something, you need to define, when you want to estimate your model in a _time-series_ setting.
- __Learning Task__: Forecasting Task // Extrapolation [in Time Series] --> _not sure if this is correct_... xD
- __Time Heterogenous Data__: These are different time-series datasets, that have different time stamps.
	- <u>Quelle</u>: Ab 27:05 (Link: http://www.youtube.com/watch?v=Wf2naBHRo8Q&t=27m05s)
- __Seasonal Periodicity__: The number of times per year, in which the forecaster expects to see a seasonal pattern. 
	- <u>Concrete Example</u>: In Philipp's Notebook, he had a seasonal periodicity of 2, e.g. he said that in winter & sommer, he expects a seasonal pattern.
- __"Reduction is composable"__: Synonym wäre "addieren" &#8594; E.g. you can split a difficult task into a bunch of smaller tasks (= `reduction`) and "add" them together to solve the bigger task at the end &#8594; "reduction is composable"...

## Quellen 

- https://blog.exxactcorp.com/lets-learn-the-difference-between-a-deep-learning-cnn-and-rnn/
https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/notes/Sonia_Hornik.pdf


