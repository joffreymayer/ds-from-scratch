---
title: "Foundations of Data Science"
author: "Joffrey Mayer"
date: "10/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Foundations of Data Science

In diesem Kapitel werde ich auf diverse **"Key-Concepts"** eingehen, die _implizit_ im Raum stehen, wenn du Data Science betreibst. Dabei steht im Fokus:

- Jargon / Fremdwörter in Data-Science 
- Technische Nuancen, die du in Bewerbungs-Interviews eventuell beantworten werden musst.
- Good Practices im Job.
- etc...

## Technisch Essentiell

### Data Science VS. mein Economics-Studium

> Was ist der Unterschied zwischen einem `Data Scientist` VS. was ich in meinem `Economics-Studium` gemacht habe?

- <u>Erkenntnis</u>: Machine Learning wird als eine "Black Box" betrachtet, wo man den X-Variablen des Modells keine grosse Beachtung schenkt: man bringt sie einfach ins Modell rein. Im Kontrast dazu, sind Ökonomen mehr dazu getrimmt, mit Hilfe eines theoretischen Modells, die "richtigen" X-Variablen zu selektieren.

### IDE explained

> What is an **IDE**?

  - <ins>Abkürzung</ins>: `IDE` == Integrated Development Environment
  - <ins>Definition</ins>: An integrated development environment (IDE) is software for building applications. It combines common developer tools into a single graphical user interface (GUI).
  - <ins>Example</ins>: R, PyCharm oder Visual-Studio Code are all IDEs. Think of it as a modern Dream Weaver! :)
  
> What are **Rest APIs**? 

  - <ins>Synonym</ins>: Restful APIs
  - <ins>Defintion</ins>: API stands for *<ins>A</ins>pplication <ins>P</ins>rogramming <ins>I</ins>nterface*. An API is a contract that allows a developer (= you) to interact with an "application" (= a database // the object of interest) through a set of "interfaces" (= list of URLs // this is *how* you are able to interact with the "application", which can be an App, a library in R / Python or a Database).
  	- Quelle: [Pokemon-API](https://pokeapi.co/about)
  - <ins>Zusammengefasst in meinen Worten</ins>: **Ein API sind Befehle, die du gibst, um mit einer Datenbank (z.B. auf einem Server) zu kommunizieren oder ein Package (in R oder Python) zum runnen zu bringen.** Ganz einfach xD
  - <u>Background Client-Server Architecture</u>: most of the applications these days, follow this architecture.
    - Client == App itself == Front-End
    - Server == Back-End
  
  - Communication between the Sever & the Client (= App) happens via API by using the `Http Protocol`.
    - <ins>Example</ins>: if the App wants to access the particular data of a customer, it sends a request to the server via http-protocol.
  - **So, when does the `Rest API` comes into play?** --> the Rest API is **a standard that established itself in the industry, when communaction between client & server** --> these are the `CRUD Operations`, which are by definition: 
  
    1) `GET` == *getting the data from the server*
    2) `POST` == *creating data*
    3) `PUT` == *updating data*
    4) `DELETE` == *deleting data*

> Beispiel eines `API` in Python?

Das Modul // Package `sktime` verwendet einen ähnlichen `API`, wie die berühmte Machine-Learning `sklearn`-Library. Hierbei wäre der Programmierer (= Du) als *Forecaster* verstanden, welcher via sogannten *methods* (zum Beispiel die *fit-method*, um das Modell zu trainieren // estimaten) mit der *application* (= hier: Python) interagiert.

> "Magic Commands" in Python, mit denen du unglaublich schnell herausfinden kannst, was eine Funktion überhaupt tut UND welche Inputs in eine Funktion gehören?

1) `shift` + `Tab` &#8594; wenn du nicht weisst, was eine Funktion // Method tut
2) `Tab` &#8594; innerhalb einer Funktion, um eine Übersicht zu allen Inputs zu erhalten! xD

> What is the `Pipe-Operator` in `R` and what does it do?

The Pipe-Operator in `R` looks like this: `%>%`. It takes in an input and "transports" it into another function to use the input and produces an output. This verbal explanation can be best illustrated via a code-example in R: 

```
library(tidyverse)
result <- mtcars %>% 
    group_by(cyl) %>% 
    summarise(meanMPG = mean(mpg))
```

- Quelle: [A Guide to the Pipe in R](https://towardsdatascience.com/an-introduction-to-the-pipe-in-r-823090760d64#:~:text=The%20pipe%20operator%20feeds%20the,the%20tibble%20result%20%2C%20shown%20below.)

> What is end-to-end Data-Science?

An end-to-end data scientist can **identify and solve problems with data, to deliver value**. To achieve the goal, they'll wear as many (or as little) hats as required. 

## Data Science Werkzeuge

> Was ist `Docker` und was ist der Vorteil davon?

Docker ist ein **Virtual Environment**, welches - wie ein Container - dir Punktgenaue Versionen von bestimmten Packages und Programmiersprachen (Python etc.) liefert. `Docker` läuft über `Open Shift`, welches eine Art **Management-Programm** für `Docker` ist (so viel ich das verstanden habe...).

Wichtig zu wissen ist, dass JEDES `Data Science Kit Notebook` ein Docker-Container ist, welcher auf `Open Shift` läuft. Dies hat den Vorteil, dass jedes dieser Notebooks auf jeder Maschine ge-runnt werden kann, ohne das Error-Problemen wegen aktualisierten Libraries zu begengnen.

> Was ist eine `Data-Pipeline`?

After streaming your data (in real time) // downloading your data from a provider, it's basically **a way to automate the process of data cleaning** in order to be able to get the plots // models from your "dirty data" in a fraction of the time you would spend, if you would do the data cleaning "by hand" yourself.

- - <ins>Youtube-Video</ins>: [What is a Data-Pipeline?](https://www.youtube.com/watch?v=VtzvF17ysbc)

> What is the difference between a `Validation Dataset` and a `Testing Dataset`?

Es gibt keinen Konsens dafür, was nun das `validation dataset` und welches das `test set` genau ist. **Nima** (= mein Mentor bei der SBB) verwendet den Begriff `test set` für dasjenige Dataset, welches `hold out` // separat für die (spätere) `Prediction` verwendet wird.

- <ins>Regel zu Unterscheidung der beiden Terme</ins>: Wenn steht: `we hold out [name of the set]`, dann ist es das `testing dataset`.

> Was ist `IDE PyCharm`?

Das ist das RStudio von Python.

> What is an `array`?

An `Array` is a List of Data. In a `DataFrame`-Object, you can think of a `column` *or* a `row` to be `arrays`. It is a data structure, which contains "n" objects within a list. 
	- <ins>Quelle</ins>: [The Coding Train 3:10-3:22](https://www.youtube.com/watch?v=NptnmWvkbTw)
	
> Was versteht man unter `Fundamental-Daten`?

Fundamental-Daten sind **effektiv messbare Daten**, die über Datenbanken accessible sind und welche als Proxy - beispielsweise in Regressions-Analysen - verwendet werden können.

> Was versteht man unter dem `Data Flow`?

Mit dem `Data Flow` sollen folgende Fragen beantwortet werden:

1) Welche Daten werden wo geholt & wieso? 
2) Wie werden die Daten anschliessend verarbeitet?
3) Was ist der End-Output, nachdem die Daten - beispielsweise - in einem ML-Modell verwedet wurde?

Zur Illustration des `Data Flows`, gab es hierzu im Wissensaustausch auch eine Bild:

![Beispiel zum Data Flow](./bilder/beispiel-data-flow.jpg)

## Data Science Synonyme

- batch = sample-size when you train your model with a dataset
- Granularität (Beispiel) = Angenommen, man möchte wissen, wie viele Tage, Stunden, Minuten und Sekunden innerhalb von 20'044 Sekunden enthalten sind &#8594; hier haben wir also *Granularität von 4* &#8594; <ins>Lösung</ins>: 4 Tage, 18 Stunden, 37 Minuten, 44 Sekunden
- Kalibrierung des Modells == Wie wurde das Modell programmiert im Allgemeinen? &#8594; Dazu gehört - bei uns - die Anpassung der Prognose.
- label == true y-value
- relativ zu == im Verhältnis zu
- shape == dimension
- target == predicted y-value
- Treiber == x-Variablen
- Volume == Speicherplatz
- weights == estimated coefficients

## Machine Learning in a Nutshell

Dies ist eine super Visualisierung, wie der gesamte Machine Learning Prozess aufgebaut ist und wie dieser anhand von `Learning Curves` kritisch beurteile // assessed werden kann.

![Konzept von Machine Learning](./bilder/framework-in-theory.jpg)

## Machine Learning Jargon &amp; Synonyme

- `"feed in"` == plug in (--> häufig im Zusammenhang mit Einsetzen von konkreten Werten für die x-Variablen in das geschätzte Modell, um Predictions zu erhalten)
- `instance` == value within a cell == konkreter "x"-Wert, welcher angenommen wird und du - beispielsweise - für eine Prediction verwenden kannst.
- `Forcasted data` == These are the predictions that you do via the help of a model (--> by plugging in concrete x-values), that you've built.
- `Training Dataset` // `Training Set` == This is the sample, that you use to estimate your model.
- `Testing Dataset` // `Test Set` == This is the `hold out` set, which you use at the end, to check whether your model is able to `generalize` // `extrapolate` well to new data.
- `"the model is learning` == what is meant by "learning" is: given some Datenpunkt-Wolke, the computer will try and fit the "best line" [oftentimes by minimizing the sum of the squared residuals, if you use `OLS` (= Ordinary Least Squared)] to construct the "best model" possible.
- `Training` == You are estimating a model on the trainig-dataset, such that the model "learns" from the data.
- `shuffle` == englisches Wort für "mischen". In the context of `splitting the dataset into test- & training-data`, it is common practice to `shuffle` your observations within your dataset first.
	- <ins>Reason why you `shuffle`</ins>?: Shuffling data serves the purpose of
		- reducing variance AND 
		- making sure that models remain general AND 
		- overfit less.
	- <ins>Merke</ins>: When dealing with `time series`, you should not use `shuffle` when `splitting the data` into training- &amp; testing-data.
- `training score` // `Test Error` == This error // score is the [oftentimes squared] difference between the `true y-variable` and `estimated // predicted y-variable` and **measures // evaluates how well the model is "performing" // how good the model is on a `test set` with an increasingly bigger `training dataset`**.
- `cross-validation score` // `Validation Error` == This is the (mean) error // score [because of `cross-validation`] that **measures // evaluates how the model is "learning" over increasingly bigger `training datasets`**.
- `fold` == **subset** of the `training dataset`
	- <ins>Example</ins>: In a `K-Fold Cross-Validation`, you *randomly* split the <ins>training set</ins> into **10 distinct subsets**, which are called `folds`.
- `samples` == number of rows // number of observations within a dataset.
- `classifiers` == These are simply regression-functions, where the **Y-Variable is binary**, e.g. die Y-Variable kann nur `Y = 0` ODER `Y = 1` als Werte annehmen.
	- <ins>Example</ins>: Logit- &amp; Probit-Regression, or Naiv Bayes, etc...
- `initialization` // `declaration` // `specification` ==  This is the assignment of an initial value for a data object or variable.
- `Array` == A List of Data is an array. It is a data structure, which contains "n" objects within a list.
	- <ins>Quelle</ins>: [The Coding Train 3:10-3:22](https://www.youtube.com/watch?v=NptnmWvkbTw&t=3m10s)
- `Extrapolation` == Voraussage von Y-Predict<ins>ed</ins> Values, welche mittels X-Variablen ermittelt werden, welche <ins>zuvor nicht im Datensatz</ins> waren.
- `Interpolation` == Voraussage von Y-Predict<ins>ed</ins> Values, welche mittels X-Variablen ermittelt werden, welche <ins>bereits im Datensatz</ins> waren, als die Schätzung  getätigt wurde.

## Projekt-Management Wichtiges

- **Sitzungen müssen gut dokumentiert werden! Insbesondere ist hervorzuheben, in welche Richtung das Projekt geht.**

## IT Begriffe &amp; Jargon

- Abhängigkeitsprobleme == 1) Probleme bei den Versionen des Packages; 2) Packages werden vorausgesetzt, sodass gewisser Code dann einen Error printed, wenn man ihn nach 2 Jahren wiederverwenden will. 
- *agnostisch* == Im IT-Umfeld hat das Wort agnostisch eine besondere Bedeutung. Es bezieht sich auf etwas, das soweit **verallgemeinert** wird, dass es auch unter verschiedenen Umgebungen funktionieren kann. 
	- <ins>Beispiel</ins>: Eine Plattform-agnostische Software läuft unter jeder Kombination aus Betriebssystemen und Prozessorarchitekturen.
- *cached* == store away for future use
- *Client* == Damit ist häufig der Browser gemeint, wenn er Abfragen an den Server gibt.
- *composite* == custom
- *Remote* == Das ist z.B. ein Server / eine Maschine, die du nicht lokal bedienst.
- *instanziieren* == Das Erzeugen eines Objekts in der objektorientierten Programmierung.

## Python Begriffe

- `Module` == Python-File
- `PyPA` ==  Python Packaging Authority
- `PyPI` == Python Package Index

## HR Begriffe / Jargon

- Geschäftseinheiten = Organisationsstruktur (nicht zu verwechseln mit Geschäfts<ins>bereich</ins>)
- Geschäftsbereich = Die Abteilung Energie ist z.B. ein Geschäftsbereich
- "Operativer Betrieb" == Daily Business
- "Pro Rata" (in Bezug zu Ferien, wenn ich nur 7.5 Monate bin bei der SBB) == 25 TAGE * (7.5 Monate / 12 Monate) = proportional
- *PEMO* = Personalmotivation
- Use Case = Anwendungsfall = Beispiel
- Traktandum = Bulletpoints in Confluence

### Nützliche Technische Abbreviations

- *BC* = Business Case
- *CPU* = Rechenleistung
- *GPU* = Graphics Processing Unit --> um graphische Darstellungs-Rendering zu verschnellern
- *GUI* = Graphical User Interface --> das ist die grafische Oberfläche, die du benutzt, um ein Spiel / Programm / App / (Webseite?) zu bedienen.
- *HPU* = High Performance Computing
- *PoC* = Proof of Concept = Meilenstein in einem Projekt

### Nützliche Business Abbreviations

- *AG* = Arbeitsgruppe
- *DAE* = Dimensionierung & Anlagemanagement
- *EN* = Energie
- *EOP* = Operations
- *GPL* = Geschäftsplanung
- *HOP* = Hochschulpraktikum
- *i.W.* = im Weiteren
- *LMS* = Learning Management System
- *PJN* = Projekte & Engineering
- *UX* = User Experience --> this is basically "people oriented computing"
- *EAIO* = Entwicklertools All-in-One -->installer that 1) provides AND 2) installs the latest development tools.
- *wdh* == Wiederholung
- *WiP* == Work in Progress
- *TDI* == Technologie, Digitalisierung & Innovation
- *MVP* == Minimal Viable Product

### Synonyme

- Rest API == Restful API

### Meeting

> Was ist das Ziel eines Meetings?

Das Ziel des Meetings ist es, dir & deinem Team die **nötige Basis zu geben, damit du in der folgenden Zeit bis zum nächsten Meeting genau weisst, was du zu tun hast**.

Am wichtigsten ist hier mit dem "Boss" zu reden und klar definieren, was er erreichen will im Projekt. Dies gibt die _globale Richtung_ des Projektes an.

_Es ist exterm wichtig, mit dem Boss diese Ziele zu definieren, da die Planung des gesamten Projektes in dieser Phase hier noch definiert werden kann. Nachdem diese anfängliche Gliederung getätigt wurde, kann im Verlauf des Projektes nicht mehr viel davon abgewichen werden. Deshalb hängt die Gesampt-Performance eines Projektes sehr stark von der anfänglichen Planung ab!_

<u>Während</u> des Projektes gibt es dann immer wieder folgende Punkte zu prüfen:

0) Sind die getätigten Schritte im Einklang mit dem Endziel des Bosses? Wichtig ist zu rechtfertigen, was du gerade am tun bist und warum genau du das tust.
1) Aufklärung, damit alle auf dem gleichen Informationsstand sind 
  - <ins>Goal</ins>: Wo stehen wir? Wie sieht die Situation mit dem Notebook aus?
2) Gibt es noch offene Lücken im Wissen eines Team-Mitglieds, welches von anderen Mitarbeitern gedeckt werden müsste? --> <u>Goal</u>: Kein Mitglied isolieren, jeder muss sich integriert fühlen. Insbesondere Wert auf Papers & Daten setzen hier
3) Was sind weitere offene Optionen und inwiefern eignen sich diese Ansätze für unser Ziel?
    - <ins>Goal</ins>: Aufzeigen, dass wir noch weitere Alternativen haben, als nur Phillip's Notebooks
4) Sonstige Unklarheiten / Bemerkungen / Inputs / Vorschläge? --> <u>Goal</u>: letzte Informationsasymmetrien beheben

> Was ist ein *Kanban*?

In der BWL-Sprache ist *Kanban* **ein Vorgehensmodell** zur Softwareentwicklung.
  
  - <ins>Ziel #1</ins>: Das Meetings soll die Anzahl an paralleler Arbeiten, (= **der Work in Progress (WiP)) minimiert // begrenzt werden** und somit kürzere Durchlaufzeiten erreicht.
  - <ins>Ziel #2</ins>: Das Meeting soll die Probleme – insbesondere **Engpässe – schnell sichtbar machen**.


