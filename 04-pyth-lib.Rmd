# Python Libraries

## List of Useful Python-Libraries 

- `numpy`, for **mathematical operations**.
- `pandas`, for **doing data analysis**, for example:
  - _Read & Save data_.
  - _Drop missing values_.
  - _Feature Engineering_.
- `statsmodels`, for **regression analysis in "econometrics-style"**.
  - Run a linear model (OLS).
  - Run a binary-regression (logit or probit).
  - Run a choice-model.
- `sktime`, for **time-series analysis inkl. machine-learning**.
- `sklearn`, for **machine-learning in "computer-science style"**.
- `matplotlib`, for **data-visualization**.
- `seaborn`, for **data-visualization**.
- `datetime`, for **dealing with dates**.
- `beautifulsoup`, for **getting data**.
- `PyTorch`, for **deeplearning**.
- `TensorFlow`, for **deeplearning**.

## `Python`-Mustercodes für Data-Science

Für eine übersichtliche **Zusammenfassung, welche die Python-Basics bis hin zu Visualisierungen abdeckt**, empfehle ich dir <a href="https://joffreymayer.github.io/ds-from-scratch/python-mustercodes.html" target="_blank">dieses Juypiter Notebook</a>.

## Basic `Python`

In this part, I will give you some useful `Python`-Code, which can be helpful in _any_ project.

### Put a time-stamp on each Python-Cell

The `ipython-autotime` library is particularly useful to get an overview of **how long each Python-Cell** takes to be executed. 

You can even use it for  debugging in combination with the `datetime`-library in order to use `print()`-statements that gives you **the run-time of - for example - each model-fiting iteration (in a loop)**.

#### Installation

To install this wonderful option

```
pip install ipython-autotime
```

#### Activation

It uses a `Python Magic-Command` (= note the `%`) in order to be able to use this library:

```
%load_ext autotime
```

## Pandas Library

### Padas DataFrame

![This is the overview of a `Pandas` DataFrame](./bilder/python-lib/pandas-df.jpg)

### How to display all the columns?

```pd.set_option('display.max_columns', None)```

### Drop Missing-values?

```
df = df.dropna() # drop the missing values
```

### `loc`- VS. `iloc`-Selection

`loc` &amp; `iloc` are the "accessor operators" in the `pandas`-library. With these,, you can <u>select</u> rows and columns in your dataframe:

- <u>For `loc`</u>: Based on the _name_ of the rows (= row-label // row-index)
and columns.

- <u>For `iloc`</u>: Based on the <u>position</u> // where the specific rows &amp; columns are within the dataset.

#### <u>Vorsicht</u>: different Slicing for `loc` VS. `iloc`!

When using `iloc`, **the range 0:5** will select entries `0,...,4` that is: it indexes EXCLUSIVELY. On the other hand, `loc`, meanwhile, indexes *INCLUSIVELY*. So **the <u>same</u> range 0:5** will select entries `0,...,5`!!!

*Hence, if you want the SAME output with `loc` and `iloc`, you simply need to slightly change the `range()`-function.*

- <u>Example</u>:

```{python eval=FALSE}
## Möglichkeit 1: with 'iloc'
iloc_test = dd.iloc[0:5,0] # row-position == 0:5 --> first 5 rows; EXCLUDES '5' from the range "0,1,2,3,4,5" 
                                          # --> hence range(0:5) results in --> "0,1,2,3,4"
                                          # column-position == 0 --> 1st row --> remember: indexing in 
                                          # Python starts at '0'!

    # IMPORTANT: 'iloc' uses the 'Python stdlib' indexing scheme, where the first element of the range is 
    # included and the last one excluded. So 0:5 will select entries 0,...,4 (= these are the first *5* 
    # entries!!).

## Möglichkeit 2: to get the SAME output with 'loc', we need a slightly DIFFERENT range!
loc_test = dd.loc[0:4,'order_id'] # row-position == 0:4 --> first 5 rows; INCLUDES '4' 
                                  # --> hence range(0:4) results in --> "0,1,2,3,4"

## check if the output are the same, even though "range()" has slightly different inputs? --> yes!
print(iloc_test)
print(loc_test)
```

### Drop a Column with the `pop()`-Method

**This method can be used, when you split your dataset into `y` (= the label) and the `X`-variables**.

- __Pop__: "Pop" is simply a word that means "to drop something". For example, `df.pop('date')` means that I am dropping the column called "data" from a dataframe called "df". Fancily, if you write `df.pop('date')` and *save* it into another variable, then you can only **select** this dropped column from the ddset.
  - <u>Example</u>: [See the `Pandas`-Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html)
  
### Convert into "Date-Time"-format with the `to_datetime()`-Method

**This method can be used when you need to convert a "Date"-Column into the correct `Date-Time`-Format in order to work with _time-series data_**.

```{python eval = FALSE}
df['Date-Time'] = pd.to_datetime(df['Date-Time'], format='%Y-%m-%d %H:%M:%S')
df['Date-Time'] # check, if it worked?
```

### <u>Umgekehrt</u>: Use the `strftime()`-Method to convert a Date-Column back into a "String"-Format

```{python eval = FALSE}
df['Date-Time'] = df['Date-Time'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S%z'))
```

> Why would we do this?

Sometimes, there will be the **problem, that we want to merge different time-series together, but they have different `Date-Time`-Formats to begin with**! 

Hence, _BEFORE_ we apply the `UTC`-universal `Date-Time`-Format, we will need to bring every separate data-frame into the same `Date-Time`-Format. 

Since `Python` is really good for handling transformations on the `str`-format, we can use this to our advantages and:

1) Bring the `Date-Time`-**String** into the way we want it to be on all our _separate_ `Date-Time`-Columns across those different datasets.
2) And then, we will be able to convert them back into the `UTC`-Format! =)

_In order to see, how to manipulate strings, I strongly recommend you to look at the sub-chapter "String-Manipulation"._

## Statsmodels

This library should be used when you need to:

- **Estimate an OLS-regression**,
- **Estimate a binary regression**, like:
  - A linear probability model, 
  - A logit regression OR,
  - A probit regression.
- **Estimate a choice model**, such as: 
  - A multinomial logit model, 
  - A probit model OR, 
  - A logit model.
- **Estimate a time-series regression**, 

### Useful Nice-to-Knows

- Use `statsmodels` in combination with the `patsy`-library. For instance, if we have: some variable y, and we want to regress it against some other variables x, a, b, and the interaction of a and b, then we simply write:

```
patsy.dmatrices("y ~ x + a + b + a:b", data)
```

### Define the `y`-variable & `X`-variable<u>s</u>

```
y, X = dmatrices('Lottery ~ Literacy + Wealth + Region', data=df, return_type='dataframe')
```

<u>Notice that `dmatrices`-function above does the following things</u>:

- **It creates Dummies**: Split the <u>categorical-variable</u> _Region_ into a set of indicator-variables (= Dummy-Variables).
- **Added a _constant_** (= `Intercept`-Column) to the exogenous regressors matrix.
- **Returned `pandas`-DataFrames** instead of simple `numpy`-arrays.

### Estimate a Model

```
model = sm.OLS(y, X) # Step 1) Choose the model type --> here, we choose the model to be of the class "OLS" (= instantiate the model: which type of model do you want, for example OLS, GLM, RLM etc...?)
results = model.fit() # Step 2: Fit the model
print(results.summary()) # Step 3: Summarize model
```

#### Extract the $\hat\beta$-Parameters

```
results.params
```

## Time-Series Forecasting

Here, I will explore different libraries that will allow you to make forecasts into the future.

### Working with `Date`-Columns

_Since you will - most probably - often work with time-series data, you MUST learn how to handle this data-type well_! 

- **For <u>any</u> project with time-series data**, the following questions about your `Date-Time`-Column need to be answered:

```
- What is the current 'dtype' of your 'Date-Time'-Column?
- If you work with multiple time-series: are all time-series already in the UTC-format? If NOT, then you better do it, otherwise you have the wrong hours across different time-zones!
```

### Facebook Prophet Library

Aus einer didaktischen Perspektive ist die offizielle Dokumentation der **Prophet-Library wunderbar, um die Unterschiede zwischen `R` &amp; `Python` (Objekt-Orientierte Programmierung) zu entdecken**.

- <u>Link zur offiziellen Dokumentation</u>: https://facebook.github.io/prophet/docs/quick_start.html

### SkLearn Library

> In some functions, you will need to set the option `random_state`. **If you want reproducible results**, how do you need to handle `random_state`?

Just set `random_state` to an integer. Dieser integer kann *beliebig* gewählt werden, das ist `SkLearn` egal!

### SkTime Library

#### SkTime API

> Überischt zum API in `sktime`?

Grundsätzlich verwendet `sktime` fit-, predict-, und transform-class-methods. Um zu verstehen, was dies genau bedeutet, hier eine globalere Übersicht mit Hilfe einer Visualisierung veranschaulicht:

![API of sktime](./bilder/api_sktime.jpg)

- For *estimator classes* (a.k.a. model classes), `sktime` provides:
 	- a fit-method (= <u>goal</u>: training // estimating the model) and 
 	- a predict-method (= <u>goal</u>: generate new predictions).

- For *transformer classes*, `sktime` provides:
	- various fit-methods,
	- various transform-methods to transform data that comes in series.
	
#### Reduction

> What does it mean: "Reduction is composable"?  

Ein Synonym wäre: "addieren" &#8594; E.g. you can split a difficult task into a bunch of smaller tasks (= reduction) and "add" them together to solve the bigger task at the end (= "reduction is composable").

#### Forecasting-Horizon

> Welche Arten von *Forecasting-Horizon* gibt es?

1) Es gibt einen **<u>relativen</u> forecasting-horizon** (FH), dh "relativ" zur Trainings-Periode ist hier gemeint!
2) Es gibt auch einen **<u>absoluten</u> FH**. Hier werden die *absolute time-points in the future* verwendet für die Prediction. 

- <u>Quelle</u>: [Im "examples"-Repository auf Github zur `Sktime`-Library > 01_forecasting.ipynd](https://github.com/alan-turing-institute/sktime/blob/main/examples/01_forecasting.ipynb)

#### Train-Test Split

> What do you need for parameters // inputs to write a train-test split function for time series data?

You need **3 arguments // inputs** for such a function in time series:

1) the data
2) the window length, e.g. how many periods the training dataset should have.
3) the length of the forecasting horizon, e.g. how many periods into the future our validation-period go.

- <u>Quelle</u>: [Youtube-Video ab 46:25](https://www.youtube.com/watch?v=Wf2naBHRo8Q&t=46m25s)

#### Konkurrenz-Libraries für Time-Series 

> What are other useful libraries when working with Time Series in Python?

Besides `Sktime`, there are 5 other libraries in Python which you can use for different purposes:

- Stop [this Video at 5:35](https://www.youtube.com/watch?v=Wf2naBHRo8Q&t=5m35s) um zu sehen, für welche Zwecke sie sich am besten eignen.

#### Example on Github

> In the [`example` Repository on Github](https://github.com/alan-turing-institute/sktime/blob/main/examples/01_forecasting.ipynb), was ist die Einheit der *y-variable* in `01_forecasting.ipynd`?

- <u>Einheit der y-Variable</u>: in Monate

## Tensorflow

### Definition

PyTorch and TensorFlow are far and away **the two most popular Deep Learning frameworks** today.

While **`TensorFlow` has a reputation for being an industry-focused framework** and **`PyTorch` has a reputation for being a research-focused framework**.

### Tensorflow VS. PyTorch

> Which one is more popular in the Deep-Learning Community?

![PyTorch VS. Tensorflow popularity](./bilder/usage-pytorch-vs-tensorflow.png)

As you can see, the adoption of PyTorch was extremely rapid and, in just a few years, grew from use in just about 7% to use in almost 80% of papers that use either PyTorch or TensorFlow.

![Sankey-Diagram, in order to answer the question: Which one has the Momentum?](./bilder/momentum-tensorflow-vs-pytorch.png)
The researchers find that **the majority of authors who used TensorFlow in 2018 migrated to PyTorch in 2019 (55%), while the vast majority of authors who used PyTorch in 2018 stayed with PyTorch 2019 (85%)**. 

This data is visualized in the `Sankey diagram` above, where the left side corresponds to 2018 and the right side to 2019.

### Data-Windowing Konzept | Erklärung mittels Beispielen

> Wie erklärt man einem Computer, dass man gerne eine Vorhersage möchte von 1h, aber <u>NICHT</u> für die darauf folgende Stunde, sondern <u>erst in 24h</u>!?

Mittels **Data-Windowing** lässt sich dieses Problem allgemein lösen:

![Data-Windowing anhand von 2 Beispielen erklärt. Es geht darum, den richtigen Prognose-Horizont festzulegen.](./bilder/python-lib/data-windowing-konzept.jpg)

### Wörterbuch

- __Offset__: Zeitlicher Versatz zwischen den Input-Variablen $X_t$ und der zu vorhersehenden Variable $Y_{t+1}$.
  - <u>Beispiel, anhand einer "single Prediction", welche 24h weiter in der Zukunft liegt</u>: 
  
![Visualisierung des Offsets](./bilder/python-lib/offset-example.jpg)

#### Synonyme

- Offset // shift
