{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code source: Sebastian Curi and Andreas Krause, based on Jaques Grobler (sklearn demos).\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# We start importing some modules and running some magic commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# General math and plotting modules.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erfinv\n",
    "from scipy import linalg\n",
    "\n",
    "# Project files.\n",
    "from utilities.util import gradient_descent\n",
    "from utilities.classifiers import Logistic\n",
    "from utilities.regularizers import L2Regularizer\n",
    "from utilities.load_data import polynomial_data, linear_separable_data\n",
    "from utilities import plot_helpers\n",
    "from utilities.widgets import noise_widget, n_components_widget, min_prob_widget\n",
    "\n",
    "# Widget and formatting modules\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl \n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# If in your browser the figures are not nicely vizualized, change the following line. \n",
    "rcParams['figure.figsize'] = (10, 5)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Machine Learning library. \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn import datasets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset, n_samples=200, noise=0.3):\n",
    "    if dataset == 'linear':\n",
    "        X, Y = linear_separable_data(n_samples, noise=noise, dim=2) \n",
    "        Y = (Y + 1) // 2\n",
    "    elif dataset == '2-blobs':\n",
    "        X, Y = datasets.make_classification(n_classes=2, n_features=2, n_informative=2, n_redundant=0,\n",
    "                                            n_clusters_per_class=1, n_samples=n_samples, random_state=8)\n",
    "    elif dataset == '3-blobs':\n",
    "        X, Y = datasets.make_classification(n_classes=3, n_features=2, n_informative=2, n_redundant=0,\n",
    "                                            n_clusters_per_class=1, n_samples=n_samples, random_state=8)\n",
    "    elif dataset == '4-blobs':\n",
    "        X, Y = datasets.make_classification(n_classes=4, n_features=2, n_informative=2, n_redundant=0,\n",
    "                                            n_clusters_per_class=1, n_samples=n_samples, random_state=8) \n",
    "    elif dataset == 'high-dim':\n",
    "        X, Y = datasets.make_classification(n_classes=3, n_features=10, n_informative=6, n_samples=n_samples,\n",
    "                                            random_state=8)\n",
    "        \n",
    "    elif dataset == 'circles':\n",
    "        X, Y = datasets.make_circles(noise=noise, n_samples=n_samples, factor=.5)\n",
    "    elif dataset == 'moons':\n",
    "        X, Y = datasets.make_moons(noise=noise, n_samples=n_samples)\n",
    "    elif dataset == 'imbalanced':\n",
    "        X, Y = linear_separable_data(n_samples, noise=noise, dim=2, num_negative=int(n_samples * 0.2))\n",
    "        Y = (Y + 1) // 2\n",
    "    elif dataset == 'correlated':\n",
    "        X, Y = datasets.make_classification(n_classes=2, n_features=2, n_informative=1, n_redundant=1,\n",
    "                                            n_clusters_per_class=1, n_samples=n_samples, random_state=8)  \n",
    "    elif dataset == 'iris':\n",
    "        X, Y = datasets.load_iris(return_X_y=True)\n",
    "    elif dataset == 'mnist':\n",
    "        X, Y = datasets.load_digits(return_X_y=True)\n",
    "    elif dataset == 'wine':\n",
    "        X, Y = datasets.load_wine(return_X_y=True)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ellipse(mean, covar, color, ax):\n",
    "    v, w = linalg.eigh(covar)\n",
    "    v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "    u = w[0] / linalg.norm(w[0])\n",
    "\n",
    "    # Plot an ellipse to show the Gaussian component\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180. * angle / np.pi  # convert to degrees\n",
    "\n",
    "\n",
    "    ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle,  color=color)\n",
    "    ell.set_clip_box(ax.bbox)\n",
    "    ell.set_alpha(0.5)\n",
    "    ax.add_artist(ell)\n",
    "\n",
    "\n",
    "def plot_model(model, X, Y, means, covariances):\n",
    "    num_classes = len(np.unique(Y))\n",
    "    cmap = plt.cm.jet\n",
    "    pmap = plt.cm.cividis_r\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=num_classes - 1)\n",
    "        \n",
    "    # PREDICT\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = .02  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    xy = np.c_[xx.ravel(), yy.ravel()]\n",
    "    C = model.predict(xy)\n",
    "    P = model.predict_proba(xy)\n",
    "    H = -(P * model.predict_log_proba(xy)).sum(axis=1)\n",
    "    \n",
    "    P = P.max(axis=1)\n",
    "    # Put the result into a color plot\n",
    "    C = C.reshape(xx.shape)\n",
    "    P = P.reshape(xx.shape)\n",
    "    H = H.reshape(xx.shape)\n",
    "    \n",
    "    # PLOTS\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.jet)\n",
    "        \n",
    "        if means is not None:\n",
    "            for i in range(num_classes):\n",
    "                plot_ellipse(means[i], covariances[i], cmap(norm(i)), ax)\n",
    "\n",
    "        ax.set_xlim(xx.min()+h, xx.max()-h)\n",
    "        ax.set_ylim(yy.min()+h, yy.max()-h)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    axes[0].set_title('Classification Boundary')\n",
    "    axes[0].contourf(xx, yy, C, cmap=cmap, alpha=0.5)\n",
    "    \n",
    "    axes[2].set_title('Prediction Probabilities')\n",
    "    cf = axes[2].contourf(xx, yy, P, cmap=pmap, alpha=0.5, vmin=1. / num_classes, vmax=1)\n",
    "    \n",
    "    axes[1].set_title('Probabilistic Boundary')\n",
    "    axes[1].contourf(xx, yy, P * C, cmap=cmap, alpha=0.5)\n",
    "    plt.show()\n",
    "    # Plot also the training point\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Modelling (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 15)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "def generative_modelling(dataset, model, noise):\n",
    "    np.random.seed(0)\n",
    "    X, Y = get_dataset(dataset, noise=noise)\n",
    "    num_classes = len(np.unique(Y))\n",
    "    X = X[:, :2]\n",
    "    if model == 'Naive Bayes':\n",
    "        model = GaussianNB().fit(X, Y)\n",
    "        mean, covariance = model.theta_, [np.diag(model.sigma_[i]) for i in range(len(model.classes_))]\n",
    "        priors = model.class_prior_\n",
    "    elif model == 'FisherLDA':\n",
    "        model = LDA(store_covariance=True, priors=np.ones(num_classes) / num_classes).fit(X, Y)\n",
    "        mean, covariance = model.means_, [model.covariance_ for i in range(len(model.classes_))]\n",
    "        priors = model.priors_\n",
    "    elif model == 'LDA':\n",
    "        model = LDA(store_covariance=True).fit(X, Y)\n",
    "        mean, covariance = model.means_, [model.covariance_ for i in range(len(model.classes_))]\n",
    "        priors = model.priors_\n",
    "    elif model == 'QDA':\n",
    "        model = QDA(store_covariance=True, reg_param=1e-6).fit(X, Y)\n",
    "        mean, covariance = model.means_, model.covariance_\n",
    "        priors = model.priors_\n",
    "    elif model == 'LogisticRegression':\n",
    "        model = LogisticRegression().fit(X, Y)\n",
    "        mean, covariance = None, None\n",
    "        priors = None\n",
    "        \n",
    "    plot_model(model, X, Y, mean, covariance)\n",
    "    if priors is not None:\n",
    "        print(f\"Class Priors: {priors}\")\n",
    "    \n",
    "interact(generative_modelling, \n",
    "         dataset=['2-blobs', 'linear',  'correlated',  'imbalanced', '3-blobs', '4-blobs', 'circles', 'moons', 'iris'], \n",
    "         model=['Naive Bayes', 'FisherLDA', 'LDA', 'QDA', 'LogisticRegression'], noise=noise_widget);\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA as Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 5)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "dataset, noise = 'high-dim', 0.3\n",
    "dataset = 'iris'\n",
    "\n",
    "def dim_reduction(dataset, noise):\n",
    "    np.random.seed(0)\n",
    "    X, Y = get_dataset(dataset, noise=noise)\n",
    "    num_classes = len(np.unique(Y))\n",
    "    cmap = plt.cm.jet\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=num_classes - 1)\n",
    "\n",
    "    # X = X[:, :2]\n",
    "\n",
    "    pca = PCA(n_components=2).fit(X)\n",
    "    Xpca = pca.transform(X)\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        lda = LDA(n_components=2, store_covariance=True, solver='eigen').fit(X, Y)\n",
    "        Xlda = np.dot(X, lda.scalings_)[:, :2]\n",
    "        means = np.dot(lda.means_, lda.scalings_)[:, :2]\n",
    "    else:\n",
    "        lda = LDA(n_components=2, store_covariance=True).fit(X, Y)\n",
    "        Xlda = np.dot(X - lda.xbar_, lda.scalings_)[:, :2]\n",
    "\n",
    "        means = np.dot(lda.means_ - lda.xbar_, lda.scalings_)[:, :2]\n",
    "\n",
    "    cov = lda.scalings_.T @ lda.covariance_ @ lda.scalings_ \n",
    "    cov = cov[:2, :2]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "    axes[0].scatter(X[:, 0], X[:, 1], c=Y, cmap=cmap)\n",
    "    axes[0].set_title('First 2 Dimensions')\n",
    "\n",
    "    axes[1].scatter(Xpca[:, 0], Xpca[:, 1], c=Y, cmap=cmap)\n",
    "    axes[1].set_title(f\"PCA Explained Var {np.array2string(pca.explained_variance_ratio_, precision=2, separator=',')}\")\n",
    "\n",
    "    axes[2].scatter(Xlda[:, 0], Xlda[:, 1], c=Y, cmap=cmap)\n",
    "    # axes[0].set_aspect('equal')\n",
    "    for i in range(num_classes):\n",
    "        plot_ellipse(means[i], cov, cmap(norm(i)), axes[2])\n",
    "    axes[2].set_title(f\"LDA Explained Var {np.array2string(lda.explained_variance_ratio_, precision=2, separator=',')}\")\n",
    "    \n",
    "interact(\n",
    "    dim_reduction, \n",
    "    dataset=['high-dim', 'iris',  'mnist', 'wine'], \n",
    "    noise=noise_widget\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Modelling as Anomally Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies(X, mean, covariance, priors, threshold):\n",
    "    num_classes = len(covariance)\n",
    "    P = np.zeros(X.shape[0])\n",
    "    m = 0\n",
    "    for i in range(num_classes):\n",
    "        d = multivariate_normal(mean[i], covariance[i])\n",
    "        d.logpdf(X)\n",
    "        P += priors[i] * 2 * d.pdf(X)\n",
    "        m += priors[i] * d.pdf(mean[i])\n",
    "    return P < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 10)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "def anomaly_detection(dataset, threshold,  model_name, noise):\n",
    "    np.random.seed(0)\n",
    "    X, Y = get_dataset(dataset, noise=noise)\n",
    "    X = X[:, :2]\n",
    "\n",
    "    num_classes = len(np.unique(Y))\n",
    "    cmap = plt.cm.jet\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=num_classes - 1)\n",
    "\n",
    "    if model_name == 'Naive Bayes':\n",
    "        model = GaussianNB().fit(X, Y)\n",
    "        mean, covariance = model.theta_, [np.diag(model.sigma_[i]) for i in range(len(model.classes_))]\n",
    "        priors = model.class_prior_\n",
    "    elif model_name == 'FisherLDA':\n",
    "        model = LDA(store_covariance=True, priors=np.ones(num_classes) / num_classes).fit(X, Y)\n",
    "        mean, covariance = model.means_, [model.covariance_ for i in range(len(model.classes_))]\n",
    "        priors = model.priors_\n",
    "    elif model_name == 'LDA':\n",
    "        model = LDA(store_covariance=True).fit(X, Y)\n",
    "        mean, covariance = model.means_, [model.covariance_ for i in range(len(model.classes_))]\n",
    "        priors = model.priors_\n",
    "    elif model_name == 'QDA':\n",
    "        model = QDA(store_covariance=True).fit(X, Y)\n",
    "        mean, covariance = model.means_, model.covariance_\n",
    "        priors = model.priors_\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2)\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = .02  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    xy = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "\n",
    "    for j in range(2):\n",
    "        axes[j, 0].scatter(X[:, 0], X[:, 1], c=Y, marker='o', cmap=cmap)\n",
    "        for i in range(num_classes):\n",
    "            plot_ellipse(mean[i], covariance[i], cmap(norm(i)), axes[j, 0]);\n",
    "\n",
    "    axes[0, 0].set_title('Original Data')\n",
    "    C = model.predict(xy)\n",
    "\n",
    "    axes[1, 0].set_title('Original Classification Boundary')\n",
    "    axes[1, 0].contourf(xx, yy, C.reshape(xx.shape), cmap=cmap, alpha=0.5);\n",
    "\n",
    "\n",
    "    idx = get_anomalies(X, mean, covariance, priors, threshold)\n",
    "    for j in range(2):\n",
    "        axes[j, 1].scatter(X[idx, 0], X[idx, 1], c=Y[idx], marker='x', cmap=cmap, label='Anomalies')\n",
    "        axes[j, 1].scatter(X[~idx, 0], X[~idx, 1], c=Y[~idx], marker='o', cmap=cmap, label='Non-anomalies')\n",
    "\n",
    "    axes[0, 1].set_title('Anomaly Detection')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    idxy = get_anomalies(xy, mean, covariance, priors, threshold)\n",
    "    C = 2 * C\n",
    "    C[idxy] = 1\n",
    "    axes[1, 1].set_title('Anomalous Classification Boundary')\n",
    "    axes[1, 1].contourf(xx, yy, C.reshape(xx.shape), cmap=cmap, alpha=0.5);\n",
    "    \n",
    "    for row in axes:\n",
    "        for ax in row:\n",
    "            ax.set_xlim(xx.min() + h, xx.max() - h)\n",
    "            ax.set_ylim(yy.min() + h, yy.max() - h)\n",
    "    \n",
    "interact(anomaly_detection, \n",
    "         dataset=['linear', '2-blobs', 'correlated',  'imbalanced', '3-blobs', '4-blobs', 'circles', 'moons', 'iris'], \n",
    "         threshold=ipywidgets.FloatSlider(\n",
    "             value=.1, min=0, max=.5, step=.01, description='Threshold', continuous_update=False),\n",
    "         model_name=['Naive Bayes', 'FisherLDA', 'LDA', 'QDA'], \n",
    "         noise=ipywidgets.FloatSlider(value=0.2, min=0, max=1, step=0.01, description='Noise:', continuous_update=False));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
